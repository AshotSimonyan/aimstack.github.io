<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Access your category realted articles</title><meta name="robots" content="index,follow"/><meta name="description" content="Access your category realted articles"/><meta property="og:title" content="Access your category realted articles"/><meta property="og:description" content="Access your category realted articles"/><meta property="og:url" content="https://aimstack.io/"/><meta property="og:image" content="https://v4.aimstack.io/banner.png"/><meta property="og:image:alt" content="banner"/><meta property="og:image:type" content="image/jpeg"/><meta property="og:image:width" content="1224"/><meta property="og:image:height" content="724"/><meta property="og:site_name" content="Aimstack"/><meta name="next-head-count" content="14"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><style id="stitches">--sxs{--sxs:0 t-fsRyUS}@media{:root,.t-fsRyUS{--fonts-OpenSans:'Open Sans', sans-serif;--fonts-Lora:'Lora', serif;--fonts-Inconsolata:'Inconsolata', monospace;--fonts-base:var(--fonts-OpenSans);--colors-blue:#1093F2;--colors-blueHover:#0F7AC8;--colors-lightBlue:rgba(16, 147, 242, 0.1);--colors-lightBlueHover:rgba(16, 147, 242, 0.2);--colors-darkBlue:#0C1031;--colors-darkBlue500:rgba(12,16,49,0.5);--colors-bigStone:#191D3C;--colors-bigStoneHover:#313551;--colors-green:#14C89D;--colors-black:#000000;--colors-black003:rgba(0,0,0,0.03);--colors-black700:rgba(0,0,0,0.7);--colors-black800:rgba(0,0,0,0.8);--colors-white:#ffffff;--colors-white100:rgba(255,255,255,0.1);--colors-white500:rgba(255,255,255,0.5);--colors-white700:rgba(255,255,255,0.7);--colors-red:#CC231A;--colors-lightGrey:#F4F7F9;--colors-lightGreyHover:#ECEEF0;--colors-grey:#CFD3D6;--colors-darkGrey:#737379;--colors-darkGreyHover:#393940;--colors-primary:var(--colors-blue);--colors-primaryHover:var(--colors-blueHover);--colors-primaryLight:var(--colors-lightBlue);--colors-primaryLightHover:var(--colors-lightBlueHover);--colors-secondary:var(--colors-green);--colors-textColor:var(--colors-black);--colors-bgColor:var(--colors-darkBlue);--colors-danger:var(--colors-red);--fontSizes-1:14px;--fontSizes-2:16px;--fontSizes-3:18px;--fontSizes-4:20px;--fontSizes-5:22px;--fontSizes-6:24px;--fontSizes-7:32px;--fontSizes-8:44px;--fontSizes-9:64px;--fontSizes-10:68px;--fontSizes-baseSize:var(--fontSizes-2);--space-1:4px;--space-2:8px;--space-3:12px;--space-4:16px;--space-5:20px;--space-6:24px;--space-7:28px;--space-8:32px;--space-9:36px;--space-10:40px;--space-11:44px;--space-12:48px;--fontWeights-1:400;--fontWeights-2:500;--fontWeights-3:600;--fontWeights-4:700;--fontWeights-5:800;--shadows-1:0px 60px 66px -65px rgba(11, 47, 97, 0.2);--shadows-2:0px 96px 66px -65px rgba(11, 47, 97, 0.2);--shadows-3:1px 1px 10px 3px  rgb(0, 0, 0, 10%);--shadows-4:0px 10px 24px -10px rgba(11, 47, 97, 0.4);--radii-1:6px;--radii-2:8px;--transitions-main:0.2s ease-out}}--sxs{--sxs:1 exQfIs k-iKtTFk}@media{html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td,article,aside,canvas,details,embed,figure,figcaption,footer,header,hgroup,main,menu,nav,output,ruby,section,summary,time,mark,audio,video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section{display:block}*[hidden]{display:none}*{box-sizing:border-box}ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:none}table{border-spacing:0}strong{font-weight:var(--fontWeights-5)}body{background:var(--colors-white);color:var(--colors-textColor);font-family:var(--fonts-base);font-size:var(--fontSizes-baseSize);line-height:1.35}a{text-decoration:none;color:inherit}a.link{color:var(--colors-primary);font-weight:var(--fontWeights-4)}.text-center{text-align:center}@keyframes k-iKtTFk{0%{opacity:0}10%{opacity:1}90%{opacity:1}100%{opacity:0}}}--sxs{--sxs:2 c-iSkjJi c-guYHoi c-fnKlzS c-hCkBfr c-ePqJJt c-kFnRKY c-lmSDjj c-kPczbf c-lizetl c-fOPBY c-jCnBs c-iKzMen c-PJLV c-doWOai c-dhzjXW c-cZmHrB c-kSnMQa c-kXnqgD c-bMqEGV c-fgXcmv c-gPAtaN c-dMnFVR c-kHrbHn c-hJzboU c-dRMHzO c-FsNLu c-eJqRfT c-jJiyUf c-MNZuo c-cChYXC c-jcfAOr c-jYGtqD c-fKjLcl c-kKhLoP c-gRRuTe c-hnRRWM c-hQOWqi c-jiSXep c-fRHVpw c-bzrsgE c-cBxMqI c-cgVSTP c-cPiarr c-jsGLMb c-fVgYPG c-fxrEBZ c-hTKfPd c-kBUzHM c-hePpyc c-gppSuL c-kqsoHo c-eCJxrf c-hMVjTK c-cQwwIn c-fagtgx c-gsaXpY c-eOYVvF c-fWgRbD c-gswrlc c-jVwFOG c-eYYUfS c-depOeu c-dOghFk c-ckoDwU c-covwPd c-eGPXIo c-jXNvwL c-gDncai c-hhjAKd c-bTiyxX c-cSRvhF c-cnJPJj c-bjrmKQ c-hdKdh c-eVsMjz}@media{.c-iSkjJi{position:relative}.c-iSkjJi .bg-top{z-index:2}.c-iSkjJi .bg-bottom{z-index:1;position:absolute;bottom:300px;left:0;right:0;object-fit:contain;width:100%;height:60%}.c-guYHoi{position:relative;z-index:3;display:flex;flex-direction:column;min-height:100vh}.c-fnKlzS{height:72px;position:fixed;top:0px;left:0px;right:0px;z-index:99;transition:var(--transitions-main)}.c-fnKlzS.dark{background-color:var(--colors-darkBlue)}.c-fnKlzS.dark a{color:var(--colors-white)}.c-fnKlzS.dark.fixed a{color:var(--colors-textColor)}.c-fnKlzS.fixed{box-shadow:var(--shadows-3);background-color:var(--colors-white)}.c-hCkBfr{margin-left:auto;margin-right:auto;padding-left:var(--space-6);padding-right:var(--space-6);width:100%;max-width:1300px}.c-ePqJJt{display:flex;align-items:center;height:100%}.c-kFnRKY{margin-right:50px}.c-kFnRKY .logo{max-width:158px;width:100%;display:block}@media (max-width: 1024px){.c-kFnRKY{position:relative;z-index:11}}.c-lmSDjj{display:flex;justify-content:center}.c-lmSDjj .nav-list{display:flex}.c-lmSDjj .nav-list li:not(:last-child){margin-right:var(--space-6)}@media (max-width: 1440px){.c-lmSDjj .nav-list li:not(:last-child){margin-right:var(--space-4)}}.c-lmSDjj .nav-list li a{-webkit-backface-visibility:hidden;backface-visibility:hidden;display:inline-flex}.c-lmSDjj .nav-list li a .text{transition:var(--transitions-main)}.c-lmSDjj .nav-list li a .badge{display:inline-block;height:18px;line-height:18px;padding:0 4px;border-radius:2px;background-color:var(--colors-primary);color:var(--colors-white);font-weight:700;font-size:10px;margin-left:6px}.c-lmSDjj .nav-list li a:hover .text{opacity:.6}@media (max-width: 1024px){.c-lmSDjj{position:fixed;top:72px;right:0;bottom:0;left:0;overflow-y:auto;z-index:10;height:0;transition:height 0.5s;background-color:var(--colors-white);flex-direction:column;justify-content:space-between}}@media (max-width: 1024px){.open .c-lmSDjj{height:calc(100% - 72px)}}@media (max-width: 1024px){.c-lmSDjj .nav-inner{width:100%;flex-direction:column;align-items:inherit;justify-content:space-between;padding-top:16px}}@media (max-width: 1024px){.c-lmSDjj .nav-list{flex-direction:column;align-items:flex-start}}@media (max-width: 1024px){.c-lmSDjj .nav-list > li{font-size:var(--fontSizes-2);font-weight:var(--fontWeights-3);width:100%}}@media (max-width: 1024px){.c-lmSDjj .nav-list > li a{display:block;padding:var(--space-3) var(--space-5)}}@media (max-width: 1024px){.c-lmSDjj .nav-list > li a:active{background-color:var(--colors-primaryLight)}}@media (max-width: 1024px){.c-lmSDjj .nav-list > li:not(:last-child){margin-right:0}}.c-kPczbf{margin-left:auto}.c-kPczbf span span{display:flex;align-items:center}.c-kPczbf.desktop-btn span span{justify-content:flex-end}.c-lizetl{display:none}@media (max-width: 1024px){.c-lizetl{display:flex;justify-content:center;padding-top:var(--space-6);padding-bottom:var(--space-6)}}@media (max-width: 1024px){.c-lizetl > li{margin-right:var(--space-6)}}.c-fOPBY{display:none}@media (max-width: 1024px){.c-fOPBY{position:relative;z-index:11;display:inline-block;-webkit-appearance:none;appearance:none;border:none;background-color:transparent;line-height:1;cursor:pointer}}.c-jCnBs{flex:1;padding-top:72px}.c-iKzMen{text-align:center;padding-top:80px;padding-bottom:80px}.c-doWOai{padding-top:80px;padding-bottom:80px;color:var(--colors-white);background-color:var(--colors-darkBlue);position:relative}@media (max-width: 1024px){.c-doWOai{padding-top:44px;padding-bottom:44px}}.c-dhzjXW{display:flex}.c-cZmHrB{flex:1}.c-kSnMQa{display:flex;flex-wrap:wrap;margin-left:-60px;margin-top:60px}@media (max-width: 743px){.c-kSnMQa{margin-left:0;margin-top:var(--space-8)}}.c-kXnqgD{width:calc((100% / 2) - 60px);margin-left:60px;margin-bottom:60px}@media (max-width: 743px){.c-kXnqgD{width:100%;margin-left:0;margin-bottom:var(--space-10)}}.c-bMqEGV{-webkit-appearance:none;appearance:none;border:none;background-color:transparent;line-height:1;cursor:pointer;border-radius:var(--radii-1);display:inline-block;transition:var(--transitions-main)}.c-fgXcmv{max-width:650px}.c-fgXcmv img{width:100%;height:auto}@media (max-width: 1024px){.c-fgXcmv{margin:0 auto}}.c-gPAtaN{text-align:center;padding-top:100px}.c-dMnFVR{display:flex;flex-wrap:wrap;margin-left:-40px;margin-top:100px}@media (max-width: 1024px){.c-dMnFVR{justify-content:center}}@media (max-width: 743px){.c-dMnFVR{margin-left:0}}.c-kHrbHn{width:calc((100% / 4) - 40px);margin-left:40px;margin-bottom:60px}@media (max-width: 1024px){.c-kHrbHn{width:calc((100% / 2) - 40px);margin-bottom:40px}}@media (max-width: 743px){.c-kHrbHn{width:100%;margin-left:0}}.c-kHrbHn .card-content{margin-top:var(--space-6)}@media (max-width: 743px){.c-kHrbHn .card-content{text-align:left;margin-top:0}}.c-hJzboU{-webkit-mask-size:100%;mask-size:100%;-webkit-mask-repeat:no-repeat}.c-hJzboU img{object-fit:contain;height:100%;width:100%}@media (max-width: 743px){.c-hJzboU{width:100px;min-width:100px;margin-right:var(--space-6)}}.c-dRMHzO{background-color:var(--colors-darkBlue)}.c-FsNLu{display:flex;align-items:center;justify-content:space-between;flex-wrap:wrap;color:var(--colors-white);padding-top:27px;padding-bottom:27px;border-bottom:1px solid var(--colors-white100)}.c-eJqRfT{margin-right:var(--space-9)}@media (max-width: 1440px){.c-eJqRfT{margin-right:var(--space-6)}}@media (max-width: 743px){.c-eJqRfT{width:100%;margin-right:0;margin-bottom:var(--space-1);text-align:center}}.c-jJiyUf{display:flex}.c-jJiyUf li:not(:last-child){margin-right:var(--space-9)}@media (max-width: 1440px){.c-jJiyUf li:not(:last-child){margin-right:var(--space-4)}}.c-jJiyUf li{transition:var(--transitions-main)}.c-jJiyUf li:hover{opacity:.6}@media (max-width: 1024px){.c-jJiyUf{order:3;width:100%;margin-top:var(--space-7)}}@media (max-width: 1024px){.c-jJiyUf li:last-child{margin-right:0}}@media (max-width: 743px){.c-jJiyUf{order:2;width:100%;margin-bottom:var(--space-2);flex-direction:column;text-align:center}}@media (max-width: 743px){.c-jJiyUf li{margin-bottom:var(--space-6)}}@media (max-width: 743px){.c-jJiyUf li:not(:last-child){margin-right:0}}.c-MNZuo{display:flex}.c-MNZuo li:not(:last-child){margin-right:var(--space-6)}.c-MNZuo li a{transition:var(--transitions-main)}.c-MNZuo li a:hover{opacity:.6}@media (max-width: 743px){.c-MNZuo{margin:0 auto;order:3}}.c-cChYXC{padding-top:var(--space-4);padding-bottom:var(--space-4);color:var(--colors-white500);text-align:center}.c-jcfAOr{display:flex;flex-wrap:wrap;margin-left:-40px}@media (max-width: 1024px){.c-jcfAOr{margin-left:-54px}}@media (max-width: 575px){.c-jcfAOr{margin-left:0}}.c-jYGtqD{width:calc((100% / 3) - 40px);margin-left:40px;margin-bottom:40px}@media (max-width: 1024px){.c-jYGtqD{width:calc((100% / 2) - 54px);margin-left:54px;margin-bottom:54px}}@media (max-width: 575px){.c-jYGtqD{width:100%;margin-left:0;margin-bottom:48px}}.c-fKjLcl{position:relative;height:0;padding-bottom:65%}.c-kKhLoP{padding-top:var(--space-6)}.c-gRRuTe{margin-bottom:var(--space-2);display:flex;align-items:center;color:var(--colors-grey);transition:var(--transitions-main)}.c-gRRuTe .icon{margin-right:var(--space-1);fill:var(--colors-grey);transition:var(--transitions-main)}.c-gRRuTe:hover{color:var(--colors-darkGray)}.c-gRRuTe:hover .icon{fill:var(--colors-darkGray)}.c-hnRRWM{display:flex;align-items:center;justify-content:flex-end}.c-hnRRWM .icon{margin-right:var(--space-1);fill:var(--colors-grey)}.c-hQOWqi{margin-top:var(--space-10);margin-bottom:var(--space-10)}.c-jiSXep{display:flex;align-items:center;justify-content:center}.c-jiSXep li{height:44px;width:44px;font-size:var(--fontSizes-1);font-weight:var(--fontWeights-4);text-align:center;margin-right:var(--space-1)}.c-jiSXep li a{display:block;line-height:44px;transition:var(--transitions-main)}.c-jiSXep li a.active{background-color:var(--colors-primary);color:var(--colors-white)}.c-jiSXep li a:hover:not(.active){color:var(--colors-primary)}.c-jiSXep li a:hover .icon{fill:var(--colors-primary)}.c-fRHVpw{padding:80px 0 64px;text-align:center}@media (max-width: 1024px){.c-fRHVpw{padding:44px 0}}@media (max-width: 743px){.c-fRHVpw{padding:44px 0 24px}}.c-bzrsgE{max-width:948px;width:100%;margin-left:auto;margin-right:auto;position:relative}.c-bzrsgE .github-btn{position:absolute;bottom:0;left:50%;translate:-50% 0}.c-cBxMqI{height:150px;display:flex;background-color:var(--colors-white500);box-shadow:var(--shadows-1)}.c-cgVSTP{display:flex;align-items:center;overflow:visible !important}.c-cgVSTP img{width:95px !important}.c-cPiarr{padding:64px 0 150px}@media (max-width: 1024px){.c-cPiarr{padding:44px 0 80px}}@media (max-width: 743px){.c-cPiarr{padding:24px 0 60px}}.c-jsGLMb{position:relative}.c-jsGLMb .yt-lite{border-radius:var(--radii-2)}.c-jsGLMb .yt-lite > .lty-playbtn{width:68px;height:48px;border:none;border-radius:25%}.c-jsGLMb iframe{position:absolute;width:100%;height:100%;top:0;left:0;border-radius:var(--radii-2);box-shadow:var(--shadows-2)}.c-fVgYPG{position:relative}.c-fVgYPG .float-text{float:left;width:45%}@media (max-width: 1024px){.c-fVgYPG .float-text{width:100%}}.c-fxrEBZ{overflow:hidden}.c-hTKfPd{width:47%;padding-top:80px;padding-bottom:var(--space-9);float:left}@media (max-width: 1024px){.c-hTKfPd{width:100%;float:none;text-align:center}}.c-kBUzHM{float:right;margin-left:80px}@media (max-width: 1024px){.c-kBUzHM{float:none;margin-left:0}}.c-hePpyc{padding-top:var(--space-5)}.c-gppSuL{position:relative}.c-gppSuL.light .hljs{background-color:var(--colors-white);color:var(--colors-textColor)}.c-gppSuL button{position:absolute;right:0;top:6px;background:none;border:none;cursor:pointer;height:42px;width:42px;transition:var(--transitions-main)}.c-gppSuL button:hover{opacity:.6}.c-gppSuL .copied{display:block;opacity:0;position:absolute;right:0;top:-20px;animation:k-iKtTFk 2.5s ease 0s alternate;color:var(--colors-secondary);font-size:var(--fontSizes-1);font-weight:var(--fontWeights-2);transition:var(--transitions-main);z-index:10}.c-gppSuL .hljs{display:block;overflow-x:auto;color:#abb2bf;background:#282c34;margin-bottom:20px;border-radius:var(--radii-1);padding:var(--space-4)}.c-gppSuL .hljs-comment,.c-gppSuL .hljs-quote{color:#5c6370;font-style:italic}.c-gppSuL .hljs-doctag,.c-gppSuL .hljs-keyword,.c-gppSuL .hljs-formula{color:#c678dd}.c-gppSuL .hljs-section,.c-gppSuL .hljs-name,.c-gppSuL .hljs-selector-tag,.c-gppSuL .hljs-deletion,.c-gppSuL .hljs-subst{color:#e06c75}.c-gppSuL .hljs-literal{color:#56b6c2}.c-gppSuL .hljs-string,.c-gppSuL .hljs-regexp,.c-gppSuL .hljs-addition,.c-gppSuL .hljs-attribute,.c-gppSuL .hljs-meta-string{color:#98c379}.c-gppSuL .hljs-built_in,.c-gppSuL .hljs-class .hljs-title{color:#e6c07b}.c-gppSuL .hljs-attr,.c-gppSuL .hljs-variable,.c-gppSuL .hljs-template-variable,.c-gppSuL .hljs-type,.c-gppSuL .hljs-selector-class,.c-gppSuL .hljs-selector-attr,.c-gppSuL .hljs-selector-pseudo,.c-gppSuL .hljs-number{color:#d19a66}.c-gppSuL .hljs-symbol,.c-gppSuL .hljs-bullet,.c-gppSuL .hljs-link,.c-gppSuL .hljs-meta,.c-gppSuL .hljs-selector-id,.c-gppSuL .hljs-title{color:#61aeee}.c-gppSuL .hljs-emphasis{font-style:italic}.c-gppSuL .hljs-strong{font-weight:bold}.c-gppSuL .hljs-link{text-decoration:underline}.c-kqsoHo{padding-top:150px;padding-bottom:150px}.c-kqsoHo .title{text-align:center;margin-bottom:100px}@media (max-width: 1024px){.c-kqsoHo{padding-top:80px;padding-bottom:80px}}@media (max-width: 1024px){.c-kqsoHo .title{margin-bottom:64px}}@media (max-width: 743px){.c-kqsoHo{padding-top:60px;padding-bottom:60px}}@media (max-width: 743px){.c-kqsoHo .title{margin-bottom:44px}}.c-eCJxrf{display:flex;align-items:center;justify-content:space-between}.c-eCJxrf .title-mobile{display:none}@media (max-width: 1024px){.c-eCJxrf{flex-wrap:wrap;align-items:flex-start}}@media (max-width: 1024px){.c-eCJxrf .title-mobile{display:block;width:100%}}@media (max-width: 743px){.c-eCJxrf{flex-direction:column;margin-bottom:60px}}.c-hMVjTK ul li{margin-bottom:var(--space-4);position:relative;padding-left:16px}.c-hMVjTK ul li:before{content:"â€¢";position:absolute;left:0;top:-5px;font-size:24px;color:var(--colors-secondary)}@media (max-width: 1024px){.c-hMVjTK ul{padding-top:var(--space-4)}}@media (max-width: 1024px){.c-hMVjTK{max-width:280px;width:100%}}@media (max-width: 1024px){.c-hMVjTK .title-desktop{display:none}}@media (max-width: 743px){.c-hMVjTK{max-width:100%;order:2}}.c-cQwwIn{display:flex;align-items:center;color:var(--colors-primary);font-family:var(--fonts-OpenSans600);text-decoration:none}.c-cQwwIn .icon{fill:var(--colors-primary);margin-left:var(--space-4)}.c-fagtgx{max-width:610px;width:100%;position:relative}.c-fagtgx img{width:100%;height:auto}@media (max-width: 1024px){.c-fagtgx{max-width:396px;margin-left:0}}@media (max-width: 743px){.c-fagtgx{max-width:100%;order:1}}.c-gsaXpY{padding:60px 0 100px;background-color:var(--colors-darkBlue);color:var(--colors-white)}@media (max-width: 1024px){.c-gsaXpY{padding:60px 0 26px}}.c-eOYVvF{display:flex;flex-wrap:wrap;margin-left:-24px}@media (max-width: 1024px){.c-eOYVvF{margin-left:-54px}}@media (max-width: 575px){.c-eOYVvF{margin-left:0}}.c-fWgRbD{width:calc((100% / 4) - 24px);margin-left:24px;margin-bottom:24px}.c-fWgRbD a{background-color:var(--colors-bigStone);display:block;height:100%;border-radius:var(--radii-1);transition:var(--transitions-main)}.c-fWgRbD a .inner{padding:var(--space-6)}.c-fWgRbD a:hover{background-color:var(--colors-bigStoneHover)}.c-fWgRbD img{display:block;border-radius:var(--radii-1) var(--radii-1) 0 0}@media (max-width: 1024px){.c-fWgRbD{width:calc((100% / 2) - 54px);margin-left:54px;margin-bottom:54px}}@media (max-width: 575px){.c-fWgRbD{width:100%;margin-left:0;margin-bottom:24px}}.c-gswrlc{padding:100px 0}.c-gswrlc .input{max-width:400px}@media (max-width: 1024px){.c-gswrlc{padding:80px 0;text-align:center}}@media (max-width: 1024px){.c-gswrlc .input{margin:0 auto}}@media (max-width: 743px){.c-gswrlc{padding:60px 0}}.c-jVwFOG{display:flex;align-items:center;justify-content:space-between}.c-eYYUfS{flex:1;margin-right:80px}@media (max-width: 1024px){.c-eYYUfS{margin-right:0}}.c-depOeu{position:relative;display:block}.c-depOeu .error-message{position:absolute;top:100%;transform:translateY(2px);color:var(--colors-danger);font-size:20px;padding-left: 12px}.c-depOeu input{border:none;border-radius:var(--radii-1);width:100%;transition:var(--transitions-main)}.c-dOghFk{flex:1}@media (max-width: 1024px){.c-dOghFk{display:none}}.c-ckoDwU{display:flex;flex:1;box-shadow:var(--shadows-4);border-radius:var(--radii-2);padding:var(--space-6);background-color:var(--colors-white)}.c-covwPd{margin-bottom:var(--space-6);padding-left:var(--space-5);list-style-type:disc;font-size:var(--fontSizes-2)}.c-covwPd li{color:var(--colors-secondary)}.c-covwPd li:not(:last-child){margin-bottom:var(--space-3)}.c-covwPd li span{color:var(--colors-black700)}.c-eGPXIo{color:var(--colors-white);background-color:var(--colors-darkBlue);padding-top:60px;padding-bottom:60px}@media (max-width: 743px){.c-eGPXIo{padding-top:40px;padding-bottom:40px}}.c-eGPXIo .logo{min-width:45px;width:45px;height:auto}.c-eGPXIo .org{padding-left:24px}.c-eGPXIo .org-name{display:flex;align-items:center;font-size:40px}@media (max-width: 743px){.c-eGPXIo .org-name p,.c-eGPXIo .org-name span{font-size:var(--fontSizes-5)}}.c-eGPXIo .org-name :not(span){color:var(--colors-primary)}.c-eGPXIo .org-name span{padding:0 8px}.c-eGPXIo .highlight{max-width:428px;width:100%}@media (max-width: 1024px){.c-eGPXIo .highlight{margin-top:30px}}.c-eGPXIo .highlight .hljs{margin-bottom:0}.c-jXNvwL{width:calc(100% - 286px);padding:0 30px;border-left:1px solid var(--colors-grey);border-right:1px solid var(--colors-grey)}@media (max-width: 1024px){.c-jXNvwL{width:100%;border:none;padding:0px}}.c-gDncai{margin:var(--space-10) auto;line-height:1.7}.c-gDncai h1,.c-gDncai h2,.c-gDncai h3,.c-gDncai h4,.c-gDncai h5,.c-gDncai h6{margin-top:var(--space-8);margin-bottom:var(--space-5)}.c-gDncai h1{font-size:var(--fontSizes-8);font-weight:var(--fontWeights-3);border-bottom:1px solid var(--colors-grey)}@media (max-width: 743px){.c-gDncai h1{font-size:var(--fontSizes-7)}}.c-gDncai h2{font-size:var(--fontSizes-7);font-weight:var(--fontWeights-3)}@media (max-width: 743px){.c-gDncai h2{font-size:var(--fontSizes-6)}}.c-gDncai h3{font-size:var(--fontSizes-6);font-weight:var(--fontWeights-3)}@media (max-width: 743px){.c-gDncai h3{font-size:var(--fontSizes-4)}}.c-gDncai p{margin-bottom:var(--space-5);font-size:var(--fontSizes-4);font-family:var(--fonts-Lora);color:var(--colors-black800)}.c-gDncai ol,.c-gDncai ul{margin-bottom:var(--space-5);padding-left:var(--space-10);font-size:var(--fontSizes-3);font-family:var(--fonts-Lora)}.c-gDncai ol li >ul,.c-gDncai ul li >ul{list-style-type:circle}.c-gDncai ol li:not(:last-child),.c-gDncai ul li:not(:last-child){margin-bottom:var(--space-2)}.c-gDncai ul{list-style-type:disc}.c-gDncai ul :has(input){list-style-type:none}.c-gDncai a{text-decoration:underline;word-break:break-all;font-family:var(--fonts-Lora)}.c-gDncai a:hover{color:var(--colors-primary)}.c-gDncai img{max-width:100%;height:auto}.c-gDncai strong{font-weight:var(--fontWeights-4)}.c-gDncai blockquote{padding-left:var(--space-9);border-left:2px solid var(--colors-grey);font-size:var(--fontSizes-2);font-style:italic}.c-gDncai em,.c-gDncai q{font-style:italic}.c-gDncai pre{font-size:var(--fontSizes-2);font-family:var(--fonts-Inconsolata);line-height:1.7;overflow:auto;white-space:pre;word-break:normal;margin:0 0 var(--space-5);padding:var(--space-10);color:var(--colors-darkGreyHover);background-color:var(--colors-lightGrey);border:none;border-radius:2px}.c-gDncai code{white-space:pre-wrap}.c-gDncai table{margin-bottom:var(--space-4)}.c-gDncai table,.c-gDncai th,.c-gDncai td{border:1px solid var(--colors-grey)}.c-gDncai th,.c-gDncai td{padding:6px 13px}.c-gDncai iframe{max-width:100%}.c-hhjAKd{width:286px;padding:30px;border-right:1px solid var(--colors-grey)}@media (max-width: 1024px){.c-hhjAKd{width:100%;border:none;padding:30px 0 0}}.c-bTiyxX{border-top:1px solid var(--colors-grey);margin-top:24px;padding-top:24px;padding-bottom:24px}@media (max-width: 1024px){.c-bTiyxX{border-bottom:1px solid var(--colors-grey)}}.c-cSRvhF{position:relative}.c-cSRvhF img{position:static !important}.c-cnJPJj{display:flex;justify-content:flex-end;margin-bottom:var(--space-10)}.c-cnJPJj button{height:40px;width:40px;background-color:var(--colors-lightGrey) !important;border-radius:var(--radii-1);margin-left:var(--space-3);transition:var(--transitions-main)}.c-cnJPJj button:hover[aria-label=twitter]{background-color:#43b1ff !important}.c-cnJPJj button:hover[aria-label=linkedin]{background-color:#0A66C2 !important}.c-cnJPJj button:hover[aria-label=facebook]{background-color:#6e8dd0 !important}.c-cnJPJj button:hover[aria-label=reddit]{background-color:#fb411c !important}.c-cnJPJj button:hover .icon{fill:var(--colors-white)}.c-bjrmKQ{padding:50px 0;border-top:2px solid var(--colors-lightGrey);border-bottom:2px solid var(--colors-lightGrey);margin-bottom:50px}.c-bjrmKQ a{transition:var(--transitions-main)}.c-bjrmKQ a .text,.c-bjrmKQ a .chevron-text{transition:var(--transitions-main)}.c-bjrmKQ a:hover .text{color:var(--colors-primary)}.c-hdKdh{flex:1;padding-right:var(--space-3);border-right:2px solid var(--colors-lightGrey)}.c-hdKdh a:hover .chevron-text{transform:translateX(15px)}@media (max-width: 743px){.c-hdKdh a:hover .chevron-text{transform:translateX(0)}}.c-eVsMjz{flex:1;text-align:right;padding-left:var(--space-3)}.c-eVsMjz a:hover .chevron-text{transform:translateX(-15px)}@media (max-width: 743px){.c-eVsMjz a:hover .chevron-text{transform:translateX(0)}}}--sxs{--sxs:3 c-PJLV-htjRrP-size-10 c-PJLV-dnvIlH-size-4 c-PJLV-ohsET-size-8 c-dhzjXW-ejCoEP-direction-row c-dhzjXW-jroWjL-align-center c-dhzjXW-awKDG-justify-start c-dhzjXW-kVNAnR-wrap-noWrap c-PJLV-ypqAk-size-3 c-bMqEGV-kwxnul-size-1 c-bMqEGV-dxfqfJ-variant-primary c-dhzjXW-iTKOFX-direction-column c-PJLV-cBLpOj-size-2 c-PJLV-EDrvg-size-1 c-dhzjXW-bICGYT-justify-center c-PJLV-hlFDyt-size-6 c-PJLV-iMgaFX-truncate-true c-PJLV-cllNQK-lineClamp-true c-PJLV-pmxQl-size-9 c-depOeu-RBfUm-size-1 c-dhzjXW-irEjuD-align-stretch c-dhzjXW-dOBaZS-gap-12 c-dhzjXW-knmidH-justify-between c-bMqEGV-jDfpYu-variant-secondary c-dhzjXW-eKWVTQ-gap-5 c-dhzjXW-kdofoX-gap-2 c-PJLV-jszWhv-size-7 c-dhzjXW-bZmKkd-justify-end}@media{.c-PJLV-htjRrP-size-10{font-size:var(--fontSizes-10);font-weight:var(--fontWeights-5);line-height:1.25}@media (max-width: 1024px){.c-PJLV-htjRrP-size-10{font-size:var(--fontSizes-8)}}@media (max-width: 743px){.c-PJLV-htjRrP-size-10{font-size:var(--fontSizes-7)}}.c-PJLV-dnvIlH-size-4{font-size:var(--fontSizes-4)}@media (max-width: 1024px){.c-PJLV-dnvIlH-size-4{font-size:var(--fontSizes-3)}}@media (max-width: 743px){.c-PJLV-dnvIlH-size-4{font-size:var(--fontSizes-2)}}.c-PJLV-ohsET-size-8{font-size:var(--fontSizes-8);font-weight:var(--fontWeights-5);line-height:1.5}@media (max-width: 743px){.c-PJLV-ohsET-size-8{font-size:var(--fontSizes-7)}}.c-dhzjXW-ejCoEP-direction-row{flex-direction:row}.c-dhzjXW-jroWjL-align-center{align-items:center}.c-dhzjXW-awKDG-justify-start{justify-content:flex-start}.c-dhzjXW-kVNAnR-wrap-noWrap{flex-wrap:nowrap}.c-PJLV-ypqAk-size-3{font-size:var(--fontSizes-3)}@media (max-width: 743px){.c-PJLV-ypqAk-size-3{font-size:var(--fontSizes-2)}}.c-bMqEGV-kwxnul-size-1{height:53px;line-height:53px;font-size:var(--fontSizes-3);padding-left:var(--space-6);padding-right:var(--space-6)}@media (max-width: 1024px){.c-bMqEGV-kwxnul-size-1{height:50px;line-height:50px}}.c-bMqEGV-dxfqfJ-variant-primary{background-color:var(--colors-primary);color:var(--colors-white)}.c-bMqEGV-dxfqfJ-variant-primary:hover{background-color:var(--colors-primaryHover)}.c-dhzjXW-iTKOFX-direction-column{flex-direction:column}.c-PJLV-cBLpOj-size-2{font-size:var(--fontSizes-2)}.c-PJLV-EDrvg-size-1{font-size:var(--fontSizes-1)}.c-dhzjXW-bICGYT-justify-center{justify-content:center}.c-PJLV-hlFDyt-size-6{font-size:var(--fontSizes-6);font-weight:var(--fontWeights-3)}@media (max-width: 743px){.c-PJLV-hlFDyt-size-6{font-size:var(--fontSizes-4)}}.c-PJLV-iMgaFX-truncate-true{max-width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.c-PJLV-cllNQK-lineClamp-true{display:-webkit-box;-webkit-line-clamp:var(---lineClamp);-webkit-box-orient:vertical;overflow:hidden}.c-PJLV-pmxQl-size-9{font-size:var(--fontSizes-9);font-weight:var(--fontWeights-5);line-height:1.1}@media (max-width: 1024px){.c-PJLV-pmxQl-size-9{font-size:var(--fontSizes-8)}}@media (max-width: 743px){.c-PJLV-pmxQl-size-9{font-size:var(--fontSizes-7)}}.c-depOeu-RBfUm-size-1 input{padding:17px 24px;font-size:var(--fontSizes-2);background-color:var(--colors-lightGrey)}.c-depOeu-RBfUm-size-1 input:hover{background-color:var(--colors-lightGreyHover)}.c-dhzjXW-irEjuD-align-stretch{align-items:stretch}.c-dhzjXW-dOBaZS-gap-12{gap:var(--space-12)}.c-dhzjXW-knmidH-justify-between{justify-content:space-between}.c-bMqEGV-jDfpYu-variant-secondary{background-color:var(--colors-primaryLight);color:var(--colors-primary)}.c-bMqEGV-jDfpYu-variant-secondary:hover{background-color:var(--colors-primaryLightHover)}.c-dhzjXW-eKWVTQ-gap-5{gap:var(--space-5)}.c-dhzjXW-kdofoX-gap-2{gap:var(--space-2)}.c-PJLV-jszWhv-size-7{font-size:var(--fontSizes-7);font-weight:var(--fontWeights-2)}@media (max-width: 743px){.c-PJLV-jszWhv-size-7{font-size:var(--fontSizes-6)}}.c-dhzjXW-bZmKkd-justify-end{justify-content:flex-end}}--sxs{--sxs:4 c-dhzjXW-lelvPF-direction-columnReverse c-dhzjXW-cLKPGv-direction-row c-dhzjXW-ewYpoe-align-start c-dhzjXW-dAvekr-direction-column c-dhzjXW-dHjzmU-direction-column}@media{@media (max-width: 1024px){.c-dhzjXW-lelvPF-direction-columnReverse{flex-direction:column-reverse}}@media (max-width: 743px){.c-dhzjXW-cLKPGv-direction-row{flex-direction:row}}@media (max-width: 743px){.c-dhzjXW-ewYpoe-align-start{align-items:flex-start}}@media (max-width: 743px){.c-dhzjXW-dAvekr-direction-column{flex-direction:column}}@media (max-width: 1024px){.c-dhzjXW-dHjzmU-direction-column{flex-direction:column}}}--sxs{--sxs:6 c-hCkBfr-ilkBNdM-css c-kPczbf-igSvvfr-css c-kPczbf-idOghFk-css c-fOPBY-ieBuAdh-css c-PJLV-ietOTGQ-css c-hCkBfr-ibrRWTZ-css c-hCkBfr-ikYMMba-css c-PJLV-igHOLBX-css c-PJLV-ijskIFF-css c-PJLV-ijpcBqa-css c-bMqEGV-icBLpOj-css c-hJzboU-ieOwGK-css c-PJLV-idgasAY-css c-PJLV-ieFlRcC-css c-PJLV-iciGHnC-css c-hJzboU-icdsEyN-css c-hJzboU-iYSetQ-css c-hJzboU-iebhThe-css c-hJzboU-ifZMaZh-css c-hJzboU-ieVlAUk-css c-dhzjXW-iguWOGj-css c-PJLV-ieRZfPH-css c-PJLV-iUazGY-css c-PJLV-ikMWyde-css c-PJLV-iedNKou-css c-bMqEGV-idKitzl-css c-PJLV-ijfuMJQ-css c-PJLV-ieBSoMY-css c-PJLV-iiMrHxl-css c-cQwwIn-ihZnFyC-css c-PJLV-igjdJOs-css c-PJLV-ieNyba-css c-PJLV-ibZBPXN-css c-PJLV-iejLhMq-css c-bMqEGV-igyJvzA-css c-dhzjXW-ielgvHS-css c-dhzjXW-ieHGUxU-css c-dhzjXW-iejLhMq-css c-PJLV-idHAijf-css c-PJLV-ieXfYvc-css c-PJLV-ijoSYcG-css c-PJLV-ihjojsL-css c-PJLV-ikGRPtV-css c-PJLV-ignELVg-css c-dhzjXW-icNlJTv-css c-dhzjXW-igyJvzA-css c-PJLV-ikaqJbg-css c-PJLV-idnFJmc-css}@media{.c-hCkBfr-ilkBNdM-css{height:100%}.c-kPczbf-igSvvfr-css{display:none}@media (max-width: 1024px){.c-kPczbf-igSvvfr-css{display:block;padding:var(--space-5)}}.c-kPczbf-idOghFk-css{flex:1}@media (max-width: 1024px){.c-kPczbf-idOghFk-css{display:none}}.c-fOPBY-ieBuAdh-css{margin-left:auto;padding:var(--space-3)}.c-PJLV-ietOTGQ-css{margin-bottom:var(--space-6)}.c-hCkBfr-ibrRWTZ-css{max-width:848px}.c-hCkBfr-ikYMMba-css{position:relative;z-index:2}@media (max-width: 1024px){.c-PJLV-igHOLBX-css{text-align:center}}.c-PJLV-ijskIFF-css{font-weight:var(--fontWeights-3);padding:var(--space-3) 0 var(--space-2)}.c-PJLV-ijpcBqa-css{color:var(--colors-white700)}.c-bMqEGV-icBLpOj-css{font-size:var(--fontSizes-2)}.c-hJzboU-ieOwGK-css{-webkit-mask-image:url(/images/static/about-us/shapes/1.svg);mask-image:url(/images/static/about-us/shapes/1.svg)}.c-PJLV-idgasAY-css{font-weight:var(--fontWeights-4)}.c-PJLV-ieFlRcC-css{padding-top:var(--space-2);padding-bottom:var(--space-2);font-weight:var(--fontWeights-3)}.c-PJLV-iciGHnC-css{color:var(--colors-black700)}.c-hJzboU-icdsEyN-css{-webkit-mask-image:url(/images/static/about-us/shapes/2.svg);mask-image:url(/images/static/about-us/shapes/2.svg)}.c-hJzboU-iYSetQ-css{-webkit-mask-image:url(/images/static/about-us/shapes/3.svg);mask-image:url(/images/static/about-us/shapes/3.svg)}.c-hJzboU-iebhThe-css{-webkit-mask-image:url(/images/static/about-us/shapes/5.svg);mask-image:url(/images/static/about-us/shapes/5.svg)}.c-hJzboU-ifZMaZh-css{-webkit-mask-image:url(/images/static/about-us/shapes/6.svg);mask-image:url(/images/static/about-us/shapes/6.svg)}.c-hJzboU-ieVlAUk-css{-webkit-mask-image:url(/images/static/about-us/shapes/7.svg);mask-image:url(/images/static/about-us/shapes/7.svg)}.c-dhzjXW-iguWOGj-css{height:100vh}.c-PJLV-ieRZfPH-css{text-align:center;margin-top:var(--space-10);margin-bottom:var(--space-10)}.c-PJLV-iUazGY-css{display:flex;align-items:center}.c-PJLV-ikMWyde-css{margin-top:var(--space-6);margin-bottom:var(--space-6);---lineClamp:3;font-family:var(--fonts-Lora)}.c-PJLV-iedNKou-css{margin-bottom:48px}.c-bMqEGV-idKitzl-css{margin-bottom:var(--space-12)}.c-PJLV-ijfuMJQ-css{opacity:0;transition:var(--transitions-main)}.c-PJLV-ieBSoMY-css span{background-color:var(--colors-secondary);color:var(--colors-white)}.c-PJLV-iiMrHxl-css{margin-bottom:var(--space-6)}.c-PJLV-iiMrHxl-css strong{font-weight:var(--fontWeights-5)}.c-cQwwIn-ihZnFyC-css{margin-top:var(--space-6);font-weight:var(--fontWeights-3)}.c-PJLV-igjdJOs-css{text-align:center}.c-PJLV-ieNyba-css{margin:0 auto 60px;text-align:center;max-width:560px}@media (max-width: 1024px){.c-PJLV-ieNyba-css{margin-bottom:44px}}.c-PJLV-ibZBPXN-css{margin-bottom:var(--space-2);font-weight:var(--fontWeights-4)}.c-PJLV-iejLhMq-css{margin-bottom:var(--space-4)}.c-bMqEGV-igyJvzA-css{margin-top:var(--space-6)}.c-dhzjXW-ielgvHS-css{padding-top:80px;padding-bottom:80px}.c-dhzjXW-ieHGUxU-css{padding-bottom:104px}.c-dhzjXW-iejLhMq-css{margin-bottom:var(--space-4)}.c-PJLV-idHAijf-css{font-weight:var(--fontWeights-4);margin-left:var(--space-4)}.c-PJLV-ieXfYvc-css{margin-bottom:var(--space-5);color:var(--colors-black700)}.c-PJLV-ijoSYcG-css{margin-bottom:var(--space-6);font-weight:var(--fontWeights-3)}.c-PJLV-ihjojsL-css{font-weight:var(--fontWeights-3)}.c-PJLV-ikGRPtV-css{font-weight:var(--fontWeights-5)}.c-PJLV-ignELVg-css{font-weight:var(--fontWeights-3);padding-bottom:var(--space-3)}.c-dhzjXW-icNlJTv-css{margin-top:var(--space-10)}.c-dhzjXW-igyJvzA-css{margin-top:var(--space-6)}.c-PJLV-ikaqJbg-css{margin-top:var(--space-6);margin-bottom:var(--space-6);font-weight:var(--fontWeights-4)}.c-PJLV-idnFJmc-css{margin-top:var(--space-3);---lineClamp:2}}</style><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d52c472f627fec66.js" defer=""></script><script src="/_next/static/chunks/framework-ffee79c6390da51e.js" defer=""></script><script src="/_next/static/chunks/main-12fb79ef298a4077.js" defer=""></script><script src="/_next/static/chunks/pages/_app-e32acc6a00dab660.js" defer=""></script><script src="/_next/static/chunks/962-0a950ce516e89aa5.js" defer=""></script><script src="/_next/static/chunks/pages/category/%5Bslug%5D-3928e37e2476d73f.js" defer=""></script><script src="/_next/static/E4IpcvEwpq4T12cZyRpo4/_buildManifest.js" defer=""></script><script src="/_next/static/E4IpcvEwpq4T12cZyRpo4/_ssgManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Inconsolata&family=Lora&family=Open+Sans:wght@400;500;600;700;800&display=swap">@font-face{font-family:'Inconsolata';font-style:normal;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/inconsolata/v31/QldgNThLqRwH-OJ1UHjlKENVzkWGVkL3GZQmAwLYxYWI2qfdm7Lpp4U8aRk.woff) format('woff')}@font-face{font-family:'Lora';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/lora/v26/0QI6MX1D_JOuGQbT0gvTJPa787weuyJF.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjZ0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjr0C4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:600;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsgH1y4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsg-1y4k.woff) format('woff')}@font-face{font-family:'Open Sans';font-style:normal;font-weight:800;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgshZ1y4k.woff) format('woff')}@font-face{font-family:'Inconsolata';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/inconsolata/v31/QldgNThLqRwH-OJ1UHjlKENVzkWGVkL3GZQmAwLYxYWI2qfdm7Lpp4U8WRL2kXWdycuJDETf.woff) format('woff');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inconsolata';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/inconsolata/v31/QldgNThLqRwH-OJ1UHjlKENVzkWGVkL3GZQmAwLYxYWI2qfdm7Lpp4U8WRP2kXWdycuJDETf.woff) format('woff');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inconsolata';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/inconsolata/v31/QldgNThLqRwH-OJ1UHjlKENVzkWGVkL3GZQmAwLYxYWI2qfdm7Lpp4U8WR32kXWdycuJDA.woff) format('woff');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Lora';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/lora/v26/0QI6MX1D_JOuGQbT0gvTJPa787weuxJMkqt8ndeYxZ2JTg.woff) format('woff');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Lora';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/lora/v26/0QI6MX1D_JOuGQbT0gvTJPa787weuxJFkqt8ndeYxZ2JTg.woff) format('woff');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Lora';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/lora/v26/0QI6MX1D_JOuGQbT0gvTJPa787weuxJOkqt8ndeYxZ2JTg.woff) format('woff');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Lora';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/lora/v26/0QI6MX1D_JOuGQbT0gvTJPa787weuxJPkqt8ndeYxZ2JTg.woff) format('woff');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Lora';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/lora/v26/0QI6MX1D_JOuGQbT0gvTJPa787weuxJBkqt8ndeYxZ0.woff) format('woff');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:600;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:600;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:600;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:600;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:600;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:600;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:600;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:600;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Open Sans';font-style:normal;font-weight:800;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSKmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:800;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSumu0SC55K5gw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Open Sans';font-style:normal;font-weight:800;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSOmu0SC55K5gw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:800;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSymu0SC55K5gw.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:800;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS2mu0SC55K5gw.woff2) format('woff2');unicode-range:U+0590-05FF,U+200C-2010,U+20AA,U+25CC,U+FB1D-FB4F}@font-face{font-family:'Open Sans';font-style:normal;font-weight:800;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSCmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Open Sans';font-style:normal;font-weight:800;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTSGmu0SC55K5gw.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Open Sans';font-style:normal;font-weight:800;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/opensans/v34/memvYaGs126MiZpBA-UvWbX2vVnXBbObj2OVTS-mu0SC55I.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><main class="c-iSkjJi"><div class="c-guYHoi"><header class="c-fnKlzS"><div class="c-hCkBfr c-hCkBfr-ilkBNdM-css"><div class="c-ePqJJt"><div class="c-kFnRKY"><a class="logo" href="/"><img alt="AimStack" srcSet="/_next/static/chunks/images/images/static/main/logo_256_75.svg 1x, /_next/static/chunks/images/images/static/main/logo_384_75.svg 2x" src="/_next/static/chunks/images/images/static/main/logo_384_75.svg" width="156" height="37" decoding="async" data-nimg="1" loading="lazy" style="color:transparent"/></a></div><nav class="c-lmSDjj"><div class="nav-inner"><ul class="nav-list"><li><a target="_self" class="" href="/#quick-start"><span class="text">Quick start</span></a></li><li><a target="_self" class="" href="/#features"><span class="text">Features</span></a></li><li><a target="_self" class="" href="/#demos"><span class="text">Demos</span></a></li><li><a target="_blank" class="" href="https://aimstack.readthedocs.io/en/latest/"><span class="text">Docs</span></a></li><li><a target="_self" class="" href="/pricing"><span class="text">Pricing</span></a></li><li><a target="_self" class="" href="/blog"><span class="text">Blog</span></a></li><li><a target="_self" class="" href="/about-us"><span class="text">About Us</span></a></li><li><a target="_blank" class="" href="/category/test#"><span class="text">Career</span><span class="badge">Hiring</span></a></li></ul><div class="c-kPczbf c-kPczbf-igSvvfr-css"><span><a href="https://github.com/aimhubio/aim" data-size="large" data-show-count="true" aria-label="Star aimhubio/aim on GitHub" data-text="Star"></a></span></div></div><ul class="c-lizetl"><li><a href="https://aimstack.slack.com/ssb/redirect#/shared-invite/email" rel="noopener noreferrer" target="_blank" aria-label="slack"><svg class="icon " style="display:inline-block;vertical-align:middle" width="20" height="20" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M380.907 539.056c-57.742 0-104.574 46.837-104.574 104.585v261.609c0 57.748 46.832 104.585 104.574 104.585s104.574-46.837 104.574-104.585v-261.609c-0.042-57.748-46.874-104.585-104.574-104.585z"></path><path d="M15.111 643.63c0 57.799 46.874 104.687 104.659 104.687s104.659-46.888 104.659-104.687v-104.685h-104.577c-0.042 0-0.042 0-0.082 0-57.785 0-104.659 46.886-104.659 104.685z"></path><path d="M381.003 14.167c-0.042 0-0.083 0-0.125 0-57.783 0-104.656 46.886-104.656 104.684s46.874 104.685 104.656 104.685h104.574v-104.685c0-0.041 0-0.124 0-0.207-0.042-57.715-46.791-104.477-104.449-104.477z"></path><path d="M118.88 485.95h262.080c57.784 0 104.657-46.892 104.657-104.697s-46.874-104.697-104.657-104.697h-262.080c-57.784 0-104.658 46.892-104.658 104.697s46.874 104.697 104.658 104.697z"></path><path d="M904.118 276.5c-57.702 0-104.454 46.767-104.454 104.49v104.905h104.573c57.788 0 104.658-46.892 104.658-104.698s-46.871-104.697-104.658-104.697c-0.040 0-0.080 0-0.119 0z"></path><path d="M538.444 118.795v262.365c0 57.741 46.834 104.573 104.577 104.573 57.737 0 104.573-46.832 104.573-104.573v-262.365c0-57.741-46.837-104.573-104.573-104.573-57.742 0-104.577 46.832-104.577 104.573z"></path><path d="M747.594 905.028c0-57.748-46.837-104.585-104.573-104.585h-104.577v104.67c0.042 57.702 46.834 104.499 104.577 104.499 57.737 0 104.573-46.837 104.573-104.585z"></path><path d="M905.068 538.944h-262.076c-57.788 0-104.659 46.886-104.659 104.685s46.871 104.687 104.659 104.687h262.076c57.788 0 104.658-46.888 104.658-104.687s-46.871-104.685-104.658-104.685z"></path></svg></a></li><li><a href="https://twitter.com/aimstackio" rel="noopener noreferrer" target="_blank" aria-label="twitter"><svg class="icon " style="display:inline-block;vertical-align:middle" width="20" height="20" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M322.14 927.976c386.322 0 597.681-320.14 597.681-597.678 0-9-0.199-18.2-0.604-27.2 41.116-29.734 76.601-66.565 104.782-108.76-38.292 17.037-78.95 28.164-120.579 33 43.833-26.275 76.654-67.553 92.381-116.18-41.24 24.439-86.339 41.679-133.363 50.98-31.685-33.666-73.577-55.957-119.199-63.427s-92.44 0.299-133.206 22.103c-40.766 21.805-73.211 56.432-92.324 98.527s-23.826 89.314-13.411 134.357c-83.5-4.19-165.188-25.881-239.767-63.667s-140.386-90.823-193.153-155.673c-26.819 46.239-35.025 100.955-22.952 153.027s43.521 97.594 87.952 127.313c-33.356-1.059-65.981-10.040-95.18-26.2v2.6c-0.030 48.525 16.745 95.562 47.475 133.116 30.729 37.552 73.515 63.309 121.085 72.886-30.899 8.451-63.328 9.685-94.78 3.6 13.424 41.731 39.54 78.228 74.706 104.405 35.166 26.171 77.626 40.712 121.454 41.591-74.408 58.449-166.322 90.155-260.94 90.004-16.78-0.027-33.543-1.056-50.2-3.083 96.122 61.666 207.937 94.424 322.14 94.359z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/aimstackio/" rel="noopener noreferrer" target="_blank" aria-label="linkedIn"><svg class="icon " style="display:inline-block;vertical-align:middle" width="20" height="20" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M948.201 0h-872.601c-41.8 0-75.6 33-75.6 73.8v876.199c0 40.801 33.8 74.001 75.6 74.001h872.601c41.796 0 75.799-33.2 75.799-73.802v-876.398c0-40.8-34.002-73.8-75.799-73.8zM303.8 872.602h-152v-488.802h152v488.802zM227.8 317.2c-48.8 0-88.2-39.4-88.2-88s39.4-88 88.2-88c48.6 0 88 39.4 88 88 0 48.4-39.4 88-88 88zM872.602 872.602h-151.802v-237.602c0-56.599-1.001-129.6-79.002-129.6-78.998 0-90.998 61.8-90.998 125.6v241.601h-151.6v-488.802h145.6v66.8h2c20.2-38.4 69.802-79 143.598-79 153.805 0 182.204 101.2 182.204 232.799v268.203z"></path></svg></a></li><li><a href="https://www.facebook.com/aimstackio" rel="noopener noreferrer" target="_blank" aria-label="fb"><svg class="icon " style="display:inline-block;vertical-align:middle" width="20" height="20" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M1024 512c0-282.77-229.228-512-512-512-282.77 0-512 229.23-512 512 0 255.551 187.23 467.371 432 505.782v-357.78h-130v-148.002h130v-112.8c0-128.32 76.44-199.2 193.391-199.2 56.001 0 114.608 10 114.608 10v126h-64.558c-63.602 0-83.445 39.47-83.445 80v96h142l-22.699 148.002h-119.302v357.78c244.77-38.411 432.003-250.231 432.003-505.782z"></path></svg></a></li></ul></nav><div class="c-kPczbf c-kPczbf-idOghFk-css desktop-btn"><span><a href="https://github.com/aimhubio/aim" data-size="large" data-show-count="true" aria-label="Star aimhubio/aim on GitHub" data-text="Star"></a></span></div><button type="button" aria-label="menu" class="c-fOPBY c-fOPBY-ieBuAdh-css"><svg class="icon " style="display:inline-block;vertical-align:middle" width="20" height="20" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path style="fill:black" d="M0 146.286c0-33.663 27.289-60.952 60.952-60.952h902.097c33.661 0 60.951 27.289 60.951 60.952s-27.29 60.952-60.951 60.952h-902.097c-33.663 0-60.952-27.29-60.952-60.952zM0 512.008c0-33.663 27.289-60.952 60.952-60.952h902.097c33.661 0 60.951 27.29 60.951 60.952s-27.29 60.952-60.951 60.952h-902.097c-33.663 0-60.952-27.29-60.952-60.952zM60.952 816.748c-33.663 0-60.952 27.29-60.952 60.956 0 33.661 27.289 60.951 60.952 60.951h902.097c33.661 0 60.951-27.29 60.951-60.951 0-33.667-27.29-60.956-60.951-60.956h-902.097z"></path></svg></button></div></div></header><div class="c-jCnBs"><div class="c-hCkBfr"><h1 class="c-PJLV c-PJLV-hlFDyt-size-6 c-PJLV-ieRZfPH-css title">Category: <!-- -->Test</h1><ul class="c-jcfAOr"><li class="c-jYGtqD"><div class="c-PJLV"><div class="c-fKjLcl"><a href="/blog/post-with-new-markdown"><img alt="post with new markdown" sizes="100vw" srcSet="/_next/static/chunks/images/images/dynamic/video-thumbnail_640_75.webp 640w, /_next/static/chunks/images/images/dynamic/video-thumbnail_750_75.webp 750w, /_next/static/chunks/images/images/dynamic/video-thumbnail_828_75.webp 828w, /_next/static/chunks/images/images/dynamic/video-thumbnail_1080_75.webp 1080w, /_next/static/chunks/images/images/dynamic/video-thumbnail_1200_75.webp 1200w, /_next/static/chunks/images/images/dynamic/video-thumbnail_1920_75.webp 1920w, /_next/static/chunks/images/images/dynamic/video-thumbnail_2048_75.webp 2048w, /_next/static/chunks/images/images/dynamic/video-thumbnail_3840_75.webp 3840w" src="/_next/static/chunks/images/images/dynamic/video-thumbnail_3840_75.webp" decoding="async" data-nimg="fill" loading="lazy" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:top;color:transparent"/></a></div><div class="c-kKhLoP"><div class="c-gRRuTe"><a href="/category/test"><p class="c-PJLV c-PJLV-EDrvg-size-1 c-PJLV-iUazGY-css"><svg class="icon " style="display:inline-block;vertical-align:middle" width="14" height="14" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M877.67 862.925h-771.994c8.090-21.811 16.077-43.52 24.166-65.229 39.834-106.086 80.077-212.070 119.194-318.362 13.722-37.171 57.549-63.795 91.546-63.693 209.306 0.922 418.611 0.717 627.917 0.205 23.654-0.102 41.984 5.939 52.838 28.16 2.662 7.68 4.403 13.517 0 25.907-47.206 129.638-96.563 263.373-143.667 393.011zM321.126 160.768c1.024 3.072 1.638 6.246 3.072 9.114 18.33 36.864 36.864 73.523 54.989 110.49 3.072 6.246 6.656 8.294 13.517 8.294 146.227-0.205 292.557-0.205 438.784-0.205 30.003 0 56.422 22.323 61.645 52.122 0.614 3.482 0 7.168 0 11.674h-12.186c-178.176 0-356.25-0.102-534.426 0-62.362 0.102-111.104 26.726-143.667 79.667-11.162 18.125-17.613 39.219-25.19 59.392-37.478 99.43-74.752 199.066-111.821 298.803-2.97 7.987-6.554 9.933-14.541 7.987-24.576-6.144-48.845-26.010-51.302-48.947v-538.522c0-46.592 34.406-49.869 49.869-49.869h271.258z"></path></svg>test</p></a></div><h3 class="c-PJLV c-PJLV-hlFDyt-size-6 c-PJLV-iMgaFX-truncate-true title"><a href="/blog/post-with-new-markdown">post with new markdown</a></h3><p class="c-PJLV c-PJLV-cBLpOj-size-2 c-PJLV-cllNQK-lineClamp-true c-PJLV-ikMWyde-css title"><a href="/blog/post-with-new-markdown">description</a></p><div class="c-hnRRWM"></div></div></div></li><li class="c-jYGtqD"><div class="c-PJLV"><div class="c-fKjLcl"><a href="/blog/new-post"><img alt="New Post" sizes="100vw" srcSet="/_next/static/chunks/images/images/dynamic/aim-logo_640_75.svg 640w, /_next/static/chunks/images/images/dynamic/aim-logo_750_75.svg 750w, /_next/static/chunks/images/images/dynamic/aim-logo_828_75.svg 828w, /_next/static/chunks/images/images/dynamic/aim-logo_1080_75.svg 1080w, /_next/static/chunks/images/images/dynamic/aim-logo_1200_75.svg 1200w, /_next/static/chunks/images/images/dynamic/aim-logo_1920_75.svg 1920w, /_next/static/chunks/images/images/dynamic/aim-logo_2048_75.svg 2048w, /_next/static/chunks/images/images/dynamic/aim-logo_3840_75.svg 3840w" src="/_next/static/chunks/images/images/dynamic/aim-logo_3840_75.svg" decoding="async" data-nimg="fill" loading="lazy" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:top;color:transparent"/></a></div><div class="c-kKhLoP"><div class="c-gRRuTe"><a href="/category/test"><p class="c-PJLV c-PJLV-EDrvg-size-1 c-PJLV-iUazGY-css"><svg class="icon " style="display:inline-block;vertical-align:middle" width="14" height="14" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M877.67 862.925h-771.994c8.090-21.811 16.077-43.52 24.166-65.229 39.834-106.086 80.077-212.070 119.194-318.362 13.722-37.171 57.549-63.795 91.546-63.693 209.306 0.922 418.611 0.717 627.917 0.205 23.654-0.102 41.984 5.939 52.838 28.16 2.662 7.68 4.403 13.517 0 25.907-47.206 129.638-96.563 263.373-143.667 393.011zM321.126 160.768c1.024 3.072 1.638 6.246 3.072 9.114 18.33 36.864 36.864 73.523 54.989 110.49 3.072 6.246 6.656 8.294 13.517 8.294 146.227-0.205 292.557-0.205 438.784-0.205 30.003 0 56.422 22.323 61.645 52.122 0.614 3.482 0 7.168 0 11.674h-12.186c-178.176 0-356.25-0.102-534.426 0-62.362 0.102-111.104 26.726-143.667 79.667-11.162 18.125-17.613 39.219-25.19 59.392-37.478 99.43-74.752 199.066-111.821 298.803-2.97 7.987-6.554 9.933-14.541 7.987-24.576-6.144-48.845-26.010-51.302-48.947v-538.522c0-46.592 34.406-49.869 49.869-49.869h271.258z"></path></svg>test</p></a></div><h3 class="c-PJLV c-PJLV-hlFDyt-size-6 c-PJLV-iMgaFX-truncate-true title"><a href="/blog/new-post">New Post</a></h3><p class="c-PJLV c-PJLV-cBLpOj-size-2 c-PJLV-cllNQK-lineClamp-true c-PJLV-ikMWyde-css title"><a href="/blog/new-post">very short description</a></p><div class="c-hnRRWM"></div></div></div></li><li class="c-jYGtqD"><div class="c-PJLV"><div class="c-fKjLcl"><a href="/blog/test-image-path"><img alt="Test image path" sizes="100vw" srcSet="/_next/static/chunks/images/images/blog/sum_640_75.webp 640w, /_next/static/chunks/images/images/blog/sum_750_75.webp 750w, /_next/static/chunks/images/images/blog/sum_828_75.webp 828w, /_next/static/chunks/images/images/blog/sum_1080_75.webp 1080w, /_next/static/chunks/images/images/blog/sum_1200_75.webp 1200w, /_next/static/chunks/images/images/blog/sum_1920_75.webp 1920w, /_next/static/chunks/images/images/blog/sum_2048_75.webp 2048w, /_next/static/chunks/images/images/blog/sum_3840_75.webp 3840w" src="/_next/static/chunks/images/images/blog/sum_3840_75.webp" decoding="async" data-nimg="fill" loading="lazy" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:top;color:transparent"/></a></div><div class="c-kKhLoP"><div class="c-gRRuTe"><a href="/category/test"><p class="c-PJLV c-PJLV-EDrvg-size-1 c-PJLV-iUazGY-css"><svg class="icon " style="display:inline-block;vertical-align:middle" width="14" height="14" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M877.67 862.925h-771.994c8.090-21.811 16.077-43.52 24.166-65.229 39.834-106.086 80.077-212.070 119.194-318.362 13.722-37.171 57.549-63.795 91.546-63.693 209.306 0.922 418.611 0.717 627.917 0.205 23.654-0.102 41.984 5.939 52.838 28.16 2.662 7.68 4.403 13.517 0 25.907-47.206 129.638-96.563 263.373-143.667 393.011zM321.126 160.768c1.024 3.072 1.638 6.246 3.072 9.114 18.33 36.864 36.864 73.523 54.989 110.49 3.072 6.246 6.656 8.294 13.517 8.294 146.227-0.205 292.557-0.205 438.784-0.205 30.003 0 56.422 22.323 61.645 52.122 0.614 3.482 0 7.168 0 11.674h-12.186c-178.176 0-356.25-0.102-534.426 0-62.362 0.102-111.104 26.726-143.667 79.667-11.162 18.125-17.613 39.219-25.19 59.392-37.478 99.43-74.752 199.066-111.821 298.803-2.97 7.987-6.554 9.933-14.541 7.987-24.576-6.144-48.845-26.010-51.302-48.947v-538.522c0-46.592 34.406-49.869 49.869-49.869h271.258z"></path></svg>Test</p></a></div><h3 class="c-PJLV c-PJLV-hlFDyt-size-6 c-PJLV-iMgaFX-truncate-true title"><a href="/blog/test-image-path">Test image path</a></h3><p class="c-PJLV c-PJLV-cBLpOj-size-2 c-PJLV-cllNQK-lineClamp-true c-PJLV-ikMWyde-css title"><a href="/blog/test-image-path">test post</a></p><div class="c-hnRRWM"></div></div></div></li><li class="c-jYGtqD"><div class="c-PJLV"><div class="c-fKjLcl"><a href="/blog/done"><img alt="DONE" sizes="100vw" srcSet="/_next/static/chunks/images/images/group-580_640_75.webp 640w, /_next/static/chunks/images/images/group-580_750_75.webp 750w, /_next/static/chunks/images/images/group-580_828_75.webp 828w, /_next/static/chunks/images/images/group-580_1080_75.webp 1080w, /_next/static/chunks/images/images/group-580_1200_75.webp 1200w, /_next/static/chunks/images/images/group-580_1920_75.webp 1920w, /_next/static/chunks/images/images/group-580_2048_75.webp 2048w, /_next/static/chunks/images/images/group-580_3840_75.webp 3840w" src="/_next/static/chunks/images/images/group-580_3840_75.webp" decoding="async" data-nimg="fill" loading="lazy" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:top;color:transparent"/></a></div><div class="c-kKhLoP"><div class="c-gRRuTe"><a href="/category/test"><p class="c-PJLV c-PJLV-EDrvg-size-1 c-PJLV-iUazGY-css"><svg class="icon " style="display:inline-block;vertical-align:middle" width="14" height="14" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M877.67 862.925h-771.994c8.090-21.811 16.077-43.52 24.166-65.229 39.834-106.086 80.077-212.070 119.194-318.362 13.722-37.171 57.549-63.795 91.546-63.693 209.306 0.922 418.611 0.717 627.917 0.205 23.654-0.102 41.984 5.939 52.838 28.16 2.662 7.68 4.403 13.517 0 25.907-47.206 129.638-96.563 263.373-143.667 393.011zM321.126 160.768c1.024 3.072 1.638 6.246 3.072 9.114 18.33 36.864 36.864 73.523 54.989 110.49 3.072 6.246 6.656 8.294 13.517 8.294 146.227-0.205 292.557-0.205 438.784-0.205 30.003 0 56.422 22.323 61.645 52.122 0.614 3.482 0 7.168 0 11.674h-12.186c-178.176 0-356.25-0.102-534.426 0-62.362 0.102-111.104 26.726-143.667 79.667-11.162 18.125-17.613 39.219-25.19 59.392-37.478 99.43-74.752 199.066-111.821 298.803-2.97 7.987-6.554 9.933-14.541 7.987-24.576-6.144-48.845-26.010-51.302-48.947v-538.522c0-46.592 34.406-49.869 49.869-49.869h271.258z"></path></svg>test</p></a></div><h3 class="c-PJLV c-PJLV-hlFDyt-size-6 c-PJLV-iMgaFX-truncate-true title"><a href="/blog/done">DONE</a></h3><p class="c-PJLV c-PJLV-cBLpOj-size-2 c-PJLV-cllNQK-lineClamp-true c-PJLV-ikMWyde-css title"><a href="/blog/done">aaaa</a></p><div class="c-hnRRWM"></div></div></div></li><li class="c-jYGtqD"><div class="c-PJLV"><div class="c-fKjLcl"><a href="/blog/check-image-functinalty-working-or-not"><img alt="Check image functinalty working or not" sizes="100vw" srcSet="/_next/static/chunks/images/images/butterfly-7353884_960_720_640_75.webp 640w, /_next/static/chunks/images/images/butterfly-7353884_960_720_750_75.webp 750w, /_next/static/chunks/images/images/butterfly-7353884_960_720_828_75.webp 828w, /_next/static/chunks/images/images/butterfly-7353884_960_720_1080_75.webp 1080w, /_next/static/chunks/images/images/butterfly-7353884_960_720_1200_75.webp 1200w, /_next/static/chunks/images/images/butterfly-7353884_960_720_1920_75.webp 1920w, /_next/static/chunks/images/images/butterfly-7353884_960_720_2048_75.webp 2048w, /_next/static/chunks/images/images/butterfly-7353884_960_720_3840_75.webp 3840w" src="/_next/static/chunks/images/images/butterfly-7353884_960_720_3840_75.webp" decoding="async" data-nimg="fill" loading="lazy" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:top;color:transparent"/></a></div><div class="c-kKhLoP"><div class="c-gRRuTe"><a href="/category/react"><p class="c-PJLV c-PJLV-EDrvg-size-1 c-PJLV-iUazGY-css"><svg class="icon " style="display:inline-block;vertical-align:middle" width="14" height="14" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M877.67 862.925h-771.994c8.090-21.811 16.077-43.52 24.166-65.229 39.834-106.086 80.077-212.070 119.194-318.362 13.722-37.171 57.549-63.795 91.546-63.693 209.306 0.922 418.611 0.717 627.917 0.205 23.654-0.102 41.984 5.939 52.838 28.16 2.662 7.68 4.403 13.517 0 25.907-47.206 129.638-96.563 263.373-143.667 393.011zM321.126 160.768c1.024 3.072 1.638 6.246 3.072 9.114 18.33 36.864 36.864 73.523 54.989 110.49 3.072 6.246 6.656 8.294 13.517 8.294 146.227-0.205 292.557-0.205 438.784-0.205 30.003 0 56.422 22.323 61.645 52.122 0.614 3.482 0 7.168 0 11.674h-12.186c-178.176 0-356.25-0.102-534.426 0-62.362 0.102-111.104 26.726-143.667 79.667-11.162 18.125-17.613 39.219-25.19 59.392-37.478 99.43-74.752 199.066-111.821 298.803-2.97 7.987-6.554 9.933-14.541 7.987-24.576-6.144-48.845-26.010-51.302-48.947v-538.522c0-46.592 34.406-49.869 49.869-49.869h271.258z"></path></svg>react</p></a></div><h3 class="c-PJLV c-PJLV-hlFDyt-size-6 c-PJLV-iMgaFX-truncate-true title"><a href="/blog/check-image-functinalty-working-or-not">Check image functinalty working or not</a></h3><p class="c-PJLV c-PJLV-cBLpOj-size-2 c-PJLV-cllNQK-lineClamp-true c-PJLV-ikMWyde-css title"><a href="/blog/check-image-functinalty-working-or-not">react, test</a></p><div class="c-hnRRWM"></div></div></div></li></ul></div></div><footer class="c-dRMHzO"><div class="c-hCkBfr"><div class="c-FsNLu"><div class="c-eJqRfT"><a class="logo" href="/"><picture><source height="26" width="109" media="(max-width: 1199px)" srcSet="/images/static/main/aim-logo-resp.svg"/><img height="26" width="26" src="/images/static/main/aim-logo.svg" alt="Aimstack"/></picture></a></div><ul class="c-jJiyUf"><li><a target="_self" href="/#quick-start">Quick start</a></li><li><a target="_self" href="/#features">Features</a></li><li><a target="_self" href="/#demos">Demos</a></li><li><a target="_blank" href="https://aimstack.readthedocs.io/en/latest/">Docs</a></li><li><a target="_self" href="/pricing">Pricing</a></li><li><a target="_self" href="/blog">Blog</a></li><li><a target="_self" href="/about-us">About Us</a></li><li><a target="_blank" href="/category/test#">Career</a></li></ul><ul class="c-MNZuo"><li><a href="https://aimstack.slack.com/ssb/redirect#/shared-invite/email" rel="noopener noreferrer" target="_blank" aria-label="slack"><svg class="icon " style="display:inline-block;vertical-align:middle" width="20" height="20" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path style="fill:white" d="M380.907 539.056c-57.742 0-104.574 46.837-104.574 104.585v261.609c0 57.748 46.832 104.585 104.574 104.585s104.574-46.837 104.574-104.585v-261.609c-0.042-57.748-46.874-104.585-104.574-104.585z"></path><path style="fill:white" d="M15.111 643.63c0 57.799 46.874 104.687 104.659 104.687s104.659-46.888 104.659-104.687v-104.685h-104.577c-0.042 0-0.042 0-0.082 0-57.785 0-104.659 46.886-104.659 104.685z"></path><path style="fill:white" d="M381.003 14.167c-0.042 0-0.083 0-0.125 0-57.783 0-104.656 46.886-104.656 104.684s46.874 104.685 104.656 104.685h104.574v-104.685c0-0.041 0-0.124 0-0.207-0.042-57.715-46.791-104.477-104.449-104.477z"></path><path style="fill:white" d="M118.88 485.95h262.080c57.784 0 104.657-46.892 104.657-104.697s-46.874-104.697-104.657-104.697h-262.080c-57.784 0-104.658 46.892-104.658 104.697s46.874 104.697 104.658 104.697z"></path><path style="fill:white" d="M904.118 276.5c-57.702 0-104.454 46.767-104.454 104.49v104.905h104.573c57.788 0 104.658-46.892 104.658-104.698s-46.871-104.697-104.658-104.697c-0.040 0-0.080 0-0.119 0z"></path><path style="fill:white" d="M538.444 118.795v262.365c0 57.741 46.834 104.573 104.577 104.573 57.737 0 104.573-46.832 104.573-104.573v-262.365c0-57.741-46.837-104.573-104.573-104.573-57.742 0-104.577 46.832-104.577 104.573z"></path><path style="fill:white" d="M747.594 905.028c0-57.748-46.837-104.585-104.573-104.585h-104.577v104.67c0.042 57.702 46.834 104.499 104.577 104.499 57.737 0 104.573-46.837 104.573-104.585z"></path><path style="fill:white" d="M905.068 538.944h-262.076c-57.788 0-104.659 46.886-104.659 104.685s46.871 104.687 104.659 104.687h262.076c57.788 0 104.658-46.888 104.658-104.687s-46.871-104.685-104.658-104.685z"></path></svg></a></li><li><a href="https://twitter.com/aimstackio" rel="noopener noreferrer" target="_blank" aria-label="twitter"><svg class="icon " style="display:inline-block;vertical-align:middle" width="20" height="20" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path style="fill:white" d="M322.14 927.976c386.322 0 597.681-320.14 597.681-597.678 0-9-0.199-18.2-0.604-27.2 41.116-29.734 76.601-66.565 104.782-108.76-38.292 17.037-78.95 28.164-120.579 33 43.833-26.275 76.654-67.553 92.381-116.18-41.24 24.439-86.339 41.679-133.363 50.98-31.685-33.666-73.577-55.957-119.199-63.427s-92.44 0.299-133.206 22.103c-40.766 21.805-73.211 56.432-92.324 98.527s-23.826 89.314-13.411 134.357c-83.5-4.19-165.188-25.881-239.767-63.667s-140.386-90.823-193.153-155.673c-26.819 46.239-35.025 100.955-22.952 153.027s43.521 97.594 87.952 127.313c-33.356-1.059-65.981-10.040-95.18-26.2v2.6c-0.030 48.525 16.745 95.562 47.475 133.116 30.729 37.552 73.515 63.309 121.085 72.886-30.899 8.451-63.328 9.685-94.78 3.6 13.424 41.731 39.54 78.228 74.706 104.405 35.166 26.171 77.626 40.712 121.454 41.591-74.408 58.449-166.322 90.155-260.94 90.004-16.78-0.027-33.543-1.056-50.2-3.083 96.122 61.666 207.937 94.424 322.14 94.359z"></path></svg></a></li><li><a href="https://www.linkedin.com/company/aimstackio/" rel="noopener noreferrer" target="_blank" aria-label="linkedIn"><svg class="icon " style="display:inline-block;vertical-align:middle" width="20" height="20" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path style="fill:white" d="M948.201 0h-872.601c-41.8 0-75.6 33-75.6 73.8v876.199c0 40.801 33.8 74.001 75.6 74.001h872.601c41.796 0 75.799-33.2 75.799-73.802v-876.398c0-40.8-34.002-73.8-75.799-73.8zM303.8 872.602h-152v-488.802h152v488.802zM227.8 317.2c-48.8 0-88.2-39.4-88.2-88s39.4-88 88.2-88c48.6 0 88 39.4 88 88 0 48.4-39.4 88-88 88zM872.602 872.602h-151.802v-237.602c0-56.599-1.001-129.6-79.002-129.6-78.998 0-90.998 61.8-90.998 125.6v241.601h-151.6v-488.802h145.6v66.8h2c20.2-38.4 69.802-79 143.598-79 153.805 0 182.204 101.2 182.204 232.799v268.203z"></path></svg></a></li><li><a href="https://www.facebook.com/aimstackio" rel="noopener noreferrer" target="_blank" aria-label="fb"><svg class="icon " style="display:inline-block;vertical-align:middle" width="20" height="20" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path style="fill:white" d="M1024 512c0-282.77-229.228-512-512-512-282.77 0-512 229.23-512 512 0 255.551 187.23 467.371 432 505.782v-357.78h-130v-148.002h130v-112.8c0-128.32 76.44-199.2 193.391-199.2 56.001 0 114.608 10 114.608 10v126h-64.558c-63.602 0-83.445 39.47-83.445 80v96h142l-22.699 148.002h-119.302v357.78c244.77-38.411 432.003-250.231 432.003-505.782z"></path></svg></a></li></ul></div><div class="c-cChYXC"><p class="c-PJLV c-PJLV-EDrvg-size-1">Copyright Â© <!-- -->2023<!-- --> Aimstack</p></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Check image functinalty working or not","date":"2022-08-16T14:56:38.839Z","author":"Rajdeep singh","description":"react, test","slug":"check-image-functinalty-working-or-not","image":"/images/butterfly-7353884_960_720.webp","draft":false,"tags":["javascript","react"],"categories":["react","test"],"body":{"raw":"in this check Check image functinalty working or not","html":"\u003cp\u003ein this check Check image functinalty working or not\u003c/p\u003e"},"_id":"posts/check-image-functinalty-working-or-not.md","_raw":{"sourceFilePath":"posts/check-image-functinalty-working-or-not.md","sourceFileName":"check-image-functinalty-working-or-not.md","sourceFileDir":"posts","contentType":"markdown","flattenedPath":"posts/check-image-functinalty-working-or-not"},"type":"Post"},{"title":"DONE","date":"2022-12-26T22:16:08.091Z","author":"Ashot","description":"aaaa","slug":"done","image":"/images/group-580.png","draft":false,"tags":["asd"],"categories":["test"],"body":{"raw":"\u003c!--StartFragment--\u003e\n\n## Where does it come from?\n\nContrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32.\n\nThe standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham.\n\n\u003c!--EndFragment--\u003e","html":"\u003ch2\u003eWhere does it come from?\u003c/h2\u003e\n\u003cp\u003eContrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32.\u003c/p\u003e\n\u003cp\u003eThe standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham.\u003c/p\u003e"},"_id":"posts/done.md","_raw":{"sourceFilePath":"posts/done.md","sourceFileName":"done.md","sourceFileDir":"posts","contentType":"markdown","flattenedPath":"posts/done"},"type":"Post"},{"title":"New Post","date":"2023-01-25T13:06:43.382Z","author":"ASh","description":"very short description","slug":"new-post","image":"/images/dynamic/aim-logo.svg","draft":false,"categories":["test"],"body":{"raw":"\u003cdiv align=\"center\"\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/154338760-edfe1885-06f3-4e02-87fe-4b13a403516b.png\"\u003e\r\n  \u003ch3\u003eAn easy-to-use \u0026 supercharged open-source experiment tracker\u003c/h3\u003e\r\n  Aim logs your training runs, enables a beautiful UI to compare them and an API to query them programmatically.\r\n\u003c/div\u003e\r\n\r\n\u003cbr/\u003e\r\n\r\n\u003cimg src=\"https://user-images.githubusercontent.com/13848158/154338753-34484cda-95b8-4da8-a610-7fdf198c05fd.png\"\u003e\r\n\r\n\u003cp align=\"center\"\u003e\r\n  \u003ca href=\"#about-aim\"\u003e\u003cb\u003eAbout\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"#why-use-aim\"\u003e\u003cb\u003eFeatures\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"#demos\"\u003e\u003cb\u003eDemos\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"https://github.com/aimhubio/aim/tree/main/examples\"\u003e\u003cb\u003eExamples\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"#quick-start\"\u003e\u003cb\u003eQuick Start\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"https://aimstack.readthedocs.io/en/latest/\"\u003e\u003cb\u003eDocumentation\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"#roadmap\"\u003e\u003cb\u003eRoadmap\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"https://community.aimstack.io/\"\u003e\u003cb\u003eDiscord Community\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"https://twitter.com/aimstackio\"\u003e\u003cb\u003eTwitter\u003c/b\u003e\u003c/a\u003e\r\n\u003c/p\u003e\r\n\r\n\u003cdiv align=\"center\"\u003e\r\n  \r\n  [![Platform Support](https://img.shields.io/badge/platform-Linux%20%7C%20macOS-blue)]()\r\n  [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/aim)](https://pypi.org/project/aim/)\r\n  [![PyPI Package](https://img.shields.io/pypi/v/aim?color=yellow)](https://pypi.org/project/aim/)\r\n  [![License](https://img.shields.io/badge/License-Apache%202.0-orange.svg)](https://opensource.org/licenses/Apache-2.0)\r\n  [![PyPI Downloads](https://img.shields.io/pypi/dw/aim?color=green)](https://pypi.org/project/aim/)\r\n  [![Issues](https://img.shields.io/github/issues/aimhubio/aim)](http://github.com/aimhubio/aim/issues)\r\n  \r\n\u003c/div\u003e\r\n\r\n\u003cdiv align=\"center\"\u003e\r\n  \u003csub\u003eIntegrates seamlessly with your favorite tools\u003c/sub\u003e\r\n  \u003cbr/\u003e\r\n  \u003cbr/\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354389-d0301620-77ea-4629-a743-f7aa249e14b5.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354496-b39d7b1c-63ef-40f0-9e59-c08d2c5e337c.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354380-3755c741-6960-42ca-b93e-84a8791f088c.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354342-7df0ef5e-63d2-4df7-b9f1-d2fc0e95f53f.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354392-afbff3de-c845-4d86-855d-53df569f91d1.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354355-89210506-e7e5-4d37-b2d6-ad3fda62ef13.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354397-8af8e1d3-4067-405e-9d42-1f131663ed22.png\" width=\"60\" /\u003e\r\n  \u003cbr/\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354513-f7486146-3891-4f3f-934f-e58bbf9ce695.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354500-c0471ce6-b2ce-4172-b9e4-07a197256303.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354361-9f911785-008d-4b75-877e-651e026cf47e.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354373-1879ae61-b5d1-41f0-a4f1-04b639b6f05e.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354483-75d9853f-7154-4d95-8190-9ad7a73d6654.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354329-cf7c3352-a72a-478d-82a7-04e3833b03b7.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354349-dcdf3bc3-d7a9-4f34-8258-4824a57f59c7.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354471-518f1814-7a41-4b23-9caf-e516507343f1.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/48801049/165162736-2cc5da39-38aa-4093-874f-e56d0ba9cea2.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/48801049/165074282-36ad18eb-1124-434d-8439-728c22cd7ac7.png\" width=\"60\" /\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv align=\"center\"\u003e\r\n  \u003cbr/\u003e\r\n  \u003ckbd\u003e\r\n    \u003cimg width=\"650px\" src=\"https://user-images.githubusercontent.com/13848158/136374529-af267918-5dc6-4a4e-8ed2-f6333a332f96.gif\" /\u003e\r\n  \u003c/kbd\u003e\r\n\u003c/div\u003e\r\n\r\n# About Aim\r\n\r\n| Track and version ML runs | Visualize runs via beautiful UI | Query runs metadata via SDK |\r\n|:--------------------:|:------------------------:|:-------------------:|\r\n| \u003cimg width=\"600px\" src=\"https://user-images.githubusercontent.com/13848158/154337794-e9310239-6614-41b3-a95b-bb91f0bb6c4f.png\"\u003e | \u003cimg width=\"600px\" src=\"https://user-images.githubusercontent.com/13848158/154337788-03fe5b31-0fa3-44af-ae79-2861707d8602.png\"\u003e | \u003cimg width=\"600px\" src=\"https://user-images.githubusercontent.com/13848158/154337793-85175c78-5659-4dd0-bb2d-05017278e2fa.png\"\u003e |\r\n\r\nAim is an open-source, self-hosted ML experiment tracking tool. \r\nIt's good at tracking lots (1000s) of training runs and it allows you to compare them with a performant and beautiful UI.\r\n\r\nYou can use not only the great Aim UI but also its SDK to query your runs' metadata programmatically. \r\nThat's especially useful for automations and additional analysis on a Jupyter Notebook.\r\n\r\n\r\nAim's mission is to democratize AI dev tools.\r\n\r\n# Why use Aim?\r\n\r\n### Compare 100s of runs in a few clicks - build models faster\r\n\r\n- Compare, group and aggregate 100s of metrics thanks to effective visualizations.\r\n- Analyze, learn correlations and patterns between hparams and metrics.\r\n- Easy pythonic search to query the runs you want to explore.\r\n\r\n### Deep dive into details of each run for easy debugging\r\n\r\n- Hyperparameters, metrics, images, distributions, audio, text - all available at hand on an intuitive UI to understand the performance of your model.\r\n- Easily track plots built via your favourite visualisation tools, like plotly and matplotlib.\r\n- Analyze system resource usage to effectively utilize computational resources.\r\n\r\n### Have all relevant information organised and accessible for easy governance\r\n\r\n- Centralized dashboard to holistically view all your runs, their hparams and results.\r\n- Use SDK to query/access all your runs and tracked metadata.\r\n- You own your data - Aim is open source and self hosted.\r\n\r\n# Demos\r\n\r\n| Machine translation | lightweight-GAN |\r\n|:---:|:---:|\r\n| \u003ca href=\"http://play.aimstack.io:10001/metrics?grouping=HQGdK9Xxy35e6sY1CYkCmk1WbWMN2AsCNfJJ3d1RJYLtrVPMoF5UpGiA6CF8bEJnfzRsKpqespf3AEuKSVrhUYvYk9MxzNGA9XZWYUf6phEg8AMbZGLRVDXnAPDuo8tueqsST1ZLizWzQwDYJWHUza6pyB2Eojt9uWqNHUdb858TqDRnCJzqiVJXKXEzFWUyvU8MckJo1qpqWWCTb4GpYN6DUJZx2GXDGR21e2xxd4m7PmNUnbA9B3apLttZoipJF6c3v7tNUKmb6irpqnNB3yc57tqYDa1XZuKfDxkMtyFdQ1x95K4jjsTVwhftEWLze35QNcxNXRCGGS9o9yEfTLG26GUX2zjPZFCjjMGU6vV7z1xRccK8MyoGrLSgAQCbvk68dTGBHpXUBvCRq8N\u0026chart=FviZzVrt4fVQPjpCLr9sVGGrcR5etSroyqambiKpm3nTgpyv4eQxKuwNX9uN8UtKmzYUhUyTMBEANHmtbwjLApkvnYeNbxGNC6PVcoqi65m1XJnSrvgt8WiD89BapFAWRUwAGx6SWD7KZPsk3RQyysU7W7FjD3Q99NusxFGhsEfD6HXc7i8xH9KHDRGjLwh6x9VTtSp4FS8HEvpLSiiJoX7LCTi8pB7dXvrQ8G5w3jPsFz4qXYFdsVaCNL1BpFFZuiqQNkfbnM84gEq7UmiV1VzM4oS3AgQHxADG3kpBVp6eKTey9F1Swd4FcUkFA9QEPjgQgqwRGjkquZ2bdDDVLBnCh7JPvboP2kifCiZZ5MDdV9MMx6PKHp4DusWyWLXiHQYPkpGPWBiuccMUXDsuJaCWJbuABdY7CyiJMv1jdHYkjabygSxehPVyEDefWAtjBfv2vaeM1xv63jadbmpKYFxft7qmuT9HvVxiGvRgs4RQFxy8K4rtFBca3HNs1mDaaY81gy9MGXyw7BS5Fniu92jaJpsWDdg6Y3AQBLZtrpJy2obEZ4yzJaCVT7JUNPAyyCUNLck393VFLoEkaD9CU5npK5R7tj1c1G3gkMNQXnSXy5NpSj8deMmXV5qz3JKu1nq2caGQKcqjzy2gLkExdm674AMFjSg9yFjK6VqASXQ17NKtWRUvaYoxGbHDAFQaMKWKh8QLm22QA9mKT8NksLptWozbgDvafnQLNMvezLU5bvKV5o75PAWYiRB56RcYfEhzaB6YWdgL7TJicyY5rFi6Az8UZ7wqB3N5iMuZdpxhKn5KbZDxyuUMuvVt24i5LVPPmmwQtqxMoJ4aLo48a2YvDW6TAkdQjNjvn6KcEEz6GTixujb1YHhMUD8v4AepWKEwKz1ddEca1P2wLQjbpihCuaqbxeohnuZZLogJdUBojBEDgrnrrVpPBaLLEkGSpkJbtrsKUuEeBo1AF3yNgHftLbynGpobVF5DhmsmddmiA6c8vSTokJxHhjpnW8mAcNHBRtmVJCT7VkdHSAhNypM4Hivwfx5jCccG9LauKmCeRMDzHiA57TX9W6ttcPHSvUyQorARQAd2oeNY4H83hZjHh9Bt8iwKZRt4xK6hrTR8tif7hq8eURXrGH9Ys7TzykXK8FHHWvLNzNnYf3E4a9NkD43MjfKvMM1hj4Q2K8MHbmRCqrmFrHP5kim9shq6mhLPTgwha32nvnrBkfPQVPwpGTzKuwE\u0026select=CdsQ7jVNkogQhRzQR3e28Ek39AZ4Ma2y37k5zJaf9EZmQhMjy8GtGm4LGU6dRFuAVG7mYww5xDrQAE74KHQ3Kk1e6661RmcmNALAUjtHyCmrTVBMCnBGNiuq1y7EzmxoodYHU1BV1rnoefQAw2kTBtbWi11hV1P4LcwFCcXfUWF6rpRC7ehEnUCTqUV4bkGVJPLcmk9mdmiGwa2YgmnSShNGPVGZiEi1rMVECyngSRVdqdZwAeXBGWFLfqF1KbZeCo4MTF4SSmFupJ9zLhYbuojEbopyFWHQ6xs3sq9epPeaQziLM4Js7oFYRmuFWUYdFqnZngmewXWmi7tQAgVqhiT6dMjG2eTdfgX6WuRSuoHALkh2XJhHA6GfZLUcxC5Ni9YyKuBTamtaYarbNNJJ8z15WWvuUkLpjgHdEpE2h924xFdu8aoZNuiQxYGvcndaW1BTGMXS5fTKPqYfe2n8Ky2HWPkcX3hEXtyawu1F9BndKNaXLPgsdAoFBArBZnSe28YtSmTa5LRucKVBAxakvv5MWMXchAmpaGFQbZyYUoMgQLcJd7Y96x6zSR7nhwr5Ar81BrmqYz2WFLuk7osUbwsc9HbSG6CQt8p6Vg2u7DjKaZXW8pjkPHAKrHWtHEDiJPJ5rj6VsdFm3\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340796-c9e91b13-8ee0-4a67-bcde-8cf3aaa7ba99.jpg\"\u003e \u003c/a\u003e | \u003ca href=\"http://play.aimstack.io:10002/images?grouping=E1zQzcmtDR3wibEa1MVysTvCyZEv1T8ixkCxTWExCyMnHtX2HyiF9eszvPgfd2xdJ5TUTKGpSs1bsLVq5tHAV3uWtsZmmckn6HjNtVCMyQDJpwhiEy5tAyw\u0026select=2NEXuD7fFoaLcwRjymjA1wLmUrGs9s3AiXcCW82C367SwJt18CAB6xzkMGowrUDuDwggE1huaPVcQJpQUsmAQx1CnGiqCUBp2jPMd5mMNPX2QKQMcmvu9ZykBNkeBvCQFPd9ERuQD2g1EjWuvyJ3H53mAZTfp94LCXvR9CUsG5ei2CjQUzfZLM6DCyUr1GPaEVnY5f1EwzicNxXuoutkBgqCqaobJ7Do4q4eHAA6ooiWU6ekS3D2sLj6qYwhVTjfGCPfbWwBiH83nFkY3fLExzdeTY2zeUHeeYikQR9S7xHbVD8WvjekdQVp8X4dNLJZxiVmEqHpPRnU3ZrYsMhE7yFAAgjJwPNUzLTt6YFrtZBcmc4rwAC2oyrqysUSEr6gzL6LcJ6yuqDGf9D5tzftHbTLDkhc8B2sCgTS\u0026images=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\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340790-bc7b7a21-e8a1-43a1-809d-4060b5bfb60f.jpg\"\u003e \u003c/a\u003e |\r\n| Training logs of a neural translation model(from WMT'19 competition). | Training logs of 'lightweight' GAN, proposed in ICLR 2021. |\r\n\r\n| FastSpeech 2 | Simple MNIST |\r\n|:---:|:---:|\r\n| \u003ca href=\"http://play.aimstack.io:10004/runs/d9e89aa7875e44b2ba85612a/audios\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340778-dbe19620-2f27-4298-b0cb-caf3904760f1.jpg\"\u003e \u003c/a\u003e | \u003ca href=\"http://play.aimstack.io:10003/runs/7f083da898624a2c98e0f363/distributions\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340785-a7e4d9fd-d048-4207-8cd1-c4edff9cca6a.jpg\"\u003e \u003c/a\u003e |\r\n| Training logs of Microsoft's \"FastSpeech 2: Fast and High-Quality End-to-End Text to Speech\". | Simple MNIST training logs. |\r\n\r\n# Quick Start\r\n\r\nFollow the steps below to get started with Aim.\r\n\r\n**1. Install Aim on your training environment**\r\n\r\n```shell\r\npip3 install aim\r\n```\r\n\r\n**2. Integrate Aim with your code**\r\n\r\n```python\r\nfrom aim import Run\r\n\r\n# Initialize a new run\r\nrun = Run()\r\n\r\n# Log run parameters\r\nrun[\"hparams\"] = {\r\n    \"learning_rate\": 0.001,\r\n    \"batch_size\": 32,\r\n}\r\n\r\n# Log metrics\r\nfor i in range(10):\r\n    run.track(i, name='loss', step=i, context={ \"subset\":\"train\" })\r\n    run.track(i, name='acc', step=i, context={ \"subset\":\"train\" })\r\n```\r\n\r\n_See the full list of supported trackable objects(e.g. images, text, etc) [here](https://aimstack.readthedocs.io/en/latest/quick_start/supported_types.html)._\r\n\r\n**3. Run the training as usual and start Aim UI**\r\n\r\n```shell\r\naim up\r\n```\r\n\r\n**4. Or query runs programmatically via SDK**\r\n\r\n```python\r\nfrom aim import Repo\r\n\r\nmy_repo = Repo('/path/to/aim/repo')\r\n\r\nquery = \"metric.name == 'loss'\" # Example query\r\n\r\n# Get collection of metrics\r\nfor run_metrics_collection in my_repo.query_metrics(query).iter_runs():\r\n    for metric in run_metrics_collection:\r\n        # Get run params\r\n        params = metric.run[...]\r\n        # Get metric values\r\n        steps, metric_values = metric.values.sparse_numpy()\r\n```\r\n\r\n# Integrations\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate PyTorch Lightning\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.pytorch_lightning import AimLogger\r\n\r\n# ...\r\ntrainer = pl.Trainer(logger=AimLogger(experiment='experiment_name'))\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-lightning)._\r\n\r\n\u003c/details\u003e\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate Hugging Face\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.hugging_face import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='mnli')\r\ntrainer = Trainer(\r\n    model=model,\r\n    args=training_args,\r\n    train_dataset=train_dataset if training_args.do_train else None,\r\n    eval_dataset=eval_dataset if training_args.do_eval else None,\r\n    callbacks=[aim_callback],\r\n    # ...\r\n)\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-hugging-face)._\r\n\r\n\u003c/details\u003e\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate Keras \u0026 tf.keras\r\n\u003c/summary\u003e\r\n\r\n```python\r\nimport aim\r\n\r\n# ...\r\nmodel.fit(x_train, y_train, epochs=epochs, callbacks=[\r\n    aim.keras.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\n    \r\n    # Use aim.tensorflow.AimCallback in case of tf.keras\r\n    aim.tensorflow.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\n])\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-keras-tf-keras)._\r\n\r\n\u003c/details\u003e\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate KerasTuner\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.keras_tuner import AimCallback\r\n\r\n# ...\r\ntuner.search(\r\n    train_ds,\r\n    validation_data=test_ds,\r\n    callbacks=[AimCallback(tuner=tuner, repo='.', experiment='keras_tuner_test')],\r\n)\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-kerastuner)._\r\n\r\n\u003c/details\u003e\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate XGBoost\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.xgboost import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\nbst = xgb.train(param, xg_train, num_round, watchlist, callbacks=[aim_callback])\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-xgboost)._\r\n\u003c/details\u003e\r\n\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate CatBoost\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.catboost import AimLogger\r\n\r\n# ...\r\nmodel.fit(train_data, train_labels, log_cout=AimLogger(loss_function='Logloss'), logging_level=\"Info\")\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-catboost)._\r\n\u003c/details\u003e\r\n\r\n\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate fastai\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.fastai import AimCallback\r\n\r\n# ...\r\nlearn = cnn_learner(dls, resnet18, pretrained=True,\r\n                    loss_func=CrossEntropyLossFlat(),\r\n                    metrics=accuracy, model_dir=\"/tmp/model/\",\r\n                    cbs=AimCallback(repo='.', experiment='fastai_test'))\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-fastai)._\r\n\u003c/details\u003e\r\n\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate LightGBM\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.lightgbm import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(experiment='lgb_test')\r\naim_callback.experiment['hparams'] = params\r\n\r\ngbm = lgb.train(params,\r\n                lgb_train,\r\n                num_boost_round=20,\r\n                valid_sets=lgb_eval,\r\n                callbacks=[aim_callback, lgb.early_stopping(stopping_rounds=5)])\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-lightgbm)._\r\n\u003c/details\u003e\r\n\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate PyTorch Ignite\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.pytorch_ignite import AimLogger\r\n\r\n# ...\r\naim_logger = AimLogger()\r\n\r\naim_logger.log_params({\r\n    \"model\": model.__class__.__name__,\r\n    \"pytorch_version\": str(torch.__version__),\r\n    \"ignite_version\": str(ignite.__version__),\r\n})\r\n\r\naim_logger.attach_output_handler(\r\n    trainer,\r\n    event_name=Events.ITERATION_COMPLETED,\r\n    tag=\"train\",\r\n    output_transform=lambda loss: {'loss': loss}\r\n)\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-ignite)._\r\n\u003c/details\u003e\r\n\r\n# Comparisons to familiar tools\r\n\r\n### Tensorboard\r\n**Training run comparison**\r\n\r\nOrder of magnitude faster training run comparison with Aim\r\n- The tracked params are first class citizens at Aim. You can search, group, aggregate via params - deeply explore all the tracked data (metrics, params, images) on the UI.\r\n- With tensorboard the users are forced to record those parameters in the training run name to be able to search and compare. This causes a super-tedius comparison experience and usability issues on the UI when there are many experiments and params. **TensorBoard doesn't have features to group, aggregate the metrics**\r\n\r\n**Scalability**\r\n\r\n- Aim is built to handle 1000s of training runs - both on the backend and on the UI.\r\n- TensorBoard becomes really slow and hard to use when a few hundred training runs are queried / compared.\r\n\r\n**Beloved TB visualizations to be added on Aim**\r\n\r\n- Embedding projector.\r\n- Neural network visualization.\r\n\r\n### MLFlow\r\nMLFlow is an end-to-end ML Lifecycle tool.\r\nAim is focused on training tracking.\r\nThe main differences of Aim and MLflow are around the UI scalability and run comparison features.\r\n\r\n**Run comparison**\r\n\r\n- Aim treats tracked parameters as first-class citizens. Users can query runs, metrics, images and filter using the params.\r\n- MLFlow does have a search by tracked config, but there are no grouping, aggregation, subplotting by hyparparams and other comparison features available.\r\n\r\n**UI Scalability**\r\n\r\n- Aim UI can handle several thousands of metrics at the same time smoothly with 1000s of steps. It may get shaky when you explore 1000s of metrics with 10000s of steps each. But we are constantly optimizing!\r\n- MLflow UI becomes slow to use when there are a few hundreds of runs.\r\n\r\n### Weights and Biases\r\n\r\nHosted vs self-hosted\r\n- Weights and Biases is a hosted closed-source MLOps platform.\r\n- Aim is self-hosted, free and open-source experiment tracking tool.\r\n\r\n# Roadmap\r\n\r\n## Detailed Sprints\r\n\r\n:sparkle: The [Aim product roadmap](https://github.com/orgs/aimhubio/projects/3)\r\n\r\n- The `Backlog` contains the issues we are going to choose from and prioritize weekly\r\n- The issues are mainly prioritized by the highly-requested features\r\n\r\n## High-level roadmap\r\n\r\nThe high-level features we are going to work on the next few months\r\n\r\n### Done\r\n  - [x] Live updates (Shipped: _Oct 18 2021_)\r\n  - [x] Images tracking and visualization (Start: _Oct 18 2021_, Shipped: _Nov 19 2021_)\r\n  - [x] Distributions tracking and visualization (Start: _Nov 10 2021_, Shipped: _Dec 3 2021_)\r\n  - [x] Jupyter integration (Start: _Nov 18 2021_, Shipped: _Dec 3 2021_)\r\n  - [x] Audio tracking and visualization (Start: _Dec 6 2021_, Shipped: _Dec 17 2021_)\r\n  - [x] Transcripts tracking and visualization (Start: _Dec 6 2021_, Shipped: _Dec 17 2021_)\r\n  - [x] Plotly integration (Start: _Dec 1 2021_, Shipped: _Dec 17 2021_)\r\n  - [x] Colab integration (Start: _Nov 18 2021_, Shipped: _Dec 17 2021_)\r\n  - [x] Centralized tracking server (Start: _Oct 18 2021_, Shipped: _Jan 22 2022_)\r\n  - [x] Tensorboard adaptor - visualize TensorBoard logs with Aim (Start: _Dec 17 2021_, Shipped: _Feb 3 2022_)\r\n  - [x] Track git info, env vars, CLI arguments, dependencies (Start: _Jan 17 2022_, Shipped: _Feb 3 2022_)\r\n  - [x] MLFlow adaptor (visualize MLflow logs with Aim) (Start: _Feb 14 2022_, Shipped: _Feb 22 2022_)\r\n  - [x] Activeloop Hub integration (Start: _Feb 14 2022_, Shipped: _Feb 22 2022_)\r\n  - [x] PyTorch-Ignite integration (Start: _Feb 14 2022_, Shipped: _Feb 22 2022_)\r\n  - [x] Run summary and overview info(system params, CLI args, git info, ...) (Start: _Feb 14 2022_, Shipped: _Mar 9 2022_)\r\n  - [x] Add DVC related metadata into aim run (Start: _Mar 7 2022_, Shipped: _Mar 26 2022_)\r\n  - [x] Ability to attach notes to Run from UI (Start: _Mar 7 2022_, Shipped: _Apr 29 2022_)\r\n  - [x] Fairseq integration (Start: _Mar 27 2022_, Shipped: _Mar 29 2022_)\r\n  - [x] LightGBM integration (Start: _Apr 14 2022_, Shipped: _May 17 2022_)\r\n  - [x] CatBoost integration (Start: _Apr 20 2022_, Shipped: _May 17 2022_)\r\n  - [x] Run execution details(display stdout/stderr logs) (Start: _Apr 25 2022_, Shipped: _May 17 2022_)\r\n  - [x] Long sequences(up to 5M of steps) support (Start: _Apr 25 2022_, Shipped: _Jun 22 2022_)\r\n  - [x] Figures Explorer (Start: _Mar 1 2022_, Shipped: _Aug 21 2022_)\r\n  - [x] Notify on stuck runs (Start: _Jul 22 2022_, Shipped: _Aug 21 2022_)\r\n  - [x] Integration with KerasTuner (Start: _Aug 10 2022_, Shipped: _Aug 21 2022_)\r\n  - [x] Integration with WandB (Start: _Aug 15 2022_, Shipped: _Aug 21 2022_)\r\n  - [x] Stable remote tracking server (Start: _Jun 15 2022_, Shipped: _Aug 21 2022_)\r\n  - [x] Integration with fast.ai (Start: _Aug 22 2022_, Shipped: _Oct 6 2022_)\r\n  - [x] Integration with MXNet (Start: _Sep 20 2022_, Shipped: _Oct 6 2022_)\r\n  - [x] Project overview page (Start: _Sep 1 2022_, Shipped: _Oct 6 2022_)\r\n  - [x] Remote tracking server scaling (Start: _Sep 11 2022_, Shipped: _Nov 26 2022_)\r\n  - [x] Integration with PaddlePaddle (Start: _Oct 2 2022_, Shipped: _Nov 26 2022_)\r\n  - [x] Integration with Optuna (Start: _Oct 2 2022_, Shipped: _Nov 26 2022_)\r\n  - [x] Audios Explorer (Start: _Oct 30 2022_, Shipped: _Nov 26 2022_)\r\n  - [x] Experiment page (Start: _Nov 9 2022_, Shipped: _Nov 26 2022_)\r\n\r\n### In Progress\r\n  - [ ] Aim SDK low-level interface (Start: _Aug 22 2022_, )\r\n  - [ ] HuggingFace datasets (Start: _Dec 29 2022_, )\r\n\r\n### To Do\r\n\r\n**Aim UI**\r\n\r\n- Runs management\r\n    - Runs explorer â€“ query and visualize runs data(images, audio, distributions, ...) in a central dashboard\r\n- Explorers\r\n    - Text Explorer\r\n    - Distributions Explorer\r\n- Dashboards â€“ customizable layouts with embedded explorers\r\n\r\n**SDK and Storage**\r\n\r\n- Scalability\r\n    - Smooth UI and SDK experience with over 10.000 runs\r\n- Runs management\r\n    - CLI interfaces\r\n        - Reporting - runs summary and run details in a CLI compatible format\r\n        - Manipulations â€“ copy, move, delete runs, params and sequences\r\n\r\n**Integrations**\r\n\r\n- ML Frameworks:\r\n    - Shortlist: MONAI, SpaCy, Raytune\r\n- Resource management tools\r\n    - Shortlist: Kubeflow, Slurm\r\n- Workflow orchestration tools\r\n- Others: Hydra, Google MLMD, Streamlit, ...\r\n\r\n### On hold\r\n\r\n- scikit-learn integration\r\n- Cloud storage support â€“ store runs blob(e.g. images) data on the cloud (Start: _Mar 21 2022_)\r\n- Artifact storage â€“ store files, model checkpoints, and beyond (Start: _Mar 21 2022_)\r\n\r\n## Community\r\n\r\n### If you have questions\r\n\r\n1. [Read the docs](https://aimstack.readthedocs.io/en/latest/)\r\n2. [Open a feature request or report a bug](https://github.com/aimhubio/aim/issues)\r\n3. [Join Discord community server](https://community.aimstack.io/)\u003cdiv align=\"center\"\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/154338760-edfe1885-06f3-4e02-87fe-4b13a403516b.png\"\u003e\r\n  \u003ch3\u003eAn easy-to-use \u0026 supercharged open-source experiment tracker\u003c/h3\u003e\r\n  Aim logs your training runs, enables a beautiful UI to compare them and an API to query them programmatically.\r\n\u003c/div\u003e\r\n\r\n\u003cbr/\u003e\r\n\r\n\u003cimg src=\"https://user-images.githubusercontent.com/13848158/154338753-34484cda-95b8-4da8-a610-7fdf198c05fd.png\"\u003e\r\n\r\n\u003cp align=\"center\"\u003e\r\n  \u003ca href=\"#about-aim\"\u003e\u003cb\u003eAbout\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"#why-use-aim\"\u003e\u003cb\u003eFeatures\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"#demos\"\u003e\u003cb\u003eDemos\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"https://github.com/aimhubio/aim/tree/main/examples\"\u003e\u003cb\u003eExamples\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"#quick-start\"\u003e\u003cb\u003eQuick Start\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"https://aimstack.readthedocs.io/en/latest/\"\u003e\u003cb\u003eDocumentation\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"#roadmap\"\u003e\u003cb\u003eRoadmap\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"https://community.aimstack.io/\"\u003e\u003cb\u003eDiscord Community\u003c/b\u003e\u003c/a\u003e \u0026bull;\r\n  \u003ca href=\"https://twitter.com/aimstackio\"\u003e\u003cb\u003eTwitter\u003c/b\u003e\u003c/a\u003e\r\n\u003c/p\u003e\r\n\r\n\u003cdiv align=\"center\"\u003e\r\n  \r\n  [![Platform Support](https://img.shields.io/badge/platform-Linux%20%7C%20macOS-blue)]()\r\n  [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/aim)](https://pypi.org/project/aim/)\r\n  [![PyPI Package](https://img.shields.io/pypi/v/aim?color=yellow)](https://pypi.org/project/aim/)\r\n  [![License](https://img.shields.io/badge/License-Apache%202.0-orange.svg)](https://opensource.org/licenses/Apache-2.0)\r\n  [![PyPI Downloads](https://img.shields.io/pypi/dw/aim?color=green)](https://pypi.org/project/aim/)\r\n  [![Issues](https://img.shields.io/github/issues/aimhubio/aim)](http://github.com/aimhubio/aim/issues)\r\n  \r\n\u003c/div\u003e\r\n\r\n\u003cdiv align=\"center\"\u003e\r\n  \u003csub\u003eIntegrates seamlessly with your favorite tools\u003c/sub\u003e\r\n  \u003cbr/\u003e\r\n  \u003cbr/\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354389-d0301620-77ea-4629-a743-f7aa249e14b5.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354496-b39d7b1c-63ef-40f0-9e59-c08d2c5e337c.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354380-3755c741-6960-42ca-b93e-84a8791f088c.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354342-7df0ef5e-63d2-4df7-b9f1-d2fc0e95f53f.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354392-afbff3de-c845-4d86-855d-53df569f91d1.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354355-89210506-e7e5-4d37-b2d6-ad3fda62ef13.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354397-8af8e1d3-4067-405e-9d42-1f131663ed22.png\" width=\"60\" /\u003e\r\n  \u003cbr/\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354513-f7486146-3891-4f3f-934f-e58bbf9ce695.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354500-c0471ce6-b2ce-4172-b9e4-07a197256303.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354361-9f911785-008d-4b75-877e-651e026cf47e.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354373-1879ae61-b5d1-41f0-a4f1-04b639b6f05e.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354483-75d9853f-7154-4d95-8190-9ad7a73d6654.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354329-cf7c3352-a72a-478d-82a7-04e3833b03b7.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354349-dcdf3bc3-d7a9-4f34-8258-4824a57f59c7.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354471-518f1814-7a41-4b23-9caf-e516507343f1.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/48801049/165162736-2cc5da39-38aa-4093-874f-e56d0ba9cea2.png\" width=\"60\" /\u003e\r\n  \u003cimg src=\"https://user-images.githubusercontent.com/48801049/165074282-36ad18eb-1124-434d-8439-728c22cd7ac7.png\" width=\"60\" /\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv align=\"center\"\u003e\r\n  \u003cbr/\u003e\r\n  \u003ckbd\u003e\r\n    \u003cimg width=\"650px\" src=\"https://user-images.githubusercontent.com/13848158/136374529-af267918-5dc6-4a4e-8ed2-f6333a332f96.gif\" /\u003e\r\n  \u003c/kbd\u003e\r\n\u003c/div\u003e\r\n\r\n# About Aim\r\n\r\n| Track and version ML runs | Visualize runs via beautiful UI | Query runs metadata via SDK |\r\n|:--------------------:|:------------------------:|:-------------------:|\r\n| \u003cimg width=\"600px\" src=\"https://user-images.githubusercontent.com/13848158/154337794-e9310239-6614-41b3-a95b-bb91f0bb6c4f.png\"\u003e | \u003cimg width=\"600px\" src=\"https://user-images.githubusercontent.com/13848158/154337788-03fe5b31-0fa3-44af-ae79-2861707d8602.png\"\u003e | \u003cimg width=\"600px\" src=\"https://user-images.githubusercontent.com/13848158/154337793-85175c78-5659-4dd0-bb2d-05017278e2fa.png\"\u003e |\r\n\r\nAim is an open-source, self-hosted ML experiment tracking tool. \r\nIt's good at tracking lots (1000s) of training runs and it allows you to compare them with a performant and beautiful UI.\r\n\r\nYou can use not only the great Aim UI but also its SDK to query your runs' metadata programmatically. \r\nThat's especially useful for automations and additional analysis on a Jupyter Notebook.\r\n\r\n\r\nAim's mission is to democratize AI dev tools.\r\n\r\n# Why use Aim?\r\n\r\n### Compare 100s of runs in a few clicks - build models faster\r\n\r\n- Compare, group and aggregate 100s of metrics thanks to effective visualizations.\r\n- Analyze, learn correlations and patterns between hparams and metrics.\r\n- Easy pythonic search to query the runs you want to explore.\r\n\r\n### Deep dive into details of each run for easy debugging\r\n\r\n- Hyperparameters, metrics, images, distributions, audio, text - all available at hand on an intuitive UI to understand the performance of your model.\r\n- Easily track plots built via your favourite visualisation tools, like plotly and matplotlib.\r\n- Analyze system resource usage to effectively utilize computational resources.\r\n\r\n### Have all relevant information organised and accessible for easy governance\r\n\r\n- Centralized dashboard to holistically view all your runs, their hparams and results.\r\n- Use SDK to query/access all your runs and tracked metadata.\r\n- You own your data - Aim is open source and self hosted.\r\n\r\n# Demos\r\n\r\n| Machine translation | lightweight-GAN |\r\n|:---:|:---:|\r\n| \u003ca href=\"http://play.aimstack.io:10001/metrics?grouping=HQGdK9Xxy35e6sY1CYkCmk1WbWMN2AsCNfJJ3d1RJYLtrVPMoF5UpGiA6CF8bEJnfzRsKpqespf3AEuKSVrhUYvYk9MxzNGA9XZWYUf6phEg8AMbZGLRVDXnAPDuo8tueqsST1ZLizWzQwDYJWHUza6pyB2Eojt9uWqNHUdb858TqDRnCJzqiVJXKXEzFWUyvU8MckJo1qpqWWCTb4GpYN6DUJZx2GXDGR21e2xxd4m7PmNUnbA9B3apLttZoipJF6c3v7tNUKmb6irpqnNB3yc57tqYDa1XZuKfDxkMtyFdQ1x95K4jjsTVwhftEWLze35QNcxNXRCGGS9o9yEfTLG26GUX2zjPZFCjjMGU6vV7z1xRccK8MyoGrLSgAQCbvk68dTGBHpXUBvCRq8N\u0026chart=FviZzVrt4fVQPjpCLr9sVGGrcR5etSroyqambiKpm3nTgpyv4eQxKuwNX9uN8UtKmzYUhUyTMBEANHmtbwjLApkvnYeNbxGNC6PVcoqi65m1XJnSrvgt8WiD89BapFAWRUwAGx6SWD7KZPsk3RQyysU7W7FjD3Q99NusxFGhsEfD6HXc7i8xH9KHDRGjLwh6x9VTtSp4FS8HEvpLSiiJoX7LCTi8pB7dXvrQ8G5w3jPsFz4qXYFdsVaCNL1BpFFZuiqQNkfbnM84gEq7UmiV1VzM4oS3AgQHxADG3kpBVp6eKTey9F1Swd4FcUkFA9QEPjgQgqwRGjkquZ2bdDDVLBnCh7JPvboP2kifCiZZ5MDdV9MMx6PKHp4DusWyWLXiHQYPkpGPWBiuccMUXDsuJaCWJbuABdY7CyiJMv1jdHYkjabygSxehPVyEDefWAtjBfv2vaeM1xv63jadbmpKYFxft7qmuT9HvVxiGvRgs4RQFxy8K4rtFBca3HNs1mDaaY81gy9MGXyw7BS5Fniu92jaJpsWDdg6Y3AQBLZtrpJy2obEZ4yzJaCVT7JUNPAyyCUNLck393VFLoEkaD9CU5npK5R7tj1c1G3gkMNQXnSXy5NpSj8deMmXV5qz3JKu1nq2caGQKcqjzy2gLkExdm674AMFjSg9yFjK6VqASXQ17NKtWRUvaYoxGbHDAFQaMKWKh8QLm22QA9mKT8NksLptWozbgDvafnQLNMvezLU5bvKV5o75PAWYiRB56RcYfEhzaB6YWdgL7TJicyY5rFi6Az8UZ7wqB3N5iMuZdpxhKn5KbZDxyuUMuvVt24i5LVPPmmwQtqxMoJ4aLo48a2YvDW6TAkdQjNjvn6KcEEz6GTixujb1YHhMUD8v4AepWKEwKz1ddEca1P2wLQjbpihCuaqbxeohnuZZLogJdUBojBEDgrnrrVpPBaLLEkGSpkJbtrsKUuEeBo1AF3yNgHftLbynGpobVF5DhmsmddmiA6c8vSTokJxHhjpnW8mAcNHBRtmVJCT7VkdHSAhNypM4Hivwfx5jCccG9LauKmCeRMDzHiA57TX9W6ttcPHSvUyQorARQAd2oeNY4H83hZjHh9Bt8iwKZRt4xK6hrTR8tif7hq8eURXrGH9Ys7TzykXK8FHHWvLNzNnYf3E4a9NkD43MjfKvMM1hj4Q2K8MHbmRCqrmFrHP5kim9shq6mhLPTgwha32nvnrBkfPQVPwpGTzKuwE\u0026select=CdsQ7jVNkogQhRzQR3e28Ek39AZ4Ma2y37k5zJaf9EZmQhMjy8GtGm4LGU6dRFuAVG7mYww5xDrQAE74KHQ3Kk1e6661RmcmNALAUjtHyCmrTVBMCnBGNiuq1y7EzmxoodYHU1BV1rnoefQAw2kTBtbWi11hV1P4LcwFCcXfUWF6rpRC7ehEnUCTqUV4bkGVJPLcmk9mdmiGwa2YgmnSShNGPVGZiEi1rMVECyngSRVdqdZwAeXBGWFLfqF1KbZeCo4MTF4SSmFupJ9zLhYbuojEbopyFWHQ6xs3sq9epPeaQziLM4Js7oFYRmuFWUYdFqnZngmewXWmi7tQAgVqhiT6dMjG2eTdfgX6WuRSuoHALkh2XJhHA6GfZLUcxC5Ni9YyKuBTamtaYarbNNJJ8z15WWvuUkLpjgHdEpE2h924xFdu8aoZNuiQxYGvcndaW1BTGMXS5fTKPqYfe2n8Ky2HWPkcX3hEXtyawu1F9BndKNaXLPgsdAoFBArBZnSe28YtSmTa5LRucKVBAxakvv5MWMXchAmpaGFQbZyYUoMgQLcJd7Y96x6zSR7nhwr5Ar81BrmqYz2WFLuk7osUbwsc9HbSG6CQt8p6Vg2u7DjKaZXW8pjkPHAKrHWtHEDiJPJ5rj6VsdFm3\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340796-c9e91b13-8ee0-4a67-bcde-8cf3aaa7ba99.jpg\"\u003e \u003c/a\u003e | \u003ca href=\"http://play.aimstack.io:10002/images?grouping=E1zQzcmtDR3wibEa1MVysTvCyZEv1T8ixkCxTWExCyMnHtX2HyiF9eszvPgfd2xdJ5TUTKGpSs1bsLVq5tHAV3uWtsZmmckn6HjNtVCMyQDJpwhiEy5tAyw\u0026select=2NEXuD7fFoaLcwRjymjA1wLmUrGs9s3AiXcCW82C367SwJt18CAB6xzkMGowrUDuDwggE1huaPVcQJpQUsmAQx1CnGiqCUBp2jPMd5mMNPX2QKQMcmvu9ZykBNkeBvCQFPd9ERuQD2g1EjWuvyJ3H53mAZTfp94LCXvR9CUsG5ei2CjQUzfZLM6DCyUr1GPaEVnY5f1EwzicNxXuoutkBgqCqaobJ7Do4q4eHAA6ooiWU6ekS3D2sLj6qYwhVTjfGCPfbWwBiH83nFkY3fLExzdeTY2zeUHeeYikQR9S7xHbVD8WvjekdQVp8X4dNLJZxiVmEqHpPRnU3ZrYsMhE7yFAAgjJwPNUzLTt6YFrtZBcmc4rwAC2oyrqysUSEr6gzL6LcJ6yuqDGf9D5tzftHbTLDkhc8B2sCgTS\u0026images=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\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340790-bc7b7a21-e8a1-43a1-809d-4060b5bfb60f.jpg\"\u003e \u003c/a\u003e |\r\n| Training logs of a neural translation model(from WMT'19 competition). | Training logs of 'lightweight' GAN, proposed in ICLR 2021. |\r\n\r\n| FastSpeech 2 | Simple MNIST |\r\n|:---:|:---:|\r\n| \u003ca href=\"http://play.aimstack.io:10004/runs/d9e89aa7875e44b2ba85612a/audios\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340778-dbe19620-2f27-4298-b0cb-caf3904760f1.jpg\"\u003e \u003c/a\u003e | \u003ca href=\"http://play.aimstack.io:10003/runs/7f083da898624a2c98e0f363/distributions\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340785-a7e4d9fd-d048-4207-8cd1-c4edff9cca6a.jpg\"\u003e \u003c/a\u003e |\r\n| Training logs of Microsoft's \"FastSpeech 2: Fast and High-Quality End-to-End Text to Speech\". | Simple MNIST training logs. |\r\n\r\n# Quick Start\r\n\r\nFollow the steps below to get started with Aim.\r\n\r\n**1. Install Aim on your training environment**\r\n\r\n```shell\r\npip3 install aim\r\n```\r\n\r\n**2. Integrate Aim with your code**\r\n\r\n```python\r\nfrom aim import Run\r\n\r\n# Initialize a new run\r\nrun = Run()\r\n\r\n# Log run parameters\r\nrun[\"hparams\"] = {\r\n    \"learning_rate\": 0.001,\r\n    \"batch_size\": 32,\r\n}\r\n\r\n# Log metrics\r\nfor i in range(10):\r\n    run.track(i, name='loss', step=i, context={ \"subset\":\"train\" })\r\n    run.track(i, name='acc', step=i, context={ \"subset\":\"train\" })\r\n```\r\n\r\n_See the full list of supported trackable objects(e.g. images, text, etc) [here](https://aimstack.readthedocs.io/en/latest/quick_start/supported_types.html)._\r\n\r\n**3. Run the training as usual and start Aim UI**\r\n\r\n```shell\r\naim up\r\n```\r\n\r\n**4. Or query runs programmatically via SDK**\r\n\r\n```python\r\nfrom aim import Repo\r\n\r\nmy_repo = Repo('/path/to/aim/repo')\r\n\r\nquery = \"metric.name == 'loss'\" # Example query\r\n\r\n# Get collection of metrics\r\nfor run_metrics_collection in my_repo.query_metrics(query).iter_runs():\r\n    for metric in run_metrics_collection:\r\n        # Get run params\r\n        params = metric.run[...]\r\n        # Get metric values\r\n        steps, metric_values = metric.values.sparse_numpy()\r\n```\r\n\r\n# Integrations\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate PyTorch Lightning\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.pytorch_lightning import AimLogger\r\n\r\n# ...\r\ntrainer = pl.Trainer(logger=AimLogger(experiment='experiment_name'))\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-lightning)._\r\n\r\n\u003c/details\u003e\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate Hugging Face\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.hugging_face import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='mnli')\r\ntrainer = Trainer(\r\n    model=model,\r\n    args=training_args,\r\n    train_dataset=train_dataset if training_args.do_train else None,\r\n    eval_dataset=eval_dataset if training_args.do_eval else None,\r\n    callbacks=[aim_callback],\r\n    # ...\r\n)\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-hugging-face)._\r\n\r\n\u003c/details\u003e\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate Keras \u0026 tf.keras\r\n\u003c/summary\u003e\r\n\r\n```python\r\nimport aim\r\n\r\n# ...\r\nmodel.fit(x_train, y_train, epochs=epochs, callbacks=[\r\n    aim.keras.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\n    \r\n    # Use aim.tensorflow.AimCallback in case of tf.keras\r\n    aim.tensorflow.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\n])\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-keras-tf-keras)._\r\n\r\n\u003c/details\u003e\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate KerasTuner\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.keras_tuner import AimCallback\r\n\r\n# ...\r\ntuner.search(\r\n    train_ds,\r\n    validation_data=test_ds,\r\n    callbacks=[AimCallback(tuner=tuner, repo='.', experiment='keras_tuner_test')],\r\n)\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-kerastuner)._\r\n\r\n\u003c/details\u003e\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate XGBoost\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.xgboost import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\nbst = xgb.train(param, xg_train, num_round, watchlist, callbacks=[aim_callback])\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-xgboost)._\r\n\u003c/details\u003e\r\n\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate CatBoost\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.catboost import AimLogger\r\n\r\n# ...\r\nmodel.fit(train_data, train_labels, log_cout=AimLogger(loss_function='Logloss'), logging_level=\"Info\")\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-catboost)._\r\n\u003c/details\u003e\r\n\r\n\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate fastai\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.fastai import AimCallback\r\n\r\n# ...\r\nlearn = cnn_learner(dls, resnet18, pretrained=True,\r\n                    loss_func=CrossEntropyLossFlat(),\r\n                    metrics=accuracy, model_dir=\"/tmp/model/\",\r\n                    cbs=AimCallback(repo='.', experiment='fastai_test'))\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-fastai)._\r\n\u003c/details\u003e\r\n\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate LightGBM\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.lightgbm import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(experiment='lgb_test')\r\naim_callback.experiment['hparams'] = params\r\n\r\ngbm = lgb.train(params,\r\n                lgb_train,\r\n                num_boost_round=20,\r\n                valid_sets=lgb_eval,\r\n                callbacks=[aim_callback, lgb.early_stopping(stopping_rounds=5)])\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-lightgbm)._\r\n\u003c/details\u003e\r\n\r\n\r\n\u003cdetails\u003e\r\n\u003csummary\u003e\r\n  Integrate PyTorch Ignite\r\n\u003c/summary\u003e\r\n\r\n```python\r\nfrom aim.pytorch_ignite import AimLogger\r\n\r\n# ...\r\naim_logger = AimLogger()\r\n\r\naim_logger.log_params({\r\n    \"model\": model.__class__.__name__,\r\n    \"pytorch_version\": str(torch.__version__),\r\n    \"ignite_version\": str(ignite.__version__),\r\n})\r\n\r\naim_logger.attach_output_handler(\r\n    trainer,\r\n    event_name=Events.ITERATION_COMPLETED,\r\n    tag=\"train\",\r\n    output_transform=lambda loss: {'loss': loss}\r\n)\r\n# ...\r\n```\r\n\r\n_See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-ignite)._\r\n\u003c/details\u003e\r\n\r\n# Comparisons to familiar tools\r\n\r\n### Tensorboard\r\n**Training run comparison**\r\n\r\nOrder of magnitude faster training run comparison with Aim\r\n- The tracked params are first class citizens at Aim. You can search, group, aggregate via params - deeply explore all the tracked data (metrics, params, images) on the UI.\r\n- With tensorboard the users are forced to record those parameters in the training run name to be able to search and compare. This causes a super-tedius comparison experience and usability issues on the UI when there are many experiments and params. **TensorBoard doesn't have features to group, aggregate the metrics**\r\n\r\n**Scalability**\r\n\r\n- Aim is built to handle 1000s of training runs - both on the backend and on the UI.\r\n- TensorBoard becomes really slow and hard to use when a few hundred training runs are queried / compared.\r\n\r\n**Beloved TB visualizations to be added on Aim**\r\n\r\n- Embedding projector.\r\n- Neural network visualization.\r\n\r\n### MLFlow\r\nMLFlow is an end-to-end ML Lifecycle tool.\r\nAim is focused on training tracking.\r\nThe main differences of Aim and MLflow are around the UI scalability and run comparison features.\r\n\r\n**Run comparison**\r\n\r\n- Aim treats tracked parameters as first-class citizens. Users can query runs, metrics, images and filter using the params.\r\n- MLFlow does have a search by tracked config, but there are no grouping, aggregation, subplotting by hyparparams and other comparison features available.\r\n\r\n**UI Scalability**\r\n\r\n- Aim UI can handle several thousands of metrics at the same time smoothly with 1000s of steps. It may get shaky when you explore 1000s of metrics with 10000s of steps each. But we are constantly optimizing!\r\n- MLflow UI becomes slow to use when there are a few hundreds of runs.\r\n\r\n### Weights and Biases\r\n\r\nHosted vs self-hosted\r\n- Weights and Biases is a hosted closed-source MLOps platform.\r\n- Aim is self-hosted, free and open-source experiment tracking tool.\r\n\r\n# Roadmap\r\n\r\n## Detailed Sprints\r\n\r\n:sparkle: The [Aim product roadmap](https://github.com/orgs/aimhubio/projects/3)\r\n\r\n- The `Backlog` contains the issues we are going to choose from and prioritize weekly\r\n- The issues are mainly prioritized by the highly-requested features\r\n\r\n## High-level roadmap\r\n\r\nThe high-level features we are going to work on the next few months\r\n\r\n### Done\r\n  - [x] Live updates (Shipped: _Oct 18 2021_)\r\n  - [x] Images tracking and visualization (Start: _Oct 18 2021_, Shipped: _Nov 19 2021_)\r\n  - [x] Distributions tracking and visualization (Start: _Nov 10 2021_, Shipped: _Dec 3 2021_)\r\n  - [x] Jupyter integration (Start: _Nov 18 2021_, Shipped: _Dec 3 2021_)\r\n  - [x] Audio tracking and visualization (Start: _Dec 6 2021_, Shipped: _Dec 17 2021_)\r\n  - [x] Transcripts tracking and visualization (Start: _Dec 6 2021_, Shipped: _Dec 17 2021_)\r\n  - [x] Plotly integration (Start: _Dec 1 2021_, Shipped: _Dec 17 2021_)\r\n  - [x] Colab integration (Start: _Nov 18 2021_, Shipped: _Dec 17 2021_)\r\n  - [x] Centralized tracking server (Start: _Oct 18 2021_, Shipped: _Jan 22 2022_)\r\n  - [x] Tensorboard adaptor - visualize TensorBoard logs with Aim (Start: _Dec 17 2021_, Shipped: _Feb 3 2022_)\r\n  - [x] Track git info, env vars, CLI arguments, dependencies (Start: _Jan 17 2022_, Shipped: _Feb 3 2022_)\r\n  - [x] MLFlow adaptor (visualize MLflow logs with Aim) (Start: _Feb 14 2022_, Shipped: _Feb 22 2022_)\r\n  - [x] Activeloop Hub integration (Start: _Feb 14 2022_, Shipped: _Feb 22 2022_)\r\n  - [x] PyTorch-Ignite integration (Start: _Feb 14 2022_, Shipped: _Feb 22 2022_)\r\n  - [x] Run summary and overview info(system params, CLI args, git info, ...) (Start: _Feb 14 2022_, Shipped: _Mar 9 2022_)\r\n  - [x] Add DVC related metadata into aim run (Start: _Mar 7 2022_, Shipped: _Mar 26 2022_)\r\n  - [x] Ability to attach notes to Run from UI (Start: _Mar 7 2022_, Shipped: _Apr 29 2022_)\r\n  - [x] Fairseq integration (Start: _Mar 27 2022_, Shipped: _Mar 29 2022_)\r\n  - [x] LightGBM integration (Start: _Apr 14 2022_, Shipped: _May 17 2022_)\r\n  - [x] CatBoost integration (Start: _Apr 20 2022_, Shipped: _May 17 2022_)\r\n  - [x] Run execution details(display stdout/stderr logs) (Start: _Apr 25 2022_, Shipped: _May 17 2022_)\r\n  - [x] Long sequences(up to 5M of steps) support (Start: _Apr 25 2022_, Shipped: _Jun 22 2022_)\r\n  - [x] Figures Explorer (Start: _Mar 1 2022_, Shipped: _Aug 21 2022_)\r\n  - [x] Notify on stuck runs (Start: _Jul 22 2022_, Shipped: _Aug 21 2022_)\r\n  - [x] Integration with KerasTuner (Start: _Aug 10 2022_, Shipped: _Aug 21 2022_)\r\n  - [x] Integration with WandB (Start: _Aug 15 2022_, Shipped: _Aug 21 2022_)\r\n  - [x] Stable remote tracking server (Start: _Jun 15 2022_, Shipped: _Aug 21 2022_)\r\n  - [x] Integration with fast.ai (Start: _Aug 22 2022_, Shipped: _Oct 6 2022_)\r\n  - [x] Integration with MXNet (Start: _Sep 20 2022_, Shipped: _Oct 6 2022_)\r\n  - [x] Project overview page (Start: _Sep 1 2022_, Shipped: _Oct 6 2022_)\r\n  - [x] Remote tracking server scaling (Start: _Sep 11 2022_, Shipped: _Nov 26 2022_)\r\n  - [x] Integration with PaddlePaddle (Start: _Oct 2 2022_, Shipped: _Nov 26 2022_)\r\n  - [x] Integration with Optuna (Start: _Oct 2 2022_, Shipped: _Nov 26 2022_)\r\n  - [x] Audios Explorer (Start: _Oct 30 2022_, Shipped: _Nov 26 2022_)\r\n  - [x] Experiment page (Start: _Nov 9 2022_, Shipped: _Nov 26 2022_)\r\n\r\n### In Progress\r\n  - [ ] Aim SDK low-level interface (Start: _Aug 22 2022_, )\r\n  - [ ] HuggingFace datasets (Start: _Dec 29 2022_, )\r\n\r\n### To Do\r\n\r\n**Aim UI**\r\n\r\n- Runs management\r\n    - Runs explorer â€“ query and visualize runs data(images, audio, distributions, ...) in a central dashboard\r\n- Explorers\r\n    - Text Explorer\r\n    - Distributions Explorer\r\n- Dashboards â€“ customizable layouts with embedded explorers\r\n\r\n**SDK and Storage**\r\n\r\n- Scalability\r\n    - Smooth UI and SDK experience with over 10.000 runs\r\n- Runs management\r\n    - CLI interfaces\r\n        - Reporting - runs summary and run details in a CLI compatible format\r\n        - Manipulations â€“ copy, move, delete runs, params and sequences\r\n\r\n**Integrations**\r\n\r\n- ML Frameworks:\r\n    - Shortlist: MONAI, SpaCy, Raytune\r\n- Resource management tools\r\n    - Shortlist: Kubeflow, Slurm\r\n- Workflow orchestration tools\r\n- Others: Hydra, Google MLMD, Streamlit, ...\r\n\r\n### On hold\r\n\r\n- scikit-learn integration\r\n- Cloud storage support â€“ store runs blob(e.g. images) data on the cloud (Start: _Mar 21 2022_)\r\n- Artifact storage â€“ store files, model checkpoints, and beyond (Start: _Mar 21 2022_)\r\n\r\n## Community\r\n\r\n### If you have questions\r\n\r\n1. [Read the docs](https://aimstack.readthedocs.io/en/latest/)\r\n2. [Open a feature request or report a bug](https://github.com/aimhubio/aim/issues)\r\n3. [Join Discord community server](https://community.aimstack.io/)","html":"\u003cp\u003e\u003ca href=\"\"\u003e\u003cimg src=\"https://img.shields.io/badge/platform-Linux%20%7C%20macOS-blue\" alt=\"Platform Support\"\u003e\u003c/a\u003e\r\n\u003ca href=\"https://pypi.org/project/aim/\"\u003e\u003cimg src=\"https://img.shields.io/pypi/pyversions/aim\" alt=\"PyPI - Python Version\"\u003e\u003c/a\u003e\r\n\u003ca href=\"https://pypi.org/project/aim/\"\u003e\u003cimg src=\"https://img.shields.io/pypi/v/aim?color=yellow\" alt=\"PyPI Package\"\u003e\u003c/a\u003e\r\n\u003ca href=\"https://opensource.org/licenses/Apache-2.0\"\u003e\u003cimg src=\"https://img.shields.io/badge/License-Apache%202.0-orange.svg\" alt=\"License\"\u003e\u003c/a\u003e\r\n\u003ca href=\"https://pypi.org/project/aim/\"\u003e\u003cimg src=\"https://img.shields.io/pypi/dw/aim?color=green\" alt=\"PyPI Downloads\"\u003e\u003c/a\u003e\r\n\u003ca href=\"http://github.com/aimhubio/aim/issues\"\u003e\u003cimg src=\"https://img.shields.io/github/issues/aimhubio/aim\" alt=\"Issues\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003eAbout Aim\u003c/h1\u003e\n\u003cp\u003e| Track and version ML runs | Visualize runs via beautiful UI | Query runs metadata via SDK |\r\n|:--------------------:|:------------------------:|:-------------------:|\r\n|  |  |  |\u003c/p\u003e\n\u003cp\u003eAim is an open-source, self-hosted ML experiment tracking tool.\r\nIt's good at tracking lots (1000s) of training runs and it allows you to compare them with a performant and beautiful UI.\u003c/p\u003e\n\u003cp\u003eYou can use not only the great Aim UI but also its SDK to query your runs' metadata programmatically.\r\nThat's especially useful for automations and additional analysis on a Jupyter Notebook.\u003c/p\u003e\n\u003cp\u003eAim's mission is to democratize AI dev tools.\u003c/p\u003e\n\u003ch1\u003eWhy use Aim?\u003c/h1\u003e\n\u003ch3\u003eCompare 100s of runs in a few clicks - build models faster\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCompare, group and aggregate 100s of metrics thanks to effective visualizations.\u003c/li\u003e\n\u003cli\u003eAnalyze, learn correlations and patterns between hparams and metrics.\u003c/li\u003e\n\u003cli\u003eEasy pythonic search to query the runs you want to explore.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eDeep dive into details of each run for easy debugging\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eHyperparameters, metrics, images, distributions, audio, text - all available at hand on an intuitive UI to understand the performance of your model.\u003c/li\u003e\n\u003cli\u003eEasily track plots built via your favourite visualisation tools, like plotly and matplotlib.\u003c/li\u003e\n\u003cli\u003eAnalyze system resource usage to effectively utilize computational resources.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eHave all relevant information organised and accessible for easy governance\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCentralized dashboard to holistically view all your runs, their hparams and results.\u003c/li\u003e\n\u003cli\u003eUse SDK to query/access all your runs and tracked metadata.\u003c/li\u003e\n\u003cli\u003eYou own your data - Aim is open source and self hosted.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003eDemos\u003c/h1\u003e\n\u003cp\u003e| Machine translation | lightweight-GAN |\r\n|:---:|:---:|\r\n|    |    |\r\n| Training logs of a neural translation model(from WMT'19 competition). | Training logs of 'lightweight' GAN, proposed in ICLR 2021. |\u003c/p\u003e\n\u003cp\u003e| FastSpeech 2 | Simple MNIST |\r\n|:---:|:---:|\r\n|    |    |\r\n| Training logs of Microsoft's \"FastSpeech 2: Fast and High-Quality End-to-End Text to Speech\". | Simple MNIST training logs. |\u003c/p\u003e\n\u003ch1\u003eQuick Start\u003c/h1\u003e\n\u003cp\u003eFollow the steps below to get started with Aim.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Aim on your training environment\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003epip3 install aim\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Integrate Aim with your code\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim import Run\r\n\r\n# Initialize a new run\r\nrun = Run()\r\n\r\n# Log run parameters\r\nrun[\"hparams\"] = {\r\n    \"learning_rate\": 0.001,\r\n    \"batch_size\": 32,\r\n}\r\n\r\n# Log metrics\r\nfor i in range(10):\r\n    run.track(i, name='loss', step=i, context={ \"subset\":\"train\" })\r\n    run.track(i, name='acc', step=i, context={ \"subset\":\"train\" })\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee the full list of supported trackable objects(e.g. images, text, etc) \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/supported_types.html\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. Run the training as usual and start Aim UI\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eaim up\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e4. Or query runs programmatically via SDK\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim import Repo\r\n\r\nmy_repo = Repo('/path/to/aim/repo')\r\n\r\nquery = \"metric.name == 'loss'\" # Example query\r\n\r\n# Get collection of metrics\r\nfor run_metrics_collection in my_repo.query_metrics(query).iter_runs():\r\n    for metric in run_metrics_collection:\r\n        # Get run params\r\n        params = metric.run[...]\r\n        # Get metric values\r\n        steps, metric_values = metric.values.sparse_numpy()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003eIntegrations\u003c/h1\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.pytorch_lightning import AimLogger\r\n\r\n# ...\r\ntrainer = pl.Trainer(logger=AimLogger(experiment='experiment_name'))\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-lightning\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.hugging_face import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='mnli')\r\ntrainer = Trainer(\r\n    model=model,\r\n    args=training_args,\r\n    train_dataset=train_dataset if training_args.do_train else None,\r\n    eval_dataset=eval_dataset if training_args.do_eval else None,\r\n    callbacks=[aim_callback],\r\n    # ...\r\n)\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-hugging-face\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport aim\r\n\r\n# ...\r\nmodel.fit(x_train, y_train, epochs=epochs, callbacks=[\r\n    aim.keras.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\n    \r\n    # Use aim.tensorflow.AimCallback in case of tf.keras\r\n    aim.tensorflow.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\n])\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-keras-tf-keras\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.keras_tuner import AimCallback\r\n\r\n# ...\r\ntuner.search(\r\n    train_ds,\r\n    validation_data=test_ds,\r\n    callbacks=[AimCallback(tuner=tuner, repo='.', experiment='keras_tuner_test')],\r\n)\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-kerastuner\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.xgboost import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\nbst = xgb.train(param, xg_train, num_round, watchlist, callbacks=[aim_callback])\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-xgboost\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.catboost import AimLogger\r\n\r\n# ...\r\nmodel.fit(train_data, train_labels, log_cout=AimLogger(loss_function='Logloss'), logging_level=\"Info\")\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-catboost\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.fastai import AimCallback\r\n\r\n# ...\r\nlearn = cnn_learner(dls, resnet18, pretrained=True,\r\n                    loss_func=CrossEntropyLossFlat(),\r\n                    metrics=accuracy, model_dir=\"/tmp/model/\",\r\n                    cbs=AimCallback(repo='.', experiment='fastai_test'))\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-fastai\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.lightgbm import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(experiment='lgb_test')\r\naim_callback.experiment['hparams'] = params\r\n\r\ngbm = lgb.train(params,\r\n                lgb_train,\r\n                num_boost_round=20,\r\n                valid_sets=lgb_eval,\r\n                callbacks=[aim_callback, lgb.early_stopping(stopping_rounds=5)])\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-lightgbm\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.pytorch_ignite import AimLogger\r\n\r\n# ...\r\naim_logger = AimLogger()\r\n\r\naim_logger.log_params({\r\n    \"model\": model.__class__.__name__,\r\n    \"pytorch_version\": str(torch.__version__),\r\n    \"ignite_version\": str(ignite.__version__),\r\n})\r\n\r\naim_logger.attach_output_handler(\r\n    trainer,\r\n    event_name=Events.ITERATION_COMPLETED,\r\n    tag=\"train\",\r\n    output_transform=lambda loss: {'loss': loss}\r\n)\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-ignite\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003ch1\u003eComparisons to familiar tools\u003c/h1\u003e\n\u003ch3\u003eTensorboard\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eTraining run comparison\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eOrder of magnitude faster training run comparison with Aim\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe tracked params are first class citizens at Aim. You can search, group, aggregate via params - deeply explore all the tracked data (metrics, params, images) on the UI.\u003c/li\u003e\n\u003cli\u003eWith tensorboard the users are forced to record those parameters in the training run name to be able to search and compare. This causes a super-tedius comparison experience and usability issues on the UI when there are many experiments and params. \u003cstrong\u003eTensorBoard doesn't have features to group, aggregate the metrics\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eScalability\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAim is built to handle 1000s of training runs - both on the backend and on the UI.\u003c/li\u003e\n\u003cli\u003eTensorBoard becomes really slow and hard to use when a few hundred training runs are queried / compared.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eBeloved TB visualizations to be added on Aim\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmbedding projector.\u003c/li\u003e\n\u003cli\u003eNeural network visualization.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eMLFlow\u003c/h3\u003e\n\u003cp\u003eMLFlow is an end-to-end ML Lifecycle tool.\r\nAim is focused on training tracking.\r\nThe main differences of Aim and MLflow are around the UI scalability and run comparison features.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRun comparison\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAim treats tracked parameters as first-class citizens. Users can query runs, metrics, images and filter using the params.\u003c/li\u003e\n\u003cli\u003eMLFlow does have a search by tracked config, but there are no grouping, aggregation, subplotting by hyparparams and other comparison features available.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eUI Scalability\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAim UI can handle several thousands of metrics at the same time smoothly with 1000s of steps. It may get shaky when you explore 1000s of metrics with 10000s of steps each. But we are constantly optimizing!\u003c/li\u003e\n\u003cli\u003eMLflow UI becomes slow to use when there are a few hundreds of runs.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eWeights and Biases\u003c/h3\u003e\n\u003cp\u003eHosted vs self-hosted\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWeights and Biases is a hosted closed-source MLOps platform.\u003c/li\u003e\n\u003cli\u003eAim is self-hosted, free and open-source experiment tracking tool.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003eRoadmap\u003c/h1\u003e\n\u003ch2\u003eDetailed Sprints\u003c/h2\u003e\n\u003cp\u003e:sparkle: The \u003ca href=\"https://github.com/orgs/aimhubio/projects/3\"\u003eAim product roadmap\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe \u003ccode\u003eBacklog\u003c/code\u003e contains the issues we are going to choose from and prioritize weekly\u003c/li\u003e\n\u003cli\u003eThe issues are mainly prioritized by the highly-requested features\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eHigh-level roadmap\u003c/h2\u003e\n\u003cp\u003eThe high-level features we are going to work on the next few months\u003c/p\u003e\n\u003ch3\u003eDone\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e[x] Live updates (Shipped: \u003cem\u003eOct 18 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Images tracking and visualization (Start: \u003cem\u003eOct 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eNov 19 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Distributions tracking and visualization (Start: \u003cem\u003eNov 10 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 3 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Jupyter integration (Start: \u003cem\u003eNov 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 3 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Audio tracking and visualization (Start: \u003cem\u003eDec 6 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Transcripts tracking and visualization (Start: \u003cem\u003eDec 6 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Plotly integration (Start: \u003cem\u003eDec 1 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Colab integration (Start: \u003cem\u003eNov 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Centralized tracking server (Start: \u003cem\u003eOct 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eJan 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Tensorboard adaptor - visualize TensorBoard logs with Aim (Start: \u003cem\u003eDec 17 2021\u003c/em\u003e, Shipped: \u003cem\u003eFeb 3 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Track git info, env vars, CLI arguments, dependencies (Start: \u003cem\u003eJan 17 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 3 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] MLFlow adaptor (visualize MLflow logs with Aim) (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Activeloop Hub integration (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] PyTorch-Ignite integration (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Run summary and overview info(system params, CLI args, git info, ...) (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eMar 9 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Add DVC related metadata into aim run (Start: \u003cem\u003eMar 7 2022\u003c/em\u003e, Shipped: \u003cem\u003eMar 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Ability to attach notes to Run from UI (Start: \u003cem\u003eMar 7 2022\u003c/em\u003e, Shipped: \u003cem\u003eApr 29 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Fairseq integration (Start: \u003cem\u003eMar 27 2022\u003c/em\u003e, Shipped: \u003cem\u003eMar 29 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] LightGBM integration (Start: \u003cem\u003eApr 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eMay 17 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] CatBoost integration (Start: \u003cem\u003eApr 20 2022\u003c/em\u003e, Shipped: \u003cem\u003eMay 17 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Run execution details(display stdout/stderr logs) (Start: \u003cem\u003eApr 25 2022\u003c/em\u003e, Shipped: \u003cem\u003eMay 17 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Long sequences(up to 5M of steps) support (Start: \u003cem\u003eApr 25 2022\u003c/em\u003e, Shipped: \u003cem\u003eJun 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Figures Explorer (Start: \u003cem\u003eMar 1 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Notify on stuck runs (Start: \u003cem\u003eJul 22 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with KerasTuner (Start: \u003cem\u003eAug 10 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with WandB (Start: \u003cem\u003eAug 15 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Stable remote tracking server (Start: \u003cem\u003eJun 15 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with fast.ai (Start: \u003cem\u003eAug 22 2022\u003c/em\u003e, Shipped: \u003cem\u003eOct 6 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with MXNet (Start: \u003cem\u003eSep 20 2022\u003c/em\u003e, Shipped: \u003cem\u003eOct 6 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Project overview page (Start: \u003cem\u003eSep 1 2022\u003c/em\u003e, Shipped: \u003cem\u003eOct 6 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Remote tracking server scaling (Start: \u003cem\u003eSep 11 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with PaddlePaddle (Start: \u003cem\u003eOct 2 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with Optuna (Start: \u003cem\u003eOct 2 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Audios Explorer (Start: \u003cem\u003eOct 30 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Experiment page (Start: \u003cem\u003eNov 9 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eIn Progress\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e[ ] Aim SDK low-level interface (Start: \u003cem\u003eAug 22 2022\u003c/em\u003e, )\u003c/li\u003e\n\u003cli\u003e[ ] HuggingFace datasets (Start: \u003cem\u003eDec 29 2022\u003c/em\u003e, )\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eTo Do\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eAim UI\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRuns management\n\u003cul\u003e\n\u003cli\u003eRuns explorer â€“ query and visualize runs data(images, audio, distributions, ...) in a central dashboard\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eExplorers\n\u003cul\u003e\n\u003cli\u003eText Explorer\u003c/li\u003e\n\u003cli\u003eDistributions Explorer\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDashboards â€“ customizable layouts with embedded explorers\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSDK and Storage\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScalability\n\u003cul\u003e\n\u003cli\u003eSmooth UI and SDK experience with over 10.000 runs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eRuns management\n\u003cul\u003e\n\u003cli\u003eCLI interfaces\n\u003cul\u003e\n\u003cli\u003eReporting - runs summary and run details in a CLI compatible format\u003c/li\u003e\n\u003cli\u003eManipulations â€“ copy, move, delete runs, params and sequences\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eIntegrations\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eML Frameworks:\n\u003cul\u003e\n\u003cli\u003eShortlist: MONAI, SpaCy, Raytune\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eResource management tools\n\u003cul\u003e\n\u003cli\u003eShortlist: Kubeflow, Slurm\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWorkflow orchestration tools\u003c/li\u003e\n\u003cli\u003eOthers: Hydra, Google MLMD, Streamlit, ...\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eOn hold\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003escikit-learn integration\u003c/li\u003e\n\u003cli\u003eCloud storage support â€“ store runs blob(e.g. images) data on the cloud (Start: \u003cem\u003eMar 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eArtifact storage â€“ store files, model checkpoints, and beyond (Start: \u003cem\u003eMar 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eCommunity\u003c/h2\u003e\n\u003ch3\u003eIf you have questions\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://aimstack.readthedocs.io/en/latest/\"\u003eRead the docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/aimhubio/aim/issues\"\u003eOpen a feature request or report a bug\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://community.aimstack.io/\"\u003eJoin Discord community server\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003ca href=\"\"\u003e\u003cimg src=\"https://img.shields.io/badge/platform-Linux%20%7C%20macOS-blue\" alt=\"Platform Support\"\u003e\u003c/a\u003e\r\n\u003ca href=\"https://pypi.org/project/aim/\"\u003e\u003cimg src=\"https://img.shields.io/pypi/pyversions/aim\" alt=\"PyPI - Python Version\"\u003e\u003c/a\u003e\r\n\u003ca href=\"https://pypi.org/project/aim/\"\u003e\u003cimg src=\"https://img.shields.io/pypi/v/aim?color=yellow\" alt=\"PyPI Package\"\u003e\u003c/a\u003e\r\n\u003ca href=\"https://opensource.org/licenses/Apache-2.0\"\u003e\u003cimg src=\"https://img.shields.io/badge/License-Apache%202.0-orange.svg\" alt=\"License\"\u003e\u003c/a\u003e\r\n\u003ca href=\"https://pypi.org/project/aim/\"\u003e\u003cimg src=\"https://img.shields.io/pypi/dw/aim?color=green\" alt=\"PyPI Downloads\"\u003e\u003c/a\u003e\r\n\u003ca href=\"http://github.com/aimhubio/aim/issues\"\u003e\u003cimg src=\"https://img.shields.io/github/issues/aimhubio/aim\" alt=\"Issues\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003eAbout Aim\u003c/h1\u003e\n\u003cp\u003e| Track and version ML runs | Visualize runs via beautiful UI | Query runs metadata via SDK |\r\n|:--------------------:|:------------------------:|:-------------------:|\r\n|  |  |  |\u003c/p\u003e\n\u003cp\u003eAim is an open-source, self-hosted ML experiment tracking tool.\r\nIt's good at tracking lots (1000s) of training runs and it allows you to compare them with a performant and beautiful UI.\u003c/p\u003e\n\u003cp\u003eYou can use not only the great Aim UI but also its SDK to query your runs' metadata programmatically.\r\nThat's especially useful for automations and additional analysis on a Jupyter Notebook.\u003c/p\u003e\n\u003cp\u003eAim's mission is to democratize AI dev tools.\u003c/p\u003e\n\u003ch1\u003eWhy use Aim?\u003c/h1\u003e\n\u003ch3\u003eCompare 100s of runs in a few clicks - build models faster\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCompare, group and aggregate 100s of metrics thanks to effective visualizations.\u003c/li\u003e\n\u003cli\u003eAnalyze, learn correlations and patterns between hparams and metrics.\u003c/li\u003e\n\u003cli\u003eEasy pythonic search to query the runs you want to explore.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eDeep dive into details of each run for easy debugging\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eHyperparameters, metrics, images, distributions, audio, text - all available at hand on an intuitive UI to understand the performance of your model.\u003c/li\u003e\n\u003cli\u003eEasily track plots built via your favourite visualisation tools, like plotly and matplotlib.\u003c/li\u003e\n\u003cli\u003eAnalyze system resource usage to effectively utilize computational resources.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eHave all relevant information organised and accessible for easy governance\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCentralized dashboard to holistically view all your runs, their hparams and results.\u003c/li\u003e\n\u003cli\u003eUse SDK to query/access all your runs and tracked metadata.\u003c/li\u003e\n\u003cli\u003eYou own your data - Aim is open source and self hosted.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003eDemos\u003c/h1\u003e\n\u003cp\u003e| Machine translation | lightweight-GAN |\r\n|:---:|:---:|\r\n|    |    |\r\n| Training logs of a neural translation model(from WMT'19 competition). | Training logs of 'lightweight' GAN, proposed in ICLR 2021. |\u003c/p\u003e\n\u003cp\u003e| FastSpeech 2 | Simple MNIST |\r\n|:---:|:---:|\r\n|    |    |\r\n| Training logs of Microsoft's \"FastSpeech 2: Fast and High-Quality End-to-End Text to Speech\". | Simple MNIST training logs. |\u003c/p\u003e\n\u003ch1\u003eQuick Start\u003c/h1\u003e\n\u003cp\u003eFollow the steps below to get started with Aim.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Aim on your training environment\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003epip3 install aim\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Integrate Aim with your code\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim import Run\r\n\r\n# Initialize a new run\r\nrun = Run()\r\n\r\n# Log run parameters\r\nrun[\"hparams\"] = {\r\n    \"learning_rate\": 0.001,\r\n    \"batch_size\": 32,\r\n}\r\n\r\n# Log metrics\r\nfor i in range(10):\r\n    run.track(i, name='loss', step=i, context={ \"subset\":\"train\" })\r\n    run.track(i, name='acc', step=i, context={ \"subset\":\"train\" })\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee the full list of supported trackable objects(e.g. images, text, etc) \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/supported_types.html\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. Run the training as usual and start Aim UI\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eaim up\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e4. Or query runs programmatically via SDK\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim import Repo\r\n\r\nmy_repo = Repo('/path/to/aim/repo')\r\n\r\nquery = \"metric.name == 'loss'\" # Example query\r\n\r\n# Get collection of metrics\r\nfor run_metrics_collection in my_repo.query_metrics(query).iter_runs():\r\n    for metric in run_metrics_collection:\r\n        # Get run params\r\n        params = metric.run[...]\r\n        # Get metric values\r\n        steps, metric_values = metric.values.sparse_numpy()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003eIntegrations\u003c/h1\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.pytorch_lightning import AimLogger\r\n\r\n# ...\r\ntrainer = pl.Trainer(logger=AimLogger(experiment='experiment_name'))\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-lightning\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.hugging_face import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='mnli')\r\ntrainer = Trainer(\r\n    model=model,\r\n    args=training_args,\r\n    train_dataset=train_dataset if training_args.do_train else None,\r\n    eval_dataset=eval_dataset if training_args.do_eval else None,\r\n    callbacks=[aim_callback],\r\n    # ...\r\n)\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-hugging-face\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport aim\r\n\r\n# ...\r\nmodel.fit(x_train, y_train, epochs=epochs, callbacks=[\r\n    aim.keras.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\n    \r\n    # Use aim.tensorflow.AimCallback in case of tf.keras\r\n    aim.tensorflow.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\n])\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-keras-tf-keras\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.keras_tuner import AimCallback\r\n\r\n# ...\r\ntuner.search(\r\n    train_ds,\r\n    validation_data=test_ds,\r\n    callbacks=[AimCallback(tuner=tuner, repo='.', experiment='keras_tuner_test')],\r\n)\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-kerastuner\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.xgboost import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\r\nbst = xgb.train(param, xg_train, num_round, watchlist, callbacks=[aim_callback])\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-xgboost\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.catboost import AimLogger\r\n\r\n# ...\r\nmodel.fit(train_data, train_labels, log_cout=AimLogger(loss_function='Logloss'), logging_level=\"Info\")\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-catboost\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.fastai import AimCallback\r\n\r\n# ...\r\nlearn = cnn_learner(dls, resnet18, pretrained=True,\r\n                    loss_func=CrossEntropyLossFlat(),\r\n                    metrics=accuracy, model_dir=\"/tmp/model/\",\r\n                    cbs=AimCallback(repo='.', experiment='fastai_test'))\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-fastai\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.lightgbm import AimCallback\r\n\r\n# ...\r\naim_callback = AimCallback(experiment='lgb_test')\r\naim_callback.experiment['hparams'] = params\r\n\r\ngbm = lgb.train(params,\r\n                lgb_train,\r\n                num_boost_round=20,\r\n                valid_sets=lgb_eval,\r\n                callbacks=[aim_callback, lgb.early_stopping(stopping_rounds=5)])\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-lightgbm\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.pytorch_ignite import AimLogger\r\n\r\n# ...\r\naim_logger = AimLogger()\r\n\r\naim_logger.log_params({\r\n    \"model\": model.__class__.__name__,\r\n    \"pytorch_version\": str(torch.__version__),\r\n    \"ignite_version\": str(ignite.__version__),\r\n})\r\n\r\naim_logger.attach_output_handler(\r\n    trainer,\r\n    event_name=Events.ITERATION_COMPLETED,\r\n    tag=\"train\",\r\n    output_transform=lambda loss: {'loss': loss}\r\n)\r\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-ignite\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003ch1\u003eComparisons to familiar tools\u003c/h1\u003e\n\u003ch3\u003eTensorboard\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eTraining run comparison\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eOrder of magnitude faster training run comparison with Aim\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe tracked params are first class citizens at Aim. You can search, group, aggregate via params - deeply explore all the tracked data (metrics, params, images) on the UI.\u003c/li\u003e\n\u003cli\u003eWith tensorboard the users are forced to record those parameters in the training run name to be able to search and compare. This causes a super-tedius comparison experience and usability issues on the UI when there are many experiments and params. \u003cstrong\u003eTensorBoard doesn't have features to group, aggregate the metrics\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eScalability\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAim is built to handle 1000s of training runs - both on the backend and on the UI.\u003c/li\u003e\n\u003cli\u003eTensorBoard becomes really slow and hard to use when a few hundred training runs are queried / compared.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eBeloved TB visualizations to be added on Aim\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmbedding projector.\u003c/li\u003e\n\u003cli\u003eNeural network visualization.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eMLFlow\u003c/h3\u003e\n\u003cp\u003eMLFlow is an end-to-end ML Lifecycle tool.\r\nAim is focused on training tracking.\r\nThe main differences of Aim and MLflow are around the UI scalability and run comparison features.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRun comparison\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAim treats tracked parameters as first-class citizens. Users can query runs, metrics, images and filter using the params.\u003c/li\u003e\n\u003cli\u003eMLFlow does have a search by tracked config, but there are no grouping, aggregation, subplotting by hyparparams and other comparison features available.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eUI Scalability\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAim UI can handle several thousands of metrics at the same time smoothly with 1000s of steps. It may get shaky when you explore 1000s of metrics with 10000s of steps each. But we are constantly optimizing!\u003c/li\u003e\n\u003cli\u003eMLflow UI becomes slow to use when there are a few hundreds of runs.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eWeights and Biases\u003c/h3\u003e\n\u003cp\u003eHosted vs self-hosted\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWeights and Biases is a hosted closed-source MLOps platform.\u003c/li\u003e\n\u003cli\u003eAim is self-hosted, free and open-source experiment tracking tool.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003eRoadmap\u003c/h1\u003e\n\u003ch2\u003eDetailed Sprints\u003c/h2\u003e\n\u003cp\u003e:sparkle: The \u003ca href=\"https://github.com/orgs/aimhubio/projects/3\"\u003eAim product roadmap\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe \u003ccode\u003eBacklog\u003c/code\u003e contains the issues we are going to choose from and prioritize weekly\u003c/li\u003e\n\u003cli\u003eThe issues are mainly prioritized by the highly-requested features\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eHigh-level roadmap\u003c/h2\u003e\n\u003cp\u003eThe high-level features we are going to work on the next few months\u003c/p\u003e\n\u003ch3\u003eDone\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e[x] Live updates (Shipped: \u003cem\u003eOct 18 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Images tracking and visualization (Start: \u003cem\u003eOct 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eNov 19 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Distributions tracking and visualization (Start: \u003cem\u003eNov 10 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 3 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Jupyter integration (Start: \u003cem\u003eNov 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 3 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Audio tracking and visualization (Start: \u003cem\u003eDec 6 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Transcripts tracking and visualization (Start: \u003cem\u003eDec 6 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Plotly integration (Start: \u003cem\u003eDec 1 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Colab integration (Start: \u003cem\u003eNov 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Centralized tracking server (Start: \u003cem\u003eOct 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eJan 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Tensorboard adaptor - visualize TensorBoard logs with Aim (Start: \u003cem\u003eDec 17 2021\u003c/em\u003e, Shipped: \u003cem\u003eFeb 3 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Track git info, env vars, CLI arguments, dependencies (Start: \u003cem\u003eJan 17 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 3 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] MLFlow adaptor (visualize MLflow logs with Aim) (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Activeloop Hub integration (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] PyTorch-Ignite integration (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Run summary and overview info(system params, CLI args, git info, ...) (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eMar 9 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Add DVC related metadata into aim run (Start: \u003cem\u003eMar 7 2022\u003c/em\u003e, Shipped: \u003cem\u003eMar 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Ability to attach notes to Run from UI (Start: \u003cem\u003eMar 7 2022\u003c/em\u003e, Shipped: \u003cem\u003eApr 29 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Fairseq integration (Start: \u003cem\u003eMar 27 2022\u003c/em\u003e, Shipped: \u003cem\u003eMar 29 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] LightGBM integration (Start: \u003cem\u003eApr 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eMay 17 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] CatBoost integration (Start: \u003cem\u003eApr 20 2022\u003c/em\u003e, Shipped: \u003cem\u003eMay 17 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Run execution details(display stdout/stderr logs) (Start: \u003cem\u003eApr 25 2022\u003c/em\u003e, Shipped: \u003cem\u003eMay 17 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Long sequences(up to 5M of steps) support (Start: \u003cem\u003eApr 25 2022\u003c/em\u003e, Shipped: \u003cem\u003eJun 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Figures Explorer (Start: \u003cem\u003eMar 1 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Notify on stuck runs (Start: \u003cem\u003eJul 22 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with KerasTuner (Start: \u003cem\u003eAug 10 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with WandB (Start: \u003cem\u003eAug 15 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Stable remote tracking server (Start: \u003cem\u003eJun 15 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with fast.ai (Start: \u003cem\u003eAug 22 2022\u003c/em\u003e, Shipped: \u003cem\u003eOct 6 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with MXNet (Start: \u003cem\u003eSep 20 2022\u003c/em\u003e, Shipped: \u003cem\u003eOct 6 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Project overview page (Start: \u003cem\u003eSep 1 2022\u003c/em\u003e, Shipped: \u003cem\u003eOct 6 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Remote tracking server scaling (Start: \u003cem\u003eSep 11 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with PaddlePaddle (Start: \u003cem\u003eOct 2 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Integration with Optuna (Start: \u003cem\u003eOct 2 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Audios Explorer (Start: \u003cem\u003eOct 30 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003e[x] Experiment page (Start: \u003cem\u003eNov 9 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eIn Progress\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e[ ] Aim SDK low-level interface (Start: \u003cem\u003eAug 22 2022\u003c/em\u003e, )\u003c/li\u003e\n\u003cli\u003e[ ] HuggingFace datasets (Start: \u003cem\u003eDec 29 2022\u003c/em\u003e, )\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eTo Do\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eAim UI\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRuns management\n\u003cul\u003e\n\u003cli\u003eRuns explorer â€“ query and visualize runs data(images, audio, distributions, ...) in a central dashboard\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eExplorers\n\u003cul\u003e\n\u003cli\u003eText Explorer\u003c/li\u003e\n\u003cli\u003eDistributions Explorer\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDashboards â€“ customizable layouts with embedded explorers\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSDK and Storage\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScalability\n\u003cul\u003e\n\u003cli\u003eSmooth UI and SDK experience with over 10.000 runs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eRuns management\n\u003cul\u003e\n\u003cli\u003eCLI interfaces\n\u003cul\u003e\n\u003cli\u003eReporting - runs summary and run details in a CLI compatible format\u003c/li\u003e\n\u003cli\u003eManipulations â€“ copy, move, delete runs, params and sequences\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eIntegrations\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eML Frameworks:\n\u003cul\u003e\n\u003cli\u003eShortlist: MONAI, SpaCy, Raytune\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eResource management tools\n\u003cul\u003e\n\u003cli\u003eShortlist: Kubeflow, Slurm\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWorkflow orchestration tools\u003c/li\u003e\n\u003cli\u003eOthers: Hydra, Google MLMD, Streamlit, ...\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eOn hold\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003escikit-learn integration\u003c/li\u003e\n\u003cli\u003eCloud storage support â€“ store runs blob(e.g. images) data on the cloud (Start: \u003cem\u003eMar 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eArtifact storage â€“ store files, model checkpoints, and beyond (Start: \u003cem\u003eMar 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eCommunity\u003c/h2\u003e\n\u003ch3\u003eIf you have questions\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://aimstack.readthedocs.io/en/latest/\"\u003eRead the docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/aimhubio/aim/issues\"\u003eOpen a feature request or report a bug\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://community.aimstack.io/\"\u003eJoin Discord community server\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e"},"_id":"posts/new-post.md","_raw":{"sourceFilePath":"posts/new-post.md","sourceFileName":"new-post.md","sourceFileDir":"posts","contentType":"markdown","flattenedPath":"posts/new-post"},"type":"Post"},{"title":"post with new markdown","date":"2023-01-25T14:33:02.283Z","author":"Ashot","description":"description","slug":"post-with-new-markdown","image":"/images/dynamic/video-thumbnail.png","draft":false,"categories":["test"],"body":{"raw":"bï»¿arev dzez\n\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/154338760-edfe1885-06f3-4e02-87fe-4b13a403516b.png\"/\u003e\n  \u003ch3\u003eAn easy-to-use \u0026 supercharged open-source experiment tracker\u003c/h3\u003e\n  Aim logs your training runs, enables a beautiful UI to compare them and an API to query them programmatically.\n\u003c/div\u003e\n\n\u003cbr/\u003e\n\n\u003cimg src=\"https://user-images.githubusercontent.com/13848158/154338753-34484cda-95b8-4da8-a610-7fdf198c05fd.png\"/\u003e\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"#about-aim\"\u003e\u003cb\u003eAbout\u003c/b\u003e\u003c/a\u003e \u0026bull;\n  \u003ca href=\"#why-use-aim\"\u003e\u003cb\u003eFeatures\u003c/b\u003e\u003c/a\u003e \u0026bull;\n  \u003ca href=\"#demos\"\u003e\u003cb\u003eDemos\u003c/b\u003e\u003c/a\u003e \u0026bull;\n  \u003ca href=\"https://github.com/aimhubio/aim/tree/main/examples\"\u003e\u003cb\u003eExamples\u003c/b\u003e\u003c/a\u003e \u0026bull;\n  \u003ca href=\"#quick-start\"\u003e\u003cb\u003eQuick Start\u003c/b\u003e\u003c/a\u003e \u0026bull;\n  \u003ca href=\"https://aimstack.readthedocs.io/en/latest/\"\u003e\u003cb\u003eDocumentation\u003c/b\u003e\u003c/a\u003e \u0026bull;\n  \u003ca href=\"#roadmap\"\u003e\u003cb\u003eRoadmap\u003c/b\u003e\u003c/a\u003e \u0026bull;\n  \u003ca href=\"https://community.aimstack.io/\"\u003e\u003cb\u003eDiscord Community\u003c/b\u003e\u003c/a\u003e \u0026bull;\n  \u003ca href=\"https://twitter.com/aimstackio\"\u003e\u003cb\u003eTwitter\u003c/b\u003e\u003c/a\u003e\n\u003c/p\u003e\n\n\u003cdiv align=\"center\"\u003e\n  \n  \\[![Platform Support](https://img.shields.io/badge/platform-Linux%20%7C%20macOS-blue)]()\n  \\[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/aim)](https://pypi.org/project/aim/)\n  \\[![PyPI Package](https://img.shields.io/pypi/v/aim?color=yellow)](https://pypi.org/project/aim/)\n  \\[![License](https://img.shields.io/badge/License-Apache%202.0-orange.svg)](https://opensource.org/licenses/Apache-2.0)\n  \\[![PyPI Downloads](https://img.shields.io/pypi/dw/aim?color=green)](https://pypi.org/project/aim/)\n  \\[![Issues](https://img.shields.io/github/issues/aimhubio/aim)](http://github.com/aimhubio/aim/issues)\n  \n\u003c/div\u003e\n\n\u003cdiv align=\"center\"\u003e\n  \u003csub\u003eIntegrates seamlessly with your favorite tools\u003c/sub\u003e\n  \u003cbr/\u003e\n  \u003cbr/\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354389-d0301620-77ea-4629-a743-f7aa249e14b5.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354496-b39d7b1c-63ef-40f0-9e59-c08d2c5e337c.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354380-3755c741-6960-42ca-b93e-84a8791f088c.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354342-7df0ef5e-63d2-4df7-b9f1-d2fc0e95f53f.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354392-afbff3de-c845-4d86-855d-53df569f91d1.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354355-89210506-e7e5-4d37-b2d6-ad3fda62ef13.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354397-8af8e1d3-4067-405e-9d42-1f131663ed22.png\" width=\"60\" /\u003e\n  \u003cbr/\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354513-f7486146-3891-4f3f-934f-e58bbf9ce695.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354500-c0471ce6-b2ce-4172-b9e4-07a197256303.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354361-9f911785-008d-4b75-877e-651e026cf47e.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354373-1879ae61-b5d1-41f0-a4f1-04b639b6f05e.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354483-75d9853f-7154-4d95-8190-9ad7a73d6654.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354329-cf7c3352-a72a-478d-82a7-04e3833b03b7.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354349-dcdf3bc3-d7a9-4f34-8258-4824a57f59c7.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/13848158/155354471-518f1814-7a41-4b23-9caf-e516507343f1.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/48801049/165162736-2cc5da39-38aa-4093-874f-e56d0ba9cea2.png\" width=\"60\" /\u003e\n  \u003cimg src=\"https://user-images.githubusercontent.com/48801049/165074282-36ad18eb-1124-434d-8439-728c22cd7ac7.png\" width=\"60\" /\u003e\n\u003c/div\u003e\n\n\u003cdiv align=\"center\"\u003e\n  \u003cbr/\u003e\n  \u003ckbd\u003e\n    \u003cimg width=\"650px\" src=\"https://user-images.githubusercontent.com/13848158/136374529-af267918-5dc6-4a4e-8ed2-f6333a332f96.gif\" /\u003e\n  \u003c/kbd\u003e\n\u003c/div\u003e\n\n# About Aim\n\n| Track and version ML runs                                                                                                        | Visualize runs via beautiful UI                                                                                                  | Query runs metadata via SDK                                                                                                      |\n| -------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |\n| \u003cimg width=\"600px\" src=\"https://user-images.githubusercontent.com/13848158/154337794-e9310239-6614-41b3-a95b-bb91f0bb6c4f.png\"/\u003e | \u003cimg width=\"600px\" src=\"https://user-images.githubusercontent.com/13848158/154337788-03fe5b31-0fa3-44af-ae79-2861707d8602.png\"/\u003e | \u003cimg width=\"600px\" src=\"https://user-images.githubusercontent.com/13848158/154337793-85175c78-5659-4dd0-bb2d-05017278e2fa.png\"/\u003e |\n\nAim is an open-source, self-hosted ML experiment tracking tool. \nIt's good at tracking lots (1000s) of training runs and it allows you to compare them with a performant and beautiful UI.\n\nYou can use not only the great Aim UI but also its SDK to query your runs' metadata programmatically. \nThat's especially useful for automations and additional analysis on a Jupyter Notebook.\n\nAim's mission is to democratize AI dev tools.\n\n# Why use Aim?\n\n### Compare 100s of runs in a few clicks - build models faster\n\n* Compare, group and aggregate 100s of metrics thanks to effective visualizations.\n* Analyze, learn correlations and patterns between hparams and metrics.\n* Easy pythonic search to query the runs you want to explore.\n\n### Deep dive into details of each run for easy debugging\n\n* Hyperparameters, metrics, images, distributions, audio, text - all available at hand on an intuitive UI to understand the performance of your model.\n* Easily track plots built via your favourite visualisation tools, like plotly and matplotlib.\n* Analyze system resource usage to effectively utilize computational resources.\n\n### Have all relevant information organised and accessible for easy governance\n\n* Centralized dashboard to holistically view all your runs, their hparams and results.\n* Use SDK to query/access all your runs and tracked metadata.\n* You own your data - Aim is open source and self hosted.\n\n# Demos\n\n| Machine translation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | lightweight-GAN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| \u003ca href=\"http://play.aimstack.io:10001/metrics?grouping=HQGdK9Xxy35e6sY1CYkCmk1WbWMN2AsCNfJJ3d1RJYLtrVPMoF5UpGiA6CF8bEJnfzRsKpqespf3AEuKSVrhUYvYk9MxzNGA9XZWYUf6phEg8AMbZGLRVDXnAPDuo8tueqsST1ZLizWzQwDYJWHUza6pyB2Eojt9uWqNHUdb858TqDRnCJzqiVJXKXEzFWUyvU8MckJo1qpqWWCTb4GpYN6DUJZx2GXDGR21e2xxd4m7PmNUnbA9B3apLttZoipJF6c3v7tNUKmb6irpqnNB3yc57tqYDa1XZuKfDxkMtyFdQ1x95K4jjsTVwhftEWLze35QNcxNXRCGGS9o9yEfTLG26GUX2zjPZFCjjMGU6vV7z1xRccK8MyoGrLSgAQCbvk68dTGBHpXUBvCRq8N\u0026chart=FviZzVrt4fVQPjpCLr9sVGGrcR5etSroyqambiKpm3nTgpyv4eQxKuwNX9uN8UtKmzYUhUyTMBEANHmtbwjLApkvnYeNbxGNC6PVcoqi65m1XJnSrvgt8WiD89BapFAWRUwAGx6SWD7KZPsk3RQyysU7W7FjD3Q99NusxFGhsEfD6HXc7i8xH9KHDRGjLwh6x9VTtSp4FS8HEvpLSiiJoX7LCTi8pB7dXvrQ8G5w3jPsFz4qXYFdsVaCNL1BpFFZuiqQNkfbnM84gEq7UmiV1VzM4oS3AgQHxADG3kpBVp6eKTey9F1Swd4FcUkFA9QEPjgQgqwRGjkquZ2bdDDVLBnCh7JPvboP2kifCiZZ5MDdV9MMx6PKHp4DusWyWLXiHQYPkpGPWBiuccMUXDsuJaCWJbuABdY7CyiJMv1jdHYkjabygSxehPVyEDefWAtjBfv2vaeM1xv63jadbmpKYFxft7qmuT9HvVxiGvRgs4RQFxy8K4rtFBca3HNs1mDaaY81gy9MGXyw7BS5Fniu92jaJpsWDdg6Y3AQBLZtrpJy2obEZ4yzJaCVT7JUNPAyyCUNLck393VFLoEkaD9CU5npK5R7tj1c1G3gkMNQXnSXy5NpSj8deMmXV5qz3JKu1nq2caGQKcqjzy2gLkExdm674AMFjSg9yFjK6VqASXQ17NKtWRUvaYoxGbHDAFQaMKWKh8QLm22QA9mKT8NksLptWozbgDvafnQLNMvezLU5bvKV5o75PAWYiRB56RcYfEhzaB6YWdgL7TJicyY5rFi6Az8UZ7wqB3N5iMuZdpxhKn5KbZDxyuUMuvVt24i5LVPPmmwQtqxMoJ4aLo48a2YvDW6TAkdQjNjvn6KcEEz6GTixujb1YHhMUD8v4AepWKEwKz1ddEca1P2wLQjbpihCuaqbxeohnuZZLogJdUBojBEDgrnrrVpPBaLLEkGSpkJbtrsKUuEeBo1AF3yNgHftLbynGpobVF5DhmsmddmiA6c8vSTokJxHhjpnW8mAcNHBRtmVJCT7VkdHSAhNypM4Hivwfx5jCccG9LauKmCeRMDzHiA57TX9W6ttcPHSvUyQorARQAd2oeNY4H83hZjHh9Bt8iwKZRt4xK6hrTR8tif7hq8eURXrGH9Ys7TzykXK8FHHWvLNzNnYf3E4a9NkD43MjfKvMM1hj4Q2K8MHbmRCqrmFrHP5kim9shq6mhLPTgwha32nvnrBkfPQVPwpGTzKuwE\u0026select=CdsQ7jVNkogQhRzQR3e28Ek39AZ4Ma2y37k5zJaf9EZmQhMjy8GtGm4LGU6dRFuAVG7mYww5xDrQAE74KHQ3Kk1e6661RmcmNALAUjtHyCmrTVBMCnBGNiuq1y7EzmxoodYHU1BV1rnoefQAw2kTBtbWi11hV1P4LcwFCcXfUWF6rpRC7ehEnUCTqUV4bkGVJPLcmk9mdmiGwa2YgmnSShNGPVGZiEi1rMVECyngSRVdqdZwAeXBGWFLfqF1KbZeCo4MTF4SSmFupJ9zLhYbuojEbopyFWHQ6xs3sq9epPeaQziLM4Js7oFYRmuFWUYdFqnZngmewXWmi7tQAgVqhiT6dMjG2eTdfgX6WuRSuoHALkh2XJhHA6GfZLUcxC5Ni9YyKuBTamtaYarbNNJJ8z15WWvuUkLpjgHdEpE2h924xFdu8aoZNuiQxYGvcndaW1BTGMXS5fTKPqYfe2n8Ky2HWPkcX3hEXtyawu1F9BndKNaXLPgsdAoFBArBZnSe28YtSmTa5LRucKVBAxakvv5MWMXchAmpaGFQbZyYUoMgQLcJd7Y96x6zSR7nhwr5Ar81BrmqYz2WFLuk7osUbwsc9HbSG6CQt8p6Vg2u7DjKaZXW8pjkPHAKrHWtHEDiJPJ5rj6VsdFm3\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340796-c9e91b13-8ee0-4a67-bcde-8cf3aaa7ba99.jpg\"/\u003e \u003c/a\u003e | \u003ca href=\"http://play.aimstack.io:10002/images?grouping=E1zQzcmtDR3wibEa1MVysTvCyZEv1T8ixkCxTWExCyMnHtX2HyiF9eszvPgfd2xdJ5TUTKGpSs1bsLVq5tHAV3uWtsZmmckn6HjNtVCMyQDJpwhiEy5tAyw\u0026select=2NEXuD7fFoaLcwRjymjA1wLmUrGs9s3AiXcCW82C367SwJt18CAB6xzkMGowrUDuDwggE1huaPVcQJpQUsmAQx1CnGiqCUBp2jPMd5mMNPX2QKQMcmvu9ZykBNkeBvCQFPd9ERuQD2g1EjWuvyJ3H53mAZTfp94LCXvR9CUsG5ei2CjQUzfZLM6DCyUr1GPaEVnY5f1EwzicNxXuoutkBgqCqaobJ7Do4q4eHAA6ooiWU6ekS3D2sLj6qYwhVTjfGCPfbWwBiH83nFkY3fLExzdeTY2zeUHeeYikQR9S7xHbVD8WvjekdQVp8X4dNLJZxiVmEqHpPRnU3ZrYsMhE7yFAAgjJwPNUzLTt6YFrtZBcmc4rwAC2oyrqysUSEr6gzL6LcJ6yuqDGf9D5tzftHbTLDkhc8B2sCgTS\u0026images=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\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340790-bc7b7a21-e8a1-43a1-809d-4060b5bfb60f.jpg\"\u003e \u003c/a\u003e |\n| Training logs of a neural translation model(from WMT'19 competition).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Training logs of 'lightweight' GAN, proposed in ICLR 2021.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n\n| FastSpeech 2                                                                                                                                                                                                        | Simple MNIST                                                                                                                                                                                                               |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| \u003ca href=\"http://play.aimstack.io:10004/runs/d9e89aa7875e44b2ba85612a/audios\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340778-dbe19620-2f27-4298-b0cb-caf3904760f1.jpg\"/\u003e \u003c/a\u003e | \u003ca href=\"http://play.aimstack.io:10003/runs/7f083da898624a2c98e0f363/distributions\"\u003e \u003cimg width=\"800px\" src=\"https://user-images.githubusercontent.com/13848158/154340785-a7e4d9fd-d048-4207-8cd1-c4edff9cca6a.jpg\"/\u003e \u003c/a\u003e |\n| Training logs of Microsoft's \"FastSpeech 2: Fast and High-Quality End-to-End Text to Speech\".                                                                                                                       | Simple MNIST training logs.                                                                                                                                                                                                |\n\n# Quick Start\n\nFollow the steps below to get started with Aim.\n\n**1. Install Aim on your training environment**\n\n```shell\npip3 install aim\n```\n\n**2. Integrate Aim with your code**\n\n```python\nfrom aim import Run\n\n# Initialize a new run\nrun = Run()\n\n# Log run parameters\nrun[\"hparams\"] = {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n}\n\n# Log metrics\nfor i in range(10):\n    run.track(i, name='loss', step=i, context={ \"subset\":\"train\" })\n    run.track(i, name='acc', step=i, context={ \"subset\":\"train\" })\n```\n\n*See the full list of supported trackable objects(e.g. images, text, etc) [here](https://aimstack.readthedocs.io/en/latest/quick_start/supported_types.html).*\n\n**3. Run the training as usual and start Aim UI**\n\n```shell\naim up\n```\n\n**4. Or query runs programmatically via SDK**\n\n```python\nfrom aim import Repo\n\nmy_repo = Repo('/path/to/aim/repo')\n\nquery = \"metric.name == 'loss'\" # Example query\n\n# Get collection of metrics\nfor run_metrics_collection in my_repo.query_metrics(query).iter_runs():\n    for metric in run_metrics_collection:\n        # Get run params\n        params = metric.run[...]\n        # Get metric values\n        steps, metric_values = metric.values.sparse_numpy()\n```\n\n# Integrations\n\n\u003cdetails\u003e\n\u003csummary\u003e\n  Integrate PyTorch Lightning\n\u003c/summary\u003e\n\n```python\nfrom aim.pytorch_lightning import AimLogger\n\n# ...\ntrainer = pl.Trainer(logger=AimLogger(experiment='experiment_name'))\n# ...\n```\n\n*See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-lightning).*\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\n  Integrate Hugging Face\n\u003c/summary\u003e\n\n```python\nfrom aim.hugging_face import AimCallback\n\n# ...\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='mnli')\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset if training_args.do_train else None,\n    eval_dataset=eval_dataset if training_args.do_eval else None,\n    callbacks=[aim_callback],\n    # ...\n)\n# ...\n```\n\n*See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-hugging-face).*\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\n  Integrate Keras \u0026 tf.keras\n\u003c/summary\u003e\n\n```python\nimport aim\n\n# ...\nmodel.fit(x_train, y_train, epochs=epochs, callbacks=[\n    aim.keras.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\n    \n    # Use aim.tensorflow.AimCallback in case of tf.keras\n    aim.tensorflow.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\n])\n# ...\n```\n\n*See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-keras-tf-keras).*\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\n  Integrate KerasTuner\n\u003c/summary\u003e\n\n```python\nfrom aim.keras_tuner import AimCallback\n\n# ...\ntuner.search(\n    train_ds,\n    validation_data=test_ds,\n    callbacks=[AimCallback(tuner=tuner, repo='.', experiment='keras_tuner_test')],\n)\n# ...\n```\n\n*See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-kerastuner).*\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\n  Integrate XGBoost\n\u003c/summary\u003e\n\n```python\nfrom aim.xgboost import AimCallback\n\n# ...\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\nbst = xgb.train(param, xg_train, num_round, watchlist, callbacks=[aim_callback])\n# ...\n```\n\n*See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-xgboost).*\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\n  Integrate CatBoost\n\u003c/summary\u003e\n\n```python\nfrom aim.catboost import AimLogger\n\n# ...\nmodel.fit(train_data, train_labels, log_cout=AimLogger(loss_function='Logloss'), logging_level=\"Info\")\n# ...\n```\n\n*See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-catboost).*\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\n  Integrate fastai\n\u003c/summary\u003e\n\n```python\nfrom aim.fastai import AimCallback\n\n# ...\nlearn = cnn_learner(dls, resnet18, pretrained=True,\n                    loss_func=CrossEntropyLossFlat(),\n                    metrics=accuracy, model_dir=\"/tmp/model/\",\n                    cbs=AimCallback(repo='.', experiment='fastai_test'))\n# ...\n```\n\n*See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-fastai).*\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\n  Integrate LightGBM\n\u003c/summary\u003e\n\n```python\nfrom aim.lightgbm import AimCallback\n\n# ...\naim_callback = AimCallback(experiment='lgb_test')\naim_callback.experiment['hparams'] = params\n\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=20,\n                valid_sets=lgb_eval,\n                callbacks=[aim_callback, lgb.early_stopping(stopping_rounds=5)])\n# ...\n```\n\n*See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-lightgbm).*\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\n  Integrate PyTorch Ignite\n\u003c/summary\u003e\n\n```python\nfrom aim.pytorch_ignite import AimLogger\n\n# ...\naim_logger = AimLogger()\n\naim_logger.log_params({\n    \"model\": model.__class__.__name__,\n    \"pytorch_version\": str(torch.__version__),\n    \"ignite_version\": str(ignite.__version__),\n})\n\naim_logger.attach_output_handler(\n    trainer,\n    event_name=Events.ITERATION_COMPLETED,\n    tag=\"train\",\n    output_transform=lambda loss: {'loss': loss}\n)\n# ...\n```\n\n*See documentation [here](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-ignite).*\n\n\u003c/details\u003e\n\n# Comparisons to familiar tools\n\n### Tensorboard\n\n**Training run comparison**\n\nOrder of magnitude faster training run comparison with Aim\n\n* The tracked params are first class citizens at Aim. You can search, group, aggregate via params - deeply explore all the tracked data (metrics, params, images) on the UI.\n* With tensorboard the users are forced to record those parameters in the training run name to be able to search and compare. This causes a super-tedius comparison experience and usability issues on the UI when there are many experiments and params. **TensorBoard doesn't have features to group, aggregate the metrics**\n\n**Scalability**\n\n* Aim is built to handle 1000s of training runs - both on the backend and on the UI.\n* TensorBoard becomes really slow and hard to use when a few hundred training runs are queried / compared.\n\n**Beloved TB visualizations to be added on Aim**\n\n* Embedding projector.\n* Neural network visualization.\n\n### MLFlow\n\nMLFlow is an end-to-end ML Lifecycle tool.\nAim is focused on training tracking.\nThe main differences of Aim and MLflow are around the UI scalability and run comparison features.\n\n**Run comparison**\n\n* Aim treats tracked parameters as first-class citizens. Users can query runs, metrics, images and filter using the params.\n* MLFlow does have a search by tracked config, but there are no grouping, aggregation, subplotting by hyparparams and other comparison features available.\n\n**UI Scalability**\n\n* Aim UI can handle several thousands of metrics at the same time smoothly with 1000s of steps. It may get shaky when you explore 1000s of metrics with 10000s of steps each. But we are constantly optimizing!\n* MLflow UI becomes slow to use when there are a few hundreds of runs.\n\n### Weights and Biases\n\nHosted vs self-hosted\n\n* Weights and Biases is a hosted closed-source MLOps platform.\n* Aim is self-hosted, free and open-source experiment tracking tool.\n\n# Roadmap\n\n## Detailed Sprints\n\n:sparkle: The [Aim product roadmap](https://github.com/orgs/aimhubio/projects/3)\n\n* The `Backlog` contains the issues we are going to choose from and prioritize weekly\n* The issues are mainly prioritized by the highly-requested features\n\n## High-level roadmap\n\nThe high-level features we are going to work on the next few months\n\n### Done\n\n* Live updates (Shipped: *Oct 18 2021*)\n* Images tracking and visualization (Start: *Oct 18 2021*, Shipped: *Nov 19 2021*)\n* Distributions tracking and visualization (Start: *Nov 10 2021*, Shipped: *Dec 3 2021*)\n* Jupyter integration (Start: *Nov 18 2021*, Shipped: *Dec 3 2021*)\n* Audio tracking and visualization (Start: *Dec 6 2021*, Shipped: *Dec 17 2021*)\n* Transcripts tracking and visualization (Start: *Dec 6 2021*, Shipped: *Dec 17 2021*)\n* Plotly integration (Start: *Dec 1 2021*, Shipped: *Dec 17 2021*)\n* Colab integration (Start: *Nov 18 2021*, Shipped: *Dec 17 2021*)\n* Centralized tracking server (Start: *Oct 18 2021*, Shipped: *Jan 22 2022*)\n* Tensorboard adaptor - visualize TensorBoard logs with Aim (Start: *Dec 17 2021*, Shipped: *Feb 3 2022*)\n* Track git info, env vars, CLI arguments, dependencies (Start: *Jan 17 2022*, Shipped: *Feb 3 2022*)\n* MLFlow adaptor (visualize MLflow logs with Aim) (Start: *Feb 14 2022*, Shipped: *Feb 22 2022*)\n* Activeloop Hub integration (Start: *Feb 14 2022*, Shipped: *Feb 22 2022*)\n* PyTorch-Ignite integration (Start: *Feb 14 2022*, Shipped: *Feb 22 2022*)\n* Run summary and overview info(system params, CLI args, git info, ...) (Start: *Feb 14 2022*, Shipped: *Mar 9 2022*)\n* Add DVC related metadata into aim run (Start: *Mar 7 2022*, Shipped: *Mar 26 2022*)\n* Ability to attach notes to Run from UI (Start: *Mar 7 2022*, Shipped: *Apr 29 2022*)\n* Fairseq integration (Start: *Mar 27 2022*, Shipped: *Mar 29 2022*)\n* LightGBM integration (Start: *Apr 14 2022*, Shipped: *May 17 2022*)\n* CatBoost integration (Start: *Apr 20 2022*, Shipped: *May 17 2022*)\n* Run execution details(display stdout/stderr logs) (Start: *Apr 25 2022*, Shipped: *May 17 2022*)\n* Long sequences(up to 5M of steps) support (Start: *Apr 25 2022*, Shipped: *Jun 22 2022*)\n* Figures Explorer (Start: *Mar 1 2022*, Shipped: *Aug 21 2022*)\n* Notify on stuck runs (Start: *Jul 22 2022*, Shipped: *Aug 21 2022*)\n* Integration with KerasTuner (Start: *Aug 10 2022*, Shipped: *Aug 21 2022*)\n* Integration with WandB (Start: *Aug 15 2022*, Shipped: *Aug 21 2022*)\n* Stable remote tracking server (Start: *Jun 15 2022*, Shipped: *Aug 21 2022*)\n* Integration with fast.ai (Start: *Aug 22 2022*, Shipped: *Oct 6 2022*)\n* Integration with MXNet (Start: *Sep 20 2022*, Shipped: *Oct 6 2022*)\n* Project overview page (Start: *Sep 1 2022*, Shipped: *Oct 6 2022*)\n* Remote tracking server scaling (Start: *Sep 11 2022*, Shipped: *Nov 26 2022*)\n* Integration with PaddlePaddle (Start: *Oct 2 2022*, Shipped: *Nov 26 2022*)\n* Integration with Optuna (Start: *Oct 2 2022*, Shipped: *Nov 26 2022*)\n* Audios Explorer (Start: *Oct 30 2022*, Shipped: *Nov 26 2022*)\n* Experiment page (Start: *Nov 9 2022*, Shipped: *Nov 26 2022*)\n\n### In Progress\n\n* Aim SDK low-level interface (Start: *Aug 22 2022*, )\n* HuggingFace datasets (Start: *Dec 29 2022*, )\n\n### To Do\n\n**Aim UI**\n\n* Runs management\n\n  * Runs explorer â€“ query and visualize runs data(images, audio, distributions, ...) in a central dashboard\n* Explorers\n\n  * Text Explorer\n  * Distributions Explorer\n* Dashboards â€“ customizable layouts with embedded explorers\n\n**SDK and Storage**\n\n* Scalability\n\n  * Smooth UI and SDK experience with over 10.000 runs\n* Runs management\n\n  * CLI interfaces\n\n    * Reporting - runs summary and run details in a CLI compatible format\n    * Manipulations â€“ copy, move, delete runs, params and sequences\n\n**Integrations**\n\n* ML Frameworks:\n\n  * Shortlist: MONAI, SpaCy, Raytune\n* Resource management tools\n\n  * Shortlist: Kubeflow, Slurm\n* Workflow orchestration tools\n* Others: Hydra, Google MLMD, Streamlit, ...\n\n### On hold\n\n* scikit-learn integration\n* Cloud storage support â€“ store runs blob(e.g. images) data on the cloud (Start: *Mar 21 2022*)\n* Artifact storage â€“ store files, model checkpoints, and beyond (Start: *Mar 21 2022*)\n\n## Community\n\n### If you have questions\n\n1. [Read the docs](https://aimstack.readthedocs.io/en/latest/)\n2. [Open a feature request or report a bug](https://github.com/aimhubio/aim/issues)\n3. [Join Discord community server](https://community.aimstack.io/)\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/_26BhViw28s\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen\u003e\u003c/iframe\u003e\n","html":"\u003cp\u003ebï»¿arev dzez\u003c/p\u003e\n\u003cp\u003e[\u003cimg src=\"https://img.shields.io/badge/platform-Linux%20%7C%20macOS-blue\" alt=\"Platform Support\"\u003e]()\n[\u003cimg src=\"https://img.shields.io/pypi/pyversions/aim\" alt=\"PyPI - Python Version\"\u003e](https://pypi.org/project/aim/)\n[\u003cimg src=\"https://img.shields.io/pypi/v/aim?color=yellow\" alt=\"PyPI Package\"\u003e](https://pypi.org/project/aim/)\n[\u003cimg src=\"https://img.shields.io/badge/License-Apache%202.0-orange.svg\" alt=\"License\"\u003e](https://opensource.org/licenses/Apache-2.0)\n[\u003cimg src=\"https://img.shields.io/pypi/dw/aim?color=green\" alt=\"PyPI Downloads\"\u003e](https://pypi.org/project/aim/)\n[\u003cimg src=\"https://img.shields.io/github/issues/aimhubio/aim\" alt=\"Issues\"\u003e](http://github.com/aimhubio/aim/issues)\u003c/p\u003e\n\u003ch1\u003eAbout Aim\u003c/h1\u003e\n\u003cp\u003e| Track and version ML runs                                                                                                        | Visualize runs via beautiful UI                                                                                                  | Query runs metadata via SDK                                                                                                      |\n| -------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |\n|  |  |  |\u003c/p\u003e\n\u003cp\u003eAim is an open-source, self-hosted ML experiment tracking tool.\nIt's good at tracking lots (1000s) of training runs and it allows you to compare them with a performant and beautiful UI.\u003c/p\u003e\n\u003cp\u003eYou can use not only the great Aim UI but also its SDK to query your runs' metadata programmatically.\nThat's especially useful for automations and additional analysis on a Jupyter Notebook.\u003c/p\u003e\n\u003cp\u003eAim's mission is to democratize AI dev tools.\u003c/p\u003e\n\u003ch1\u003eWhy use Aim?\u003c/h1\u003e\n\u003ch3\u003eCompare 100s of runs in a few clicks - build models faster\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCompare, group and aggregate 100s of metrics thanks to effective visualizations.\u003c/li\u003e\n\u003cli\u003eAnalyze, learn correlations and patterns between hparams and metrics.\u003c/li\u003e\n\u003cli\u003eEasy pythonic search to query the runs you want to explore.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eDeep dive into details of each run for easy debugging\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eHyperparameters, metrics, images, distributions, audio, text - all available at hand on an intuitive UI to understand the performance of your model.\u003c/li\u003e\n\u003cli\u003eEasily track plots built via your favourite visualisation tools, like plotly and matplotlib.\u003c/li\u003e\n\u003cli\u003eAnalyze system resource usage to effectively utilize computational resources.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eHave all relevant information organised and accessible for easy governance\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCentralized dashboard to holistically view all your runs, their hparams and results.\u003c/li\u003e\n\u003cli\u003eUse SDK to query/access all your runs and tracked metadata.\u003c/li\u003e\n\u003cli\u003eYou own your data - Aim is open source and self hosted.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003eDemos\u003c/h1\u003e\n\u003cp\u003e| Machine translation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | lightweight-GAN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n|    |    |\n| Training logs of a neural translation model(from WMT'19 competition).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Training logs of 'lightweight' GAN, proposed in ICLR 2021.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\u003c/p\u003e\n\u003cp\u003e| FastSpeech 2                                                                                                                                                                                                        | Simple MNIST                                                                                                                                                                                                               |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n|    |    |\n| Training logs of Microsoft's \"FastSpeech 2: Fast and High-Quality End-to-End Text to Speech\".                                                                                                                       | Simple MNIST training logs.                                                                                                                                                                                                |\u003c/p\u003e\n\u003ch1\u003eQuick Start\u003c/h1\u003e\n\u003cp\u003eFollow the steps below to get started with Aim.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Aim on your training environment\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003epip3 install aim\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Integrate Aim with your code\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim import Run\n\n# Initialize a new run\nrun = Run()\n\n# Log run parameters\nrun[\"hparams\"] = {\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n}\n\n# Log metrics\nfor i in range(10):\n    run.track(i, name='loss', step=i, context={ \"subset\":\"train\" })\n    run.track(i, name='acc', step=i, context={ \"subset\":\"train\" })\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee the full list of supported trackable objects(e.g. images, text, etc) \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/supported_types.html\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. Run the training as usual and start Aim UI\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eaim up\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e4. Or query runs programmatically via SDK\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim import Repo\n\nmy_repo = Repo('/path/to/aim/repo')\n\nquery = \"metric.name == 'loss'\" # Example query\n\n# Get collection of metrics\nfor run_metrics_collection in my_repo.query_metrics(query).iter_runs():\n    for metric in run_metrics_collection:\n        # Get run params\n        params = metric.run[...]\n        # Get metric values\n        steps, metric_values = metric.values.sparse_numpy()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003eIntegrations\u003c/h1\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.pytorch_lightning import AimLogger\n\n# ...\ntrainer = pl.Trainer(logger=AimLogger(experiment='experiment_name'))\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-lightning\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.hugging_face import AimCallback\n\n# ...\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='mnli')\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset if training_args.do_train else None,\n    eval_dataset=eval_dataset if training_args.do_eval else None,\n    callbacks=[aim_callback],\n    # ...\n)\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-hugging-face\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport aim\n\n# ...\nmodel.fit(x_train, y_train, epochs=epochs, callbacks=[\n    aim.keras.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\n    \n    # Use aim.tensorflow.AimCallback in case of tf.keras\n    aim.tensorflow.AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\n])\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-keras-tf-keras\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.keras_tuner import AimCallback\n\n# ...\ntuner.search(\n    train_ds,\n    validation_data=test_ds,\n    callbacks=[AimCallback(tuner=tuner, repo='.', experiment='keras_tuner_test')],\n)\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-kerastuner\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.xgboost import AimCallback\n\n# ...\naim_callback = AimCallback(repo='/path/to/logs/dir', experiment='experiment_name')\nbst = xgb.train(param, xg_train, num_round, watchlist, callbacks=[aim_callback])\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-xgboost\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.catboost import AimLogger\n\n# ...\nmodel.fit(train_data, train_labels, log_cout=AimLogger(loss_function='Logloss'), logging_level=\"Info\")\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-catboost\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.fastai import AimCallback\n\n# ...\nlearn = cnn_learner(dls, resnet18, pretrained=True,\n                    loss_func=CrossEntropyLossFlat(),\n                    metrics=accuracy, model_dir=\"/tmp/model/\",\n                    cbs=AimCallback(repo='.', experiment='fastai_test'))\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-fastai\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.lightgbm import AimCallback\n\n# ...\naim_callback = AimCallback(experiment='lgb_test')\naim_callback.experiment['hparams'] = params\n\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=20,\n                valid_sets=lgb_eval,\n                callbacks=[aim_callback, lgb.early_stopping(stopping_rounds=5)])\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-lightgbm\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom aim.pytorch_ignite import AimLogger\n\n# ...\naim_logger = AimLogger()\n\naim_logger.log_params({\n    \"model\": model.__class__.__name__,\n    \"pytorch_version\": str(torch.__version__),\n    \"ignite_version\": str(ignite.__version__),\n})\n\naim_logger.attach_output_handler(\n    trainer,\n    event_name=Events.ITERATION_COMPLETED,\n    tag=\"train\",\n    output_transform=lambda loss: {'loss': loss}\n)\n# ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eSee documentation \u003ca href=\"https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-ignite\"\u003ehere\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003ch1\u003eComparisons to familiar tools\u003c/h1\u003e\n\u003ch3\u003eTensorboard\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eTraining run comparison\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eOrder of magnitude faster training run comparison with Aim\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe tracked params are first class citizens at Aim. You can search, group, aggregate via params - deeply explore all the tracked data (metrics, params, images) on the UI.\u003c/li\u003e\n\u003cli\u003eWith tensorboard the users are forced to record those parameters in the training run name to be able to search and compare. This causes a super-tedius comparison experience and usability issues on the UI when there are many experiments and params. \u003cstrong\u003eTensorBoard doesn't have features to group, aggregate the metrics\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eScalability\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAim is built to handle 1000s of training runs - both on the backend and on the UI.\u003c/li\u003e\n\u003cli\u003eTensorBoard becomes really slow and hard to use when a few hundred training runs are queried / compared.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eBeloved TB visualizations to be added on Aim\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmbedding projector.\u003c/li\u003e\n\u003cli\u003eNeural network visualization.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eMLFlow\u003c/h3\u003e\n\u003cp\u003eMLFlow is an end-to-end ML Lifecycle tool.\nAim is focused on training tracking.\nThe main differences of Aim and MLflow are around the UI scalability and run comparison features.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRun comparison\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAim treats tracked parameters as first-class citizens. Users can query runs, metrics, images and filter using the params.\u003c/li\u003e\n\u003cli\u003eMLFlow does have a search by tracked config, but there are no grouping, aggregation, subplotting by hyparparams and other comparison features available.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eUI Scalability\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAim UI can handle several thousands of metrics at the same time smoothly with 1000s of steps. It may get shaky when you explore 1000s of metrics with 10000s of steps each. But we are constantly optimizing!\u003c/li\u003e\n\u003cli\u003eMLflow UI becomes slow to use when there are a few hundreds of runs.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eWeights and Biases\u003c/h3\u003e\n\u003cp\u003eHosted vs self-hosted\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWeights and Biases is a hosted closed-source MLOps platform.\u003c/li\u003e\n\u003cli\u003eAim is self-hosted, free and open-source experiment tracking tool.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003eRoadmap\u003c/h1\u003e\n\u003ch2\u003eDetailed Sprints\u003c/h2\u003e\n\u003cp\u003e:sparkle: The \u003ca href=\"https://github.com/orgs/aimhubio/projects/3\"\u003eAim product roadmap\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe \u003ccode\u003eBacklog\u003c/code\u003e contains the issues we are going to choose from and prioritize weekly\u003c/li\u003e\n\u003cli\u003eThe issues are mainly prioritized by the highly-requested features\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eHigh-level roadmap\u003c/h2\u003e\n\u003cp\u003eThe high-level features we are going to work on the next few months\u003c/p\u003e\n\u003ch3\u003eDone\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eLive updates (Shipped: \u003cem\u003eOct 18 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eImages tracking and visualization (Start: \u003cem\u003eOct 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eNov 19 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eDistributions tracking and visualization (Start: \u003cem\u003eNov 10 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 3 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eJupyter integration (Start: \u003cem\u003eNov 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 3 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eAudio tracking and visualization (Start: \u003cem\u003eDec 6 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eTranscripts tracking and visualization (Start: \u003cem\u003eDec 6 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003ePlotly integration (Start: \u003cem\u003eDec 1 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eColab integration (Start: \u003cem\u003eNov 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eDec 17 2021\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eCentralized tracking server (Start: \u003cem\u003eOct 18 2021\u003c/em\u003e, Shipped: \u003cem\u003eJan 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eTensorboard adaptor - visualize TensorBoard logs with Aim (Start: \u003cem\u003eDec 17 2021\u003c/em\u003e, Shipped: \u003cem\u003eFeb 3 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eTrack git info, env vars, CLI arguments, dependencies (Start: \u003cem\u003eJan 17 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 3 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eMLFlow adaptor (visualize MLflow logs with Aim) (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eActiveloop Hub integration (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003ePyTorch-Ignite integration (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eFeb 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eRun summary and overview info(system params, CLI args, git info, ...) (Start: \u003cem\u003eFeb 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eMar 9 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eAdd DVC related metadata into aim run (Start: \u003cem\u003eMar 7 2022\u003c/em\u003e, Shipped: \u003cem\u003eMar 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eAbility to attach notes to Run from UI (Start: \u003cem\u003eMar 7 2022\u003c/em\u003e, Shipped: \u003cem\u003eApr 29 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eFairseq integration (Start: \u003cem\u003eMar 27 2022\u003c/em\u003e, Shipped: \u003cem\u003eMar 29 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eLightGBM integration (Start: \u003cem\u003eApr 14 2022\u003c/em\u003e, Shipped: \u003cem\u003eMay 17 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eCatBoost integration (Start: \u003cem\u003eApr 20 2022\u003c/em\u003e, Shipped: \u003cem\u003eMay 17 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eRun execution details(display stdout/stderr logs) (Start: \u003cem\u003eApr 25 2022\u003c/em\u003e, Shipped: \u003cem\u003eMay 17 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eLong sequences(up to 5M of steps) support (Start: \u003cem\u003eApr 25 2022\u003c/em\u003e, Shipped: \u003cem\u003eJun 22 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eFigures Explorer (Start: \u003cem\u003eMar 1 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eNotify on stuck runs (Start: \u003cem\u003eJul 22 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eIntegration with KerasTuner (Start: \u003cem\u003eAug 10 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eIntegration with WandB (Start: \u003cem\u003eAug 15 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eStable remote tracking server (Start: \u003cem\u003eJun 15 2022\u003c/em\u003e, Shipped: \u003cem\u003eAug 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eIntegration with fast.ai (Start: \u003cem\u003eAug 22 2022\u003c/em\u003e, Shipped: \u003cem\u003eOct 6 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eIntegration with MXNet (Start: \u003cem\u003eSep 20 2022\u003c/em\u003e, Shipped: \u003cem\u003eOct 6 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eProject overview page (Start: \u003cem\u003eSep 1 2022\u003c/em\u003e, Shipped: \u003cem\u003eOct 6 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eRemote tracking server scaling (Start: \u003cem\u003eSep 11 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eIntegration with PaddlePaddle (Start: \u003cem\u003eOct 2 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eIntegration with Optuna (Start: \u003cem\u003eOct 2 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eAudios Explorer (Start: \u003cem\u003eOct 30 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eExperiment page (Start: \u003cem\u003eNov 9 2022\u003c/em\u003e, Shipped: \u003cem\u003eNov 26 2022\u003c/em\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eIn Progress\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAim SDK low-level interface (Start: \u003cem\u003eAug 22 2022\u003c/em\u003e, )\u003c/li\u003e\n\u003cli\u003eHuggingFace datasets (Start: \u003cem\u003eDec 29 2022\u003c/em\u003e, )\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eTo Do\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eAim UI\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eRuns management\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRuns explorer â€“ query and visualize runs data(images, audio, distributions, ...) in a central dashboard\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eExplorers\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eText Explorer\u003c/li\u003e\n\u003cli\u003eDistributions Explorer\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDashboards â€“ customizable layouts with embedded explorers\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSDK and Storage\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eScalability\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSmooth UI and SDK experience with over 10.000 runs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRuns management\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eCLI interfaces\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eReporting - runs summary and run details in a CLI compatible format\u003c/li\u003e\n\u003cli\u003eManipulations â€“ copy, move, delete runs, params and sequences\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eIntegrations\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eML Frameworks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eShortlist: MONAI, SpaCy, Raytune\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eResource management tools\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eShortlist: Kubeflow, Slurm\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWorkflow orchestration tools\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOthers: Hydra, Google MLMD, Streamlit, ...\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eOn hold\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003escikit-learn integration\u003c/li\u003e\n\u003cli\u003eCloud storage support â€“ store runs blob(e.g. images) data on the cloud (Start: \u003cem\u003eMar 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eArtifact storage â€“ store files, model checkpoints, and beyond (Start: \u003cem\u003eMar 21 2022\u003c/em\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eCommunity\u003c/h2\u003e\n\u003ch3\u003eIf you have questions\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://aimstack.readthedocs.io/en/latest/\"\u003eRead the docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/aimhubio/aim/issues\"\u003eOpen a feature request or report a bug\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://community.aimstack.io/\"\u003eJoin Discord community server\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e"},"_id":"posts/post-with-new-markdown.md","_raw":{"sourceFilePath":"posts/post-with-new-markdown.md","sourceFileName":"post-with-new-markdown.md","sourceFileDir":"posts","contentType":"markdown","flattenedPath":"posts/post-with-new-markdown"},"type":"Post"},{"title":"Test image path","date":"2023-01-14T18:17:57.545Z","author":"Ash","description":"test post","slug":"test-image-path","image":"/images/blog/sum.png","draft":false,"categories":["Test"],"body":{"raw":"\u003c!--StartFragment--\u003e\n\n## Where does it come from?\n\nContrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the \u003ch5\u003e cites\u003c/h5\u003e of the word in classical **literature**, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32\n\nThe standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by \u003cHighlight\u003e\u003cFlex align='center' css={{ marginTop: '$10' }}\u003e\n  \u003cIcon name='back' size={20} /\u003e\n  \u003cText size={3} css={{ fontWeight: '$3' }}\u003e\n    Go Back\n  \u003c/Text\u003e\n\u003c/Flex\u003e\u003c/Highlight\u003e\n\n\u003c!--EndFragment--\u003e\n\n```jsx\n\u003cFlex align='center' css={{ marginTop: '$10' }}\u003e\n  \u003cIcon name='back' size={20} /\u003e\n  \u003cText size={3} css={{ fontWeight: '$3' }}\u003e\n    Go Back\n  \u003c/Text\u003e\n\u003c/Flex\u003e\n```","html":"\u003ch2\u003eWhere does it come from?\u003c/h2\u003e\n\u003cp\u003eContrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the  cites of the word in classical \u003cstrong\u003eliterature\u003c/strong\u003e, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32\u003c/p\u003e\n\u003cp\u003eThe standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by \u0026#x3C;Flex align='center' css={{ marginTop: '$10' }}\u003e\n\n\u0026#x3C;Text size={3} css={{ fontWeight: '$3' }}\u003e\nGo Back\n\n\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-jsx\"\u003e\u0026#x3C;Flex align='center' css={{ marginTop: '$10' }}\u003e\n  \u0026#x3C;Icon name='back' size={20} /\u003e\n  \u0026#x3C;Text size={3} css={{ fontWeight: '$3' }}\u003e\n    Go Back\n  \u0026#x3C;/Text\u003e\n\u0026#x3C;/Flex\u003e\n\u003c/code\u003e\u003c/pre\u003e"},"_id":"posts/test-image-path.md","_raw":{"sourceFilePath":"posts/test-image-path.md","sourceFileName":"test-image-path.md","sourceFileDir":"posts","contentType":"markdown","flattenedPath":"posts/test-image-path"},"type":"Post"}]},"__N_SSG":true},"page":"/category/[slug]","query":{"slug":"test"},"buildId":"E4IpcvEwpq4T12cZyRpo4","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>